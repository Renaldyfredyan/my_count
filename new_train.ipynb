{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc73632-b277-4a0f-a9fc-4d4362652014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "Training with 1 GPUs\n",
      "Initializing directories...\n",
      "Setting up datasets...\n",
      "\n",
      "GPU Memory at Start of batch 0:\n",
      "  Allocated: 677.67MB\n",
      "/home/renaldy_fredyan/PhDResearch/ELS/module5/debug_utils.py:24: FutureWarning: `torch.cuda.memory_cached` has been renamed to `torch.cuda.memory_reserved`\n",
      "  print(f\"  Cached: {torch.cuda.memory_cached() / 1024**2:.2f}MB\")\n",
      "  Cached: 728.00MB\n",
      "  Peak: 684.96MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 693.67MB\n",
      "  Cached: 728.00MB\n",
      "  Peak: 693.67MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4168, min: -7.0649\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5030, min: -5.7705\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 4859.26MB\n",
      "  Cached: 5130.00MB\n",
      "  Peak: 4867.26MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 4811.26MB\n",
      "  Cached: 5130.00MB\n",
      "  Peak: 4867.26MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4168, min: -7.0649\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5030, min: -5.7705\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1069, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3951, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9591, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 4997.91MB\n",
      "  Cached: 5262.00MB\n",
      "  Peak: 5013.91MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 88.1846, min: -73.8470\n",
      "  memory: 0.01MB\n",
      "[rank0]:[W216 16:28:48.292407893 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "grad.sizes() = [256, 256, 1, 1], strides() = [256, 1, 256, 256]\n",
      "bucket_view.sizes() = [256, 256, 1, 1], strides() = [256, 1, 1, 1] (Triggered internally at /opt/conda/conda-bld/pytorch_1729647352509/work/torch/csrc/distributed/c10d/reducer.cpp:327.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\n",
      "GPU Memory at Start of batch 1:\n",
      "  Allocated: 1715.83MB\n",
      "  Cached: 7038.00MB\n",
      "  Peak: 6603.32MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.83MB\n",
      "  Cached: 7038.00MB\n",
      "  Peak: 6603.32MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0366, min: -6.6731\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0097, min: -6.1564\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5875.47MB\n",
      "  Cached: 7038.00MB\n",
      "  Peak: 6603.32MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5827.47MB\n",
      "  Cached: 7038.00MB\n",
      "  Peak: 6603.32MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0366, min: -6.6731\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0097, min: -6.1564\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8729, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2421, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4578, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6014.12MB\n",
      "  Cached: 7038.00MB\n",
      "  Peak: 6603.32MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.5174, min: -82.2519\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 2:\n",
      "  Allocated: 1717.11MB\n",
      "  Cached: 8092.00MB\n",
      "  Peak: 7274.47MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.11MB\n",
      "  Cached: 8092.00MB\n",
      "  Peak: 7274.47MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1660, min: -7.3783\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9923, min: -6.0370\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.99MB\n",
      "  Cached: 8092.00MB\n",
      "  Peak: 7274.47MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.99MB\n",
      "  Cached: 8092.00MB\n",
      "  Peak: 7274.47MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1660, min: -7.3783\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9923, min: -6.0370\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8404, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3287, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8153, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.50MB\n",
      "  Cached: 8092.00MB\n",
      "  Peak: 7274.47MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 116.9808, min: -96.5956\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 3:\n",
      "  Allocated: 1715.69MB\n",
      "  Cached: 8106.00MB\n",
      "  Peak: 7280.71MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.69MB\n",
      "  Cached: 8106.00MB\n",
      "  Peak: 7280.71MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3541, min: -6.6862\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5891, min: -5.7358\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.62MB\n",
      "  Cached: 8106.00MB\n",
      "  Peak: 7280.71MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5830.62MB\n",
      "  Cached: 8106.00MB\n",
      "  Peak: 7280.71MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3541, min: -6.6862\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5891, min: -5.7358\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0592, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2342, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3306, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.13MB\n",
      "  Cached: 8106.00MB\n",
      "  Peak: 7280.71MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 96.7179, min: -84.3556\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 4:\n",
      "  Allocated: 1717.54MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7280.71MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.54MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7280.71MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5223, min: -6.4893\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8660, min: -5.9188\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.83MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7280.71MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.83MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7280.71MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5223, min: -6.4893\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8660, min: -5.9188\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7954, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6835, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9449, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.19MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7280.71MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.1228, min: -74.9747\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 5:\n",
      "  Allocated: 1716.54MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7286.42MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.54MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7286.42MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3572, min: -6.8654\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2291, min: -6.0707\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.94MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7286.42MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.94MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7286.42MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3572, min: -6.8654\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2291, min: -6.0707\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7961, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5542, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2641, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.31MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7286.42MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.9519, min: -85.0657\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 6:\n",
      "  Allocated: 1716.54MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7286.42MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.54MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7286.42MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0137, min: -7.2647\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6488, min: -6.0313\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.87MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7286.42MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.87MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7286.42MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0137, min: -7.2647\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6488, min: -6.0313\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2152, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8486, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1473, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.38MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7286.42MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.6563, min: -71.2666\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 7:\n",
      "  Allocated: 1717.38MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7287.16MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.38MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7287.16MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.5580, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6460, min: -7.1174\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6534, min: -5.8608\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.83MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7287.16MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.83MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7287.16MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6460, min: -7.1174\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6534, min: -5.8608\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8822, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5335, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9774, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.48MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7287.16MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.8757, min: -78.5098\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 8:\n",
      "  Allocated: 1717.52MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7287.16MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.52MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7287.16MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1483, min: -6.7456\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5431, min: -6.6303\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.53MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7287.16MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.53MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7287.16MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1483, min: -6.7456\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5431, min: -6.6303\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3077, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9400, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9437, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6034.04MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7287.16MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 95.0493, min: -82.9394\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 9:\n",
      "  Allocated: 1719.41MB\n",
      "  Cached: 8068.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1735.41MB\n",
      "  Cached: 8068.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6426, min: -6.9268\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8533, min: -6.2353\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.60MB\n",
      "  Cached: 8068.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.60MB\n",
      "  Cached: 8068.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6426, min: -6.9268\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8533, min: -6.2353\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4353, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4889, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4283, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.96MB\n",
      "  Cached: 8068.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.3655, min: -75.6050\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 10:\n",
      "  Allocated: 1717.69MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.69MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1094, min: -7.5685\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3615, min: -5.7191\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.93MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.93MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1094, min: -7.5685\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3615, min: -5.7191\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0506, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7852, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9161, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.58MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 88.6878, min: -78.6665\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 11:\n",
      "  Allocated: 1718.93MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.93MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0077, min: -7.7188\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0017, min: -6.6298\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.39MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.39MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0077, min: -7.7188\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0017, min: -6.6298\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0452, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8162, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1851, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.04MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.5468, min: -72.9193\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 12:\n",
      "  Allocated: 1716.98MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.98MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1256, min: -6.8525\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7097, min: -6.9376\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.39MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.39MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1256, min: -6.8525\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7097, min: -6.9376\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3014, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1749, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6287, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.04MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.9863, min: -92.8121\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 13:\n",
      "  Allocated: 1718.81MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.81MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4812, min: -7.0011\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9233, min: -6.2679\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.36MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.36MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4812, min: -7.0011\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9233, min: -6.2679\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0201, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0756, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2856, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.01MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.2872, min: -78.1963\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 14:\n",
      "  Allocated: 1718.76MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.76MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6978, min: -7.4675\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9876, min: -6.5335\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5896.06MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5848.06MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6978, min: -7.4675\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9876, min: -6.5335\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4604, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9598, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5364, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6034.71MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.3020, min: -78.4086\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 15:\n",
      "  Allocated: 1717.91MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.91MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3668, min: -6.7808\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7542, min: -6.4498\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5896.33MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5848.33MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3668, min: -6.7808\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7542, min: -6.4498\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8218, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4474, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1803, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6035.84MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7290.84MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.0104, min: -82.2316\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 16:\n",
      "  Allocated: 1715.63MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.63MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3560, min: -6.8050\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6732, min: -6.4433\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.51MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.51MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3560, min: -6.8050\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6732, min: -6.4433\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2518, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1919, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.8563, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.16MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 111.2379, min: -101.6870\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 17:\n",
      "  Allocated: 1717.41MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.41MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9988, min: -6.0937\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5353, min: -6.3077\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.77MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.77MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9988, min: -6.0937\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5353, min: -6.3077\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5606, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8152, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6409, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.42MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.8912, min: -94.1771\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 18:\n",
      "  Allocated: 1716.76MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.76MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6714, min: -6.7412\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8362, min: -6.7394\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.97MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.97MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6714, min: -6.7412\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8362, min: -6.7394\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0451, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3849, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2332, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.62MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 88.5796, min: -79.9799\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 19:\n",
      "  Allocated: 1716.41MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.41MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7424, min: -7.0701\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9577, min: -6.8885\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.95MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.95MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7424, min: -7.0701\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9577, min: -6.8885\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7015, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5157, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1162, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.46MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 111.3124, min: -102.6762\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 20:\n",
      "  Allocated: 1715.87MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.87MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5629, min: -8.0506\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4262, min: -6.6108\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.42MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.42MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5629, min: -8.0506\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4262, min: -6.6108\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5883, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1754, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9164, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.07MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.6282, min: -80.4034\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 21:\n",
      "  Allocated: 1718.53MB\n",
      "  Cached: 8010.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.53MB\n",
      "  Cached: 8010.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0732, min: -7.5308\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4987, min: -7.6068\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.31MB\n",
      "  Cached: 8010.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.31MB\n",
      "  Cached: 8010.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0732, min: -7.5308\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4987, min: -7.6068\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9839, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6699, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3560, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.96MB\n",
      "  Cached: 8010.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 72.7332, min: -69.7388\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 22:\n",
      "  Allocated: 1717.84MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.84MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8827, min: -7.1599\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8788, min: -8.0764\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.61MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.61MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8827, min: -7.1599\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8788, min: -8.0764\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5242, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7034, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0728, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.26MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.5683, min: -81.8416\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 23:\n",
      "  Allocated: 1716.84MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.85MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0795, min: -7.7098\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6354, min: -5.9922\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.23MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.23MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0795, min: -7.7098\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6354, min: -5.9922\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0587, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2464, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6401, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.88MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.2696, min: -101.2649\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 24:\n",
      "  Allocated: 1715.94MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.94MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7207, min: -8.0975\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8061, min: -6.7727\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.31MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.31MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7207, min: -8.0975\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8061, min: -6.7727\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5121, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4412, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.9773, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.96MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 102.7800, min: -86.6163\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 25:\n",
      "  Allocated: 1716.92MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.92MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8661, min: -6.7776\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7335, min: -6.8696\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.10MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.10MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8661, min: -6.7776\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7335, min: -6.8696\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8957, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2748, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9462, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.75MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.7084, min: -88.6202\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 26:\n",
      "  Allocated: 1717.25MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.26MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0303, min: -7.6637\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8544, min: -6.6723\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.41MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.41MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0303, min: -7.6637\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8544, min: -6.6723\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8377, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7699, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2450, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.77MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 109.7133, min: -106.0601\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 27:\n",
      "  Allocated: 1715.62MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.62MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5831, min: -7.3990\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7479, min: -6.7902\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.76MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.76MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5831, min: -7.3990\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7479, min: -6.7902\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5380, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6981, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3263, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.13MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 108.9693, min: -103.3300\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 28:\n",
      "  Allocated: 1715.54MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.54MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4196, min: -6.6330\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1629, min: -7.0367\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.00MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.00MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4196, min: -6.6330\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1629, min: -7.0367\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4159, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5089, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.1487, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.65MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.8252, min: -84.5770\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 29:\n",
      "  Allocated: 1716.05MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.05MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8120, min: -8.3586\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7921, min: -6.5138\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.24MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.24MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8120, min: -8.3586\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7921, min: -6.5138\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6024, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9755, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8211, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.89MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.5382, min: -91.8285\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 30:\n",
      "  Allocated: 1715.19MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.19MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9467, min: -7.6158\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4976, min: -5.8267\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.44MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.44MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9467, min: -7.6158\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4976, min: -5.8267\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5353, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3943, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.5466, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.80MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.8650, min: -89.8327\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 31:\n",
      "  Allocated: 1718.44MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.44MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5550, min: -6.4634\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9716, min: -8.6253\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.79MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.79MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5550, min: -6.4634\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9716, min: -8.6253\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3067, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7109, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7016, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6034.15MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.7952, min: -87.1484\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 32:\n",
      "  Allocated: 1717.34MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.34MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7007, min: -6.8487\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6365, min: -5.9706\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.11MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.11MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7007, min: -6.8487\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6365, min: -5.9706\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2700, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9014, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8463, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.76MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.0520, min: -83.4873\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 33:\n",
      "  Allocated: 1716.79MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.79MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4696, min: -7.6794\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7851, min: -6.7181\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.42MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.42MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4696, min: -7.6794\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7851, min: -6.7181\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3838, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9248, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8030, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.07MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 110.8521, min: -109.1170\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 34:\n",
      "  Allocated: 1719.83MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1735.83MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1856, min: -7.7749\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7343, min: -5.8167\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5895.56MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5847.56MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1856, min: -7.7749\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7343, min: -5.8167\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8756, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3113, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1392, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6034.21MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 87.5645, min: -82.8331\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 35:\n",
      "  Allocated: 1718.18MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.18MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6183, min: -6.8603\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0724, min: -7.4672\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.95MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.95MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6183, min: -6.8603\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0724, min: -7.4672\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8049, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8634, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6749, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.60MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.8502, min: -87.2676\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 36:\n",
      "  Allocated: 1718.34MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.34MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9496, min: -7.8548\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7808, min: -5.7784\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.00MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.00MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9496, min: -7.8548\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7808, min: -5.7784\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0588, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.0744, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5426, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.36MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.7624, min: -95.2186\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 37:\n",
      "  Allocated: 1718.40MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.40MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2339, min: -7.3260\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5923, min: -6.1286\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.21MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.21MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2339, min: -7.3260\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5923, min: -6.1286\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2503, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9056, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1970, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.58MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 96.6983, min: -87.1585\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 38:\n",
      "  Allocated: 1718.28MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.28MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5555, min: -8.4489\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9356, min: -6.4328\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.00MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.00MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5555, min: -8.4489\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9356, min: -6.4328\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2392, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9398, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1155, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.65MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 104.1059, min: -96.0036\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 39:\n",
      "  Allocated: 1717.91MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.91MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6691, min: -8.2825\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7253, min: -5.5842\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.65MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.65MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6691, min: -8.2825\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7253, min: -5.5842\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4674, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7316, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5257, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.83MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.7320, min: -91.2816\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 40:\n",
      "  Allocated: 1715.95MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.95MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9365, min: -7.1754\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1718, min: -6.5436\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.05MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.05MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9365, min: -7.1754\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1718, min: -6.5436\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3121, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0867, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6494, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.42MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.7431, min: -89.8113\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 41:\n",
      "  Allocated: 1716.81MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.81MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4327, min: -7.3870\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7434, min: -6.5418\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.44MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.44MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4327, min: -7.3870\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7434, min: -6.5418\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6769, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8202, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2776, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.09MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 100.6937, min: -102.8415\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 42:\n",
      "  Allocated: 1714.83MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.83MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8136, min: -7.3999\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5369, min: -7.9669\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.58MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.58MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8136, min: -7.3999\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5369, min: -7.9669\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3080, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8111, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6135, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.23MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 70.7531, min: -76.6238\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 43:\n",
      "  Allocated: 1719.26MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1735.26MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8909, min: -7.4992\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6165, min: -6.6838\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.94MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.94MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8909, min: -7.4992\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6165, min: -6.6838\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2018, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6869, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8329, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.59MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.4675, min: -85.7645\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 44:\n",
      "  Allocated: 1716.48MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.48MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9802, min: -7.4641\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9681, min: -6.5191\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.19MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.19MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9802, min: -7.4641\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9681, min: -6.5191\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1792, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7403, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3289, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.56MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.1169, min: -86.3705\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 45:\n",
      "  Allocated: 1717.35MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.35MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1898, min: -7.4327\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0174, min: -6.1741\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.37MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.37MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1898, min: -7.4327\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0174, min: -6.1741\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7553, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3889, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2124, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.02MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 88.2826, min: -85.8309\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 46:\n",
      "  Allocated: 1716.61MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.61MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8284, min: -7.6282\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5716, min: -6.2970\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.12MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.69MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8284, min: -7.6282\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5716, min: -6.2970\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7678, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0658, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8974, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.77MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.0662, min: -89.6545\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 47:\n",
      "  Allocated: 1713.68MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.68MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9894, min: -6.9942\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5431, min: -5.9298\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.30MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.30MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9894, min: -6.9942\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5431, min: -5.9298\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5437, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1713, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2723, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.95MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 95.4743, min: -93.3815\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 48:\n",
      "  Allocated: 1715.95MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.95MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3901, min: -6.5114\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9563, min: -6.0423\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.79MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.79MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3901, min: -6.5114\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9563, min: -6.0423\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7127, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4783, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8700, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.30MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.7332, min: -87.6043\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 49:\n",
      "  Allocated: 1715.36MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.36MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8559, min: -7.0761\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9351, min: -5.7512\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.71MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.71MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8559, min: -7.0761\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9351, min: -5.7512\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7191, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0778, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 9.0744, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.22MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.3426, min: -88.5706\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 50:\n",
      "  Allocated: 1716.48MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.48MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0329, min: -8.1601\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7609, min: -6.2610\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.09MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.09MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0329, min: -8.1601\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7609, min: -6.2610\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4399, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4519, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3093, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.45MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 64.2167, min: -63.9771\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 51:\n",
      "  Allocated: 1716.06MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.06MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6184, min: -7.2686\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5144, min: -5.2878\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.62MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.62MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6184, min: -7.2686\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5144, min: -5.2878\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4692, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0125, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2751, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.27MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.6867, min: -87.1204\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 52:\n",
      "  Allocated: 1714.96MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.96MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0300, min: -7.2837\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9492, min: -7.0256\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.17MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.17MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0300, min: -7.2837\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9492, min: -7.0256\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5244, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5601, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3143, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.82MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.2956, min: -98.7021\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 53:\n",
      "  Allocated: 1715.39MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.39MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0950, min: -7.6039\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2581, min: -6.7158\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.30MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.30MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0950, min: -7.6039\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2581, min: -6.7158\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7727, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2530, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.9124, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.67MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.5205, min: -101.0868\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 54:\n",
      "  Allocated: 1715.30MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.30MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3986, min: -7.3202\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6653, min: -6.3146\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.34MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.34MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3986, min: -7.3202\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6653, min: -6.3146\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8184, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0049, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5970, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.99MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 77.7608, min: -68.6766\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 55:\n",
      "  Allocated: 1716.25MB\n",
      "  Cached: 8010.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.25MB\n",
      "  Cached: 8010.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8644, min: -7.9925\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2480, min: -6.7108\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.44MB\n",
      "  Cached: 8010.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.01MB\n",
      "  Cached: 8010.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8644, min: -7.9925\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2480, min: -6.7108\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5235, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4964, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3814, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.95MB\n",
      "  Cached: 8010.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.8714, min: -86.5016\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 56:\n",
      "  Allocated: 1714.37MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.37MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9046, min: -7.0188\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8746, min: -6.5332\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.40MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.40MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9046, min: -7.0188\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8746, min: -6.5332\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3711, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8364, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6317, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.05MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.1862, min: -74.2277\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 57:\n",
      "  Allocated: 1715.49MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.49MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5184, min: -8.7848\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0190, min: -6.4921\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.06MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.06MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5184, min: -8.7848\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0190, min: -6.4921\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5804, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7662, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9850, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.71MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.6189, min: -92.7505\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 58:\n",
      "  Allocated: 1715.66MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.67MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9957, min: -7.6583\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8776, min: -6.3667\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.50MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.07MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9957, min: -7.6583\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8776, min: -6.3667\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6707, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0588, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5112, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.87MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.1281, min: -84.1071\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 59:\n",
      "  Allocated: 1717.16MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.16MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.2407, min: -7.4549\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4951, min: -5.7497\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.03MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.03MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.2407, min: -7.4549\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4951, min: -5.7497\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2998, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4888, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0406, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.40MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.4857, min: -94.8094\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 60:\n",
      "  Allocated: 1715.38MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.38MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4000, min: -6.7124\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3003, min: -6.0633\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.29MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.29MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4000, min: -6.7124\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3003, min: -6.0633\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1128, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9671, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9040, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.65MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.1516, min: -83.1004\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 61:\n",
      "  Allocated: 1717.76MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.76MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7398, min: -7.0217\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3332, min: -6.3453\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.76MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.76MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7398, min: -7.0217\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3332, min: -6.3453\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1293, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3433, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4280, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.41MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 63.7677, min: -61.4963\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 62:\n",
      "  Allocated: 1716.39MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.39MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3777, min: -6.7554\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4423, min: -6.4258\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.06MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.06MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3777, min: -6.7554\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4423, min: -6.4258\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0196, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3713, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0223, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.57MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 72.1127, min: -75.2495\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 63:\n",
      "  Allocated: 1716.95MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.95MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2023, min: -6.7048\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9647, min: -6.8097\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.02MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.59MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2023, min: -6.7048\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9647, min: -6.8097\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1017, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5725, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2249, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.39MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.6783, min: -94.6821\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 64:\n",
      "  Allocated: 1716.65MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.65MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3839, min: -6.8411\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8195, min: -6.7244\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.08MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.08MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3839, min: -6.8411\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8195, min: -6.7244\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2775, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3703, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2851, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.59MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.3229, min: -89.8847\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 65:\n",
      "  Allocated: 1715.30MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.30MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5715, min: -7.2826\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6635, min: -6.5990\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.30MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.30MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5715, min: -7.2826\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6635, min: -6.5990\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7692, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4333, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8973, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.95MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.9437, min: -78.2495\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 66:\n",
      "  Allocated: 1715.52MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.52MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9840, min: -7.5435\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3489, min: -6.0597\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.69MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.69MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9840, min: -7.5435\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3489, min: -6.0597\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6604, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7246, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2920, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.34MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.0930, min: -73.1686\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 67:\n",
      "  Allocated: 1715.40MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.40MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8187, min: -7.1532\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6656, min: -6.5042\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.51MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5829.51MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8187, min: -7.1532\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6656, min: -6.5042\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9971, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2673, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7403, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.88MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 68.6469, min: -65.5222\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 68:\n",
      "  Allocated: 1716.28MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.28MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1386, min: -6.6500\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6168, min: -6.4537\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.84MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.84MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1386, min: -6.6500\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6168, min: -6.4537\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4028, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7115, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9139, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.49MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.4054, min: -97.0459\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 69:\n",
      "  Allocated: 1715.63MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.63MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4750, min: -6.4507\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4353, min: -6.5768\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.93MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.93MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4750, min: -6.4507\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4353, min: -6.5768\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5428, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9242, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9811, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.30MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.2467, min: -82.3971\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 70:\n",
      "  Allocated: 1714.93MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.93MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0547, min: -6.8082\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8815, min: -6.5645\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.46MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.46MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0547, min: -6.8082\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8815, min: -6.5645\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9358, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7926, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2452, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.10MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.7850, min: -80.5014\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 71:\n",
      "  Allocated: 1716.62MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.62MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5482, min: -7.9878\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7859, min: -6.2495\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.06MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.06MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5482, min: -7.9878\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7859, min: -6.2495\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5024, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2357, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8036, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.71MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.9202, min: -91.6491\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 72:\n",
      "  Allocated: 1716.19MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.19MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0238, min: -7.6329\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4172, min: -6.2503\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.77MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.77MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0238, min: -7.6329\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4172, min: -6.2503\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3957, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4725, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6627, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.42MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.8323, min: -85.0369\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 73:\n",
      "  Allocated: 1714.38MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.38MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3127, min: -6.4880\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8288, min: -6.8231\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.19MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.19MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3127, min: -6.4880\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8288, min: -6.8231\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8928, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6251, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7719, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.56MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 78.9010, min: -80.2280\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 74:\n",
      "  Allocated: 1715.23MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.24MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.5240, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3546, min: -8.4246\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0358, min: -8.1510\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.66MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.66MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3546, min: -8.4246\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0358, min: -8.1510\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1352, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7843, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9942, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.03MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 102.1097, min: -97.4285\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 75:\n",
      "  Allocated: 1713.45MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.45MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9584, min: -7.6645\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7474, min: -8.2407\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.85MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5829.85MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9584, min: -7.6645\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7474, min: -8.2407\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8934, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8919, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3684, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6016.50MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 100.6183, min: -95.3113\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 76:\n",
      "  Allocated: 1715.54MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.54MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7110, min: -7.1776\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7261, min: -6.1623\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.30MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.30MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7110, min: -7.1776\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7261, min: -6.1623\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4818, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7029, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5495, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.95MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.4836, min: -90.0873\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 77:\n",
      "  Allocated: 1715.73MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.73MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6181, min: -6.6186\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4513, min: -7.0371\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.64MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.64MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6181, min: -6.6186\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4513, min: -7.0371\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3075, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5909, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2221, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.29MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 111.0635, min: -107.0488\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 78:\n",
      "  Allocated: 1715.62MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.62MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7726, min: -7.6007\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5805, min: -6.1559\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5876.80MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5828.80MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7726, min: -7.6007\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5805, min: -6.1559\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8348, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6344, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9488, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6016.98MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.3597, min: -83.0033\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 79:\n",
      "  Allocated: 1716.34MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.34MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3758, min: -7.5191\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9306, min: -6.1882\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.05MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.05MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3758, min: -7.5191\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9306, min: -6.1882\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6187, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6893, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5793, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.70MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.0927, min: -93.8040\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 80:\n",
      "  Allocated: 1716.29MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.29MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0456, min: -8.0904\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3062, min: -6.7459\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.99MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.99MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0456, min: -8.0904\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3062, min: -6.7459\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9544, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3929, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9887, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.36MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.4392, min: -94.5569\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 81:\n",
      "  Allocated: 1715.27MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.27MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6504, min: -7.7614\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8724, min: -6.3993\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.48MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.48MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6504, min: -7.7614\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8724, min: -6.3993\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0259, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3501, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6703, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.99MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 78.5656, min: -76.6203\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 82:\n",
      "  Allocated: 1716.01MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.01MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8616, min: -7.2289\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4545, min: -6.5891\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.37MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.37MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8616, min: -7.2289\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4545, min: -6.5891\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3425, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6198, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9295, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.88MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 96.2309, min: -97.2625\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 83:\n",
      "  Allocated: 1715.76MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.76MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7225, min: -7.0313\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0597, min: -6.7253\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.03MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.03MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7225, min: -7.0313\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0597, min: -6.7253\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3611, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6879, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4475, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.68MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.0231, min: -84.8546\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 84:\n",
      "  Allocated: 1717.05MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.05MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8673, min: -8.1934\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8764, min: -6.8383\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.61MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.61MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8673, min: -8.1934\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8764, min: -6.8383\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6106, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6964, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4918, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.26MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.4170, min: -81.5715\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 85:\n",
      "  Allocated: 1716.68MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.68MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4954, min: -6.5649\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8156, min: -6.2140\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.25MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.82MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4954, min: -6.5649\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8156, min: -6.2140\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7017, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1457, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3538, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.89MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 104.3240, min: -91.7847\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 86:\n",
      "  Allocated: 1715.86MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.87MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1586, min: -7.5077\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5866, min: -6.6096\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.15MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.15MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1586, min: -7.5077\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5866, min: -6.6096\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8266, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6328, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8034, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.80MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.6739, min: -86.8046\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 87:\n",
      "  Allocated: 1716.11MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.11MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0027, min: -7.8143\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0982, min: -7.8964\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.74MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.74MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0027, min: -7.8143\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0982, min: -7.8964\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3138, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8583, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6201, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.39MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.1464, min: -99.1134\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 88:\n",
      "  Allocated: 1715.68MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.68MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0715, min: -6.5131\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4634, min: -6.0552\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.87MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.87MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0715, min: -6.5131\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4634, min: -6.0552\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5779, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7175, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7487, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.24MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.7533, min: -80.1263\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 89:\n",
      "  Allocated: 1715.82MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.82MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4753, min: -7.1774\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0644, min: -5.9061\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.47MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.47MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4753, min: -7.1774\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0644, min: -5.9061\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.2224, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4219, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6412, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.84MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.9318, min: -90.2942\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 90:\n",
      "  Allocated: 1717.03MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.03MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3421, min: -7.3564\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3301, min: -6.3442\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.04MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.04MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3421, min: -7.3564\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3301, min: -6.3442\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8320, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8521, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9240, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.41MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 95.4626, min: -96.1019\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 91:\n",
      "  Allocated: 1718.05MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.05MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5326, min: -7.4128\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9365, min: -6.8066\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.75MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.32MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5326, min: -7.4128\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9365, min: -6.8066\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9404, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4478, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2998, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.40MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.7177, min: -84.4914\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 92:\n",
      "  Allocated: 1715.47MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.47MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1806, min: -8.4081\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3778, min: -6.9807\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.09MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.09MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1806, min: -8.4081\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3778, min: -6.9807\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6553, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0371, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0609, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.45MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.5143, min: -98.7079\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 93:\n",
      "  Allocated: 1714.01MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.01MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.1388, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7931, min: -7.4108\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3570, min: -5.9163\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.90MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.47MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7931, min: -7.4108\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3570, min: -5.9163\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1438, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5325, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1249, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.41MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.0979, min: -90.4778\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 94:\n",
      "  Allocated: 1718.30MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.30MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0472, min: -8.6426\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4920, min: -6.0480\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.59MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.59MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0472, min: -8.6426\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4920, min: -6.0480\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4296, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5986, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9877, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.24MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 109.8976, min: -111.8941\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 95:\n",
      "  Allocated: 1717.77MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.77MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9982, min: -7.6864\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5532, min: -6.2862\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.92MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.92MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9982, min: -7.6864\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5532, min: -6.2862\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1302, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8326, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4978, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.29MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 87.0540, min: -87.6121\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 96:\n",
      "  Allocated: 1716.68MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.69MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6157, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8934, min: -7.3621\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6100, min: -6.1926\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.00MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.00MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8934, min: -7.3621\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6100, min: -6.1926\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1828, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2151, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0663, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.65MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 100.6894, min: -103.4301\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 97:\n",
      "  Allocated: 1717.00MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.00MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2288, min: -7.3317\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7416, min: -6.0442\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.46MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.46MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2288, min: -7.3317\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7416, min: -6.0442\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4653, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7832, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3306, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.83MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 108.5142, min: -111.3744\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 98:\n",
      "  Allocated: 1714.70MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.70MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4313, min: -7.1478\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9228, min: -7.5239\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.75MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.75MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4313, min: -7.1478\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9228, min: -7.5239\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6553, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6128, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8138, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.11MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.3664, min: -93.0019\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 99:\n",
      "  Allocated: 1717.31MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.31MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1288, min: -7.4839\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6929, min: -6.1011\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.37MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.37MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1288, min: -7.4839\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6929, min: -6.1011\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1578, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4824, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7433, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.88MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.3259, min: -103.8337\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 100:\n",
      "  Allocated: 1714.97MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.97MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5692, min: -7.1105\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6738, min: -6.8423\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.88MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.88MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5692, min: -7.1105\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6738, min: -6.8423\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3452, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4601, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7221, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.53MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 115.1507, min: -112.2812\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 101:\n",
      "  Allocated: 1714.76MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.76MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9890, min: -7.2872\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6678, min: -6.4034\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.55MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.55MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9890, min: -7.2872\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6678, min: -6.4034\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5043, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1939, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4183, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.20MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 68.7459, min: -66.5126\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 102:\n",
      "  Allocated: 1714.62MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.62MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2738, min: -7.6374\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1474, min: -6.3632\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.01MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.01MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2738, min: -7.6374\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1474, min: -6.3632\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4145, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0652, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8599, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.38MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.5623, min: -93.0977\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 103:\n",
      "  Allocated: 1715.70MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.70MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7508, min: -7.3174\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8449, min: -5.7304\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.13MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.13MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7508, min: -7.3174\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8449, min: -5.7304\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4950, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2272, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1301, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.78MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 100.7675, min: -101.7855\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 104:\n",
      "  Allocated: 1715.66MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.67MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9931, min: -8.4127\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4603, min: -6.1856\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.01MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.01MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9931, min: -8.4127\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4603, min: -6.1856\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7026, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5048, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1423, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.38MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.4081, min: -84.3533\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 105:\n",
      "  Allocated: 1715.36MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.36MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0548, min: -7.3315\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4130, min: -6.5730\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.17MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.17MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0548, min: -7.3315\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4130, min: -6.5730\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6533, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5631, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0439, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.68MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.4931, min: -91.7403\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 106:\n",
      "  Allocated: 1716.05MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.05MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1686, min: -6.8002\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3437, min: -7.5747\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.94MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.94MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1686, min: -6.8002\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3437, min: -7.5747\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3606, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1632, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6883, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.59MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.7141, min: -83.0259\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 107:\n",
      "  Allocated: 1715.89MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.89MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.8549, min: -7.8066\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7044, min: -6.4335\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.38MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.38MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.8549, min: -7.8066\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7044, min: -6.4335\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0185, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0601, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6359, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.89MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 116.9425, min: -120.6850\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 108:\n",
      "  Allocated: 1717.38MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.38MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5427, min: -8.0377\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4348, min: -6.8529\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.19MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.19MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5427, min: -8.0377\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4348, min: -6.8529\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9613, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5469, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0113, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.84MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.3478, min: -93.1793\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 109:\n",
      "  Allocated: 1715.06MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.06MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0514, min: -6.7380\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6108, min: -5.8794\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.70MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.70MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0514, min: -6.7380\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6108, min: -5.8794\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3044, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9126, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8228, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.21MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.8390, min: -85.4828\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 110:\n",
      "  Allocated: 1715.76MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.76MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8176, min: -6.9142\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4648, min: -5.9236\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5894.26MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5846.26MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8176, min: -6.9142\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4648, min: -5.9236\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6727, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5555, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 9.6669, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.91MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 75.6416, min: -78.3929\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 111:\n",
      "  Allocated: 1717.52MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.52MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3669, min: -7.8999\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4468, min: -6.8590\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.57MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.57MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3669, min: -7.8999\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4468, min: -6.8590\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8189, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6418, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.8035, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.75MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 88.2616, min: -89.7732\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 112:\n",
      "  Allocated: 1715.40MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.41MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7584, min: -7.1309\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5061, min: -6.2571\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.10MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.10MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7584, min: -7.1309\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5061, min: -6.2571\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5230, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7372, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.7956, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.75MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.6873, min: -98.0260\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 113:\n",
      "  Allocated: 1714.09MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.09MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.5499, min: -2.1159\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4819, min: -7.6510\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0102, min: -6.5141\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.39MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.39MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4819, min: -7.6510\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0102, min: -6.5141\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6615, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6354, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6000, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.04MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.6180, min: -93.6038\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 114:\n",
      "  Allocated: 1715.83MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.83MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.9810, min: -8.1253\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6806, min: -6.3489\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.87MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.87MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.9810, min: -8.1253\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6806, min: -6.3489\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4136, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5794, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7200, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.52MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.2186, min: -90.1402\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 115:\n",
      "  Allocated: 1716.95MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.95MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8771, min: -7.7710\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8449, min: -6.6115\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.28MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.28MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8771, min: -7.7710\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8449, min: -6.6115\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3153, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7251, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0327, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.93MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.3460, min: -93.2538\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 116:\n",
      "  Allocated: 1716.17MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.17MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0499, min: -8.4311\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7594, min: -6.3479\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.21MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.21MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0499, min: -8.4311\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7594, min: -6.3479\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9399, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0487, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9450, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.85MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.4662, min: -92.0748\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 117:\n",
      "  Allocated: 1716.17MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.17MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1697, min: -6.7556\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0202, min: -6.2169\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.06MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.06MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1697, min: -6.7556\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0202, min: -6.2169\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0163, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6682, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3790, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.57MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.7972, min: -91.8609\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 118:\n",
      "  Allocated: 1714.52MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.52MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3192, min: -8.0067\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5586, min: -7.2931\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.07MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.07MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3192, min: -8.0067\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5586, min: -7.2931\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1026, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9538, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6432, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.72MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 96.4373, min: -97.4782\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 119:\n",
      "  Allocated: 1714.20MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.20MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.1900, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2203, min: -7.8854\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5015, min: -5.5394\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.57MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.57MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2203, min: -7.8854\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5015, min: -5.5394\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5301, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6384, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4787, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.22MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.9777, min: -91.7433\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 120:\n",
      "  Allocated: 1715.30MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.30MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4312, min: -7.0215\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4828, min: -5.6286\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.05MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.05MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4312, min: -7.0215\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4828, min: -5.6286\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2147, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9541, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5599, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.56MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 78.6382, min: -81.0752\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 121:\n",
      "  Allocated: 1713.98MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.98MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1055, min: -7.7468\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7131, min: -6.4516\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.81MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5829.81MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1055, min: -7.7468\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7131, min: -6.4516\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7398, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5944, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6524, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.99MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 77.4533, min: -84.8541\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 122:\n",
      "  Allocated: 1716.64MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.64MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.4876, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8685, min: -7.8622\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4403, min: -6.8070\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.63MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.20MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8685, min: -7.8622\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4403, min: -6.8070\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7944, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6713, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4108, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.28MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 111.5691, min: -110.5523\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 123:\n",
      "  Allocated: 1713.23MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.24MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2339, min: -8.3794\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7215, min: -6.3465\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.13MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5828.70MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2339, min: -8.3794\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7215, min: -6.3465\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0554, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9437, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2434, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6016.64MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.8118, min: -81.4097\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 124:\n",
      "  Allocated: 1718.24MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.24MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5082, min: -7.9063\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3858, min: -6.2069\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.50MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.50MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5082, min: -7.9063\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3858, min: -6.2069\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0992, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4146, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4922, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.15MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 76.8811, min: -78.7906\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 125:\n",
      "  Allocated: 1716.55MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.55MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1781, min: -8.3389\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3187, min: -5.9233\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.53MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5830.10MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1781, min: -8.3389\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3187, min: -5.9233\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6532, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9111, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3242, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.90MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 114.2850, min: -103.0616\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 126:\n",
      "  Allocated: 1716.56MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.56MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1246, min: -6.7495\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1121, min: -6.9050\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.78MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.78MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1246, min: -6.7495\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1121, min: -6.9050\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9878, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6329, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4326, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.43MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 100.0900, min: -100.4253\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 127:\n",
      "  Allocated: 1717.90MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.90MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.7688, min: -7.9584\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8059, min: -7.1420\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.93MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.93MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.7688, min: -7.9584\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8059, min: -7.1420\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4350, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4003, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 10.2110, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.58MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.7029, min: -88.3996\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 128:\n",
      "  Allocated: 1715.69MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.69MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6531, min: -7.3549\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6178, min: -6.5255\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.93MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.93MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6531, min: -7.3549\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6178, min: -6.5255\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1550, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2468, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.2931, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.58MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 72.3078, min: -69.8915\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 129:\n",
      "  Allocated: 1719.19MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1735.19MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1128, min: -7.5323\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7441, min: -6.2092\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.00MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.57MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1128, min: -7.5323\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7441, min: -6.2092\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9644, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8375, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8242, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.36MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 120.0245, min: -121.0934\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 130:\n",
      "  Allocated: 1714.84MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.85MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8949, min: -7.8406\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9081, min: -6.5431\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.37MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5830.37MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8949, min: -7.8406\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9081, min: -6.5431\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0575, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0826, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5711, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.73MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.6201, min: -80.1021\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 131:\n",
      "  Allocated: 1715.94MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.94MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8426, min: -7.3119\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5852, min: -6.1572\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.68MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.68MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8426, min: -7.3119\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5852, min: -6.1572\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9293, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2650, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4738, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.33MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.1991, min: -97.2290\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 132:\n",
      "  Allocated: 1716.62MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.62MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2556, min: -7.7837\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5739, min: -7.2794\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.31MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.31MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2556, min: -7.7837\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5739, min: -7.2794\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9242, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7136, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4639, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.67MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.1819, min: -85.6106\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 133:\n",
      "  Allocated: 1714.95MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.95MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6534, min: -7.5024\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4051, min: -5.9427\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.88MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5830.88MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6534, min: -7.5024\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4051, min: -5.9427\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3646, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9714, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.9967, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.25MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.8134, min: -92.9470\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 134:\n",
      "  Allocated: 1715.09MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.09MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6896, min: -7.1856\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1657, min: -6.9059\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.28MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.28MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6896, min: -7.1856\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1657, min: -6.9059\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5572, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5791, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4843, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.93MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 95.9495, min: -92.9974\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 135:\n",
      "  Allocated: 1716.06MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.06MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0490, min: -6.9214\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6767, min: -6.1530\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.95MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.95MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0490, min: -6.9214\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6767, min: -6.1530\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3367, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1375, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4910, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.60MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 113.7150, min: -111.3392\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 136:\n",
      "  Allocated: 1715.78MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.78MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5839, min: -8.2778\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1305, min: -6.6126\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.20MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.20MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5839, min: -8.2778\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1305, min: -6.6126\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9766, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8727, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5108, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.56MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.5097, min: -80.9869\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 137:\n",
      "  Allocated: 1715.01MB\n",
      "  Cached: 8112.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.01MB\n",
      "  Cached: 8112.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.8272, min: -7.5217\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7956, min: -6.2734\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.00MB\n",
      "  Cached: 8112.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.57MB\n",
      "  Cached: 8112.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.8272, min: -7.5217\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7956, min: -6.2734\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8000, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0876, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4572, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.65MB\n",
      "  Cached: 8112.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.7784, min: -81.7530\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 138:\n",
      "  Allocated: 1718.19MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.19MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6397, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0496, min: -7.3946\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7332, min: -6.2564\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.22MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.22MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0496, min: -7.3946\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7332, min: -6.2564\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3622, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6816, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5616, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.87MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 108.2587, min: -109.8654\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 139:\n",
      "  Allocated: 1715.52MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.52MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8545, min: -7.7691\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9089, min: -6.4725\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.55MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.55MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8545, min: -7.7691\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9089, min: -6.4725\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9517, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1226, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3839, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.20MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.5077, min: -86.7466\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 140:\n",
      "  Allocated: 1716.81MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.81MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1715, min: -7.5004\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6740, min: -6.3448\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.79MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.79MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1715, min: -7.5004\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6740, min: -6.3448\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3647, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9343, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6573, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.29MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.9960, min: -83.3733\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 141:\n",
      "  Allocated: 1714.55MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.55MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7845, min: -7.2374\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0024, min: -6.8968\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.54MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.54MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7845, min: -7.2374\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0024, min: -6.8968\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7836, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6034, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7608, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.19MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 105.8588, min: -107.2751\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 142:\n",
      "  Allocated: 1714.50MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.50MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0414, min: -8.0009\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1071, min: -7.4427\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.95MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5829.95MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0414, min: -8.0009\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1071, min: -7.4427\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8497, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4631, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2799, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.32MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.3109, min: -93.7761\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 143:\n",
      "  Allocated: 1717.76MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.76MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7888, min: -7.3597\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3038, min: -7.4000\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.93MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.93MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7888, min: -7.3597\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3038, min: -7.4000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8130, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6131, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8442, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.57MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 96.2748, min: -95.7206\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 144:\n",
      "  Allocated: 1717.66MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.67MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9531, min: -7.5859\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4004, min: -7.3736\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5895.42MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5847.42MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9531, min: -7.5859\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4004, min: -7.3736\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4935, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0206, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1482, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6034.07MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 72.8753, min: -77.1780\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 145:\n",
      "  Allocated: 1719.82MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1735.82MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0238, min: -6.8688\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5758, min: -6.4599\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5895.99MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5847.99MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0238, min: -6.8688\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5758, min: -6.4599\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8064, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3841, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9063, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6034.64MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 62.6148, min: -60.1209\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 146:\n",
      "  Allocated: 1716.16MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.16MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3284, min: -7.4371\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7102, min: -6.2728\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.76MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.33MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3284, min: -7.4371\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7102, min: -6.2728\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1727, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7193, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8857, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.41MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 112.5344, min: -112.5436\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 147:\n",
      "  Allocated: 1716.19MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.19MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8693, min: -7.3649\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1260, min: -5.5931\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.97MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5829.97MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8693, min: -7.3649\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1260, min: -5.5931\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8696, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0746, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0416, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.34MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.5759, min: -92.8200\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 148:\n",
      "  Allocated: 1715.35MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.35MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7213, min: -7.9440\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6110, min: -6.2954\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.81MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.81MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7213, min: -7.9440\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6110, min: -6.2954\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0208, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2762, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8473, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.46MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 67.8386, min: -68.5331\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 149:\n",
      "  Allocated: 1715.40MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.40MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1431, min: -7.8274\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4813, min: -6.4215\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5876.43MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5828.43MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1431, min: -7.8274\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4813, min: -6.4215\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5857, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6365, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9020, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6016.43MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.0016, min: -83.9783\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 150:\n",
      "  Allocated: 1719.13MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1735.13MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8297, min: -6.9011\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2886, min: -6.3286\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.74MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.74MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8297, min: -6.9011\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2886, min: -6.3286\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8363, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5280, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2904, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.11MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 80.2574, min: -82.3936\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 151:\n",
      "  Allocated: 1715.66MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.67MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1968, min: -7.1587\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7874, min: -7.5040\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.78MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.35MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1968, min: -7.1587\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7874, min: -7.5040\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2263, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9088, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6202, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.43MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.7851, min: -79.7523\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 152:\n",
      "  Allocated: 1717.52MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.52MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0468, min: -7.3264\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1728, min: -6.1266\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.54MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.54MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0468, min: -7.3264\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1728, min: -6.1266\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4806, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9252, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0096, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.91MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.2662, min: -86.1324\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 153:\n",
      "  Allocated: 1716.75MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.75MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1285, min: -7.5548\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1650, min: -6.4114\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.74MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.74MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1285, min: -7.5548\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1650, min: -6.4114\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0765, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4893, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0375, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.39MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.7616, min: -79.0019\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 154:\n",
      "  Allocated: 1718.30MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.30MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2617, min: -7.8826\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3316, min: -6.7871\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.62MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.62MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2617, min: -7.8826\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3316, min: -6.7871\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8653, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2673, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2140, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.27MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.4985, min: -82.6470\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 155:\n",
      "  Allocated: 1713.81MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.81MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6281, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1378, min: -7.8526\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7829, min: -6.0922\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.33MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.33MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1378, min: -7.8526\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7829, min: -6.0922\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6182, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9179, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4483, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.98MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.9208, min: -88.9039\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 156:\n",
      "  Allocated: 1716.11MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.11MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9010, min: -6.6771\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6699, min: -5.5288\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.38MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.38MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9010, min: -6.6771\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6699, min: -5.5288\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3137, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3091, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1300, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.03MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 113.9181, min: -114.2810\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 157:\n",
      "  Allocated: 1715.33MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.33MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0662, min: -7.3629\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9173, min: -5.8117\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.92MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.92MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0662, min: -7.3629\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9173, min: -5.8117\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6153, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2858, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0131, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.43MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.1036, min: -87.3157\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 158:\n",
      "  Allocated: 1713.66MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.67MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.0357\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5626, min: -6.7634\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6312, min: -5.8253\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.66MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.23MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5626, min: -6.7634\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6312, min: -5.8253\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2517, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7059, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3813, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.31MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 80.2856, min: -78.8638\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 159:\n",
      "  Allocated: 1717.22MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.23MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0518, min: -7.5657\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5619, min: -6.5360\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.17MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.17MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0518, min: -7.5657\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5619, min: -6.5360\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7141, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7097, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1842, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.81MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.7183, min: -98.7479\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 160:\n",
      "  Allocated: 1713.43MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.43MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7972, min: -7.6702\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8069, min: -6.5346\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.18MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.18MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7972, min: -7.6702\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8069, min: -6.5346\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1745, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 3.9320, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9303, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.55MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.1200, min: -103.1026\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 161:\n",
      "  Allocated: 1714.18MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.18MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2078, min: -7.6666\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6670, min: -6.9513\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.36MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.36MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2078, min: -7.6666\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6670, min: -6.9513\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7648, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3905, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0883, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.00MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 77.4783, min: -79.6010\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 162:\n",
      "  Allocated: 1714.79MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.79MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8478, min: -7.4466\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9466, min: -6.5133\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.92MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5830.92MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8478, min: -7.4466\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9466, min: -6.5133\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3002, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6963, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5876, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.57MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.2858, min: -82.4994\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 163:\n",
      "  Allocated: 1715.09MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.09MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7995, min: -7.8429\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4281, min: -5.8786\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.89MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.89MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7995, min: -7.8429\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4281, min: -5.8786\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6890, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7733, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8509, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.54MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.5056, min: -89.9291\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 164:\n",
      "  Allocated: 1717.23MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.24MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1042, min: -6.7464\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4222, min: -6.1359\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.50MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.50MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1042, min: -6.7464\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4222, min: -6.1359\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9355, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8656, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.0504, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.15MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.5023, min: -87.9760\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 165:\n",
      "  Allocated: 1714.82MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.82MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2782, min: -7.0070\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9490, min: -6.2300\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.25MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.25MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2782, min: -7.0070\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9490, min: -6.2300\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9470, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8946, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5293, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.61MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.8303, min: -78.3492\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 166:\n",
      "  Allocated: 1716.76MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.76MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8662, min: -7.6715\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5974, min: -6.7556\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.96MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.96MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8662, min: -7.6715\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5974, min: -6.7556\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7417, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1145, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2166, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.61MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.9824, min: -82.6559\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 167:\n",
      "  Allocated: 1713.76MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.76MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0187, min: -8.1068\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0259, min: -6.5505\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.73MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.73MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0187, min: -8.1068\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0259, min: -6.5505\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9230, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4759, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7997, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.09MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 96.2762, min: -93.3418\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 168:\n",
      "  Allocated: 1717.89MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.89MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8378, min: -8.8897\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6933, min: -6.4855\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5894.37MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.37MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8378, min: -8.8897\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6933, min: -6.4855\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3968, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4632, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2052, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6033.02MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 73.3652, min: -74.6310\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 169:\n",
      "  Allocated: 1715.39MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.39MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1162\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7532, min: -6.5047\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0253, min: -6.4378\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.42MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.42MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7532, min: -6.5047\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0253, min: -6.4378\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4571, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3343, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6795, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6033.93MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.25MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.8475, min: -86.2369\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 170:\n",
      "  Allocated: 1715.09MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.09MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6187, min: -7.6285\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2341, min: -6.1889\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.39MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.96MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6187, min: -7.6285\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2341, min: -6.1889\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5543, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4384, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1580, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.76MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.8923, min: -83.1437\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 171:\n",
      "  Allocated: 1717.10MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.10MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7189, min: -7.4410\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4555, min: -7.7099\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.25MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.25MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7189, min: -7.4410\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4555, min: -7.7099\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9821, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7227, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5455, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.90MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.5275, min: -86.4724\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 172:\n",
      "  Allocated: 1715.87MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.87MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7000, min: -6.8216\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8186, min: -6.7863\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.36MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.36MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7000, min: -6.8216\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8186, min: -6.7863\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9751, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6022, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6398, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.01MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.3934, min: -80.1362\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 173:\n",
      "  Allocated: 1715.44MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.44MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6287, min: -7.0534\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5985, min: -7.2845\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.18MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.75MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6287, min: -7.0534\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5985, min: -7.2845\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0673, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6802, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4575, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.55MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 102.2937, min: -103.2802\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 174:\n",
      "  Allocated: 1713.74MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.74MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4744, min: -8.1045\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5501, min: -6.1092\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.72MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.72MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4744, min: -8.1045\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5501, min: -6.1092\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6415, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3604, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0572, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.23MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 104.7522, min: -95.6158\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 175:\n",
      "  Allocated: 1718.38MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.38MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6388, min: -7.5938\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0658, min: -6.3981\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.99MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.99MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6388, min: -7.5938\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0658, min: -6.3981\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1245, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5089, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1071, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6033.36MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.4277, min: -91.3175\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 176:\n",
      "  Allocated: 1716.11MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.11MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5579, min: -7.8819\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9821, min: -6.3119\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.40MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.40MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5579, min: -7.8819\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9821, min: -6.3119\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8045, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3936, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8784, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.05MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.3801, min: -95.0830\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 177:\n",
      "  Allocated: 1717.62MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.62MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6976, min: -6.7681\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5165, min: -6.1847\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5895.98MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5847.55MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6976, min: -6.7681\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5165, min: -6.1847\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1232, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2344, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0016, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6035.49MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.8185, min: -82.0090\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 178:\n",
      "  Allocated: 1714.83MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.83MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8037, min: -7.5677\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1084, min: -6.1897\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.84MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.84MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8037, min: -7.5677\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1084, min: -6.1897\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9925, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7442, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3608, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.35MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.1639, min: -84.3243\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 179:\n",
      "  Allocated: 1716.83MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.83MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6499, min: -6.7914\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0501, min: -5.9605\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.54MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.54MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6499, min: -6.7914\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0501, min: -5.9605\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9337, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 3.9041, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5904, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.91MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 75.4867, min: -76.3253\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 180:\n",
      "  Allocated: 1716.48MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.48MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4966, min: -6.9235\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4510, min: -6.6075\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.65MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.65MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4966, min: -6.9235\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4510, min: -6.6075\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6577, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3822, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1513, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.83MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.3247, min: -88.5517\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 181:\n",
      "  Allocated: 1715.49MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.49MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2110, min: -6.6788\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7359, min: -6.7596\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.95MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.95MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2110, min: -6.6788\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7359, min: -6.7596\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8010, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2912, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3286, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.60MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 88.4349, min: -84.6274\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 182:\n",
      "  Allocated: 1714.19MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.19MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9872, min: -7.9516\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9094, min: -6.5126\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.52MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.52MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9872, min: -7.9516\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9094, min: -6.5126\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9738, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0774, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1779, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.89MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.6708, min: -86.8046\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 183:\n",
      "  Allocated: 1714.59MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.59MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8846, min: -7.0469\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7668, min: -6.5482\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.08MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.65MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8846, min: -7.0469\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7668, min: -6.5482\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3535, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2064, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3994, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.73MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.3259, min: -86.7396\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 184:\n",
      "  Allocated: 1716.47MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.47MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0229, min: -6.6738\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0095, min: -7.3381\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.07MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.07MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0229, min: -6.6738\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0095, min: -7.3381\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3360, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9902, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1986, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.44MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.4261, min: -77.4634\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 185:\n",
      "  Allocated: 1715.95MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.95MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9729, min: -6.8287\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6198, min: -6.0495\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.75MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.75MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9729, min: -6.8287\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6198, min: -6.0495\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0617, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9223, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8346, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.40MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.7891, min: -79.6426\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 186:\n",
      "  Allocated: 1717.54MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.54MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0914, min: -7.9277\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7001, min: -6.2374\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.78MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.78MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0914, min: -7.9277\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7001, min: -6.2374\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9579, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1448, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7837, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.43MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 80.8129, min: -78.9815\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 187:\n",
      "  Allocated: 1716.62MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.62MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.2649, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4302, min: -8.1883\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9250, min: -6.6326\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.95MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.95MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4302, min: -8.1883\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9250, min: -6.6326\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2910, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3929, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0823, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.60MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.4071, min: -99.2707\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 188:\n",
      "  Allocated: 1717.38MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.38MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0894, min: -7.8757\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9538, min: -6.0041\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.36MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.36MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0894, min: -7.8757\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9538, min: -6.0041\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0871, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9974, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7865, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.01MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.0785, min: -91.1554\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 189:\n",
      "  Allocated: 1716.07MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.07MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2438, min: -7.2136\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6951, min: -6.3353\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.11MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.11MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2438, min: -7.2136\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6951, min: -6.3353\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9942, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3974, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9257, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.47MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 52.1345, min: -51.0821\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 190:\n",
      "  Allocated: 1713.76MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.76MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1523, min: -7.8471\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8959, min: -7.0362\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.21MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.21MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1523, min: -7.8471\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8959, min: -7.0362\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2430, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3026, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8928, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.86MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 100.6877, min: -98.7769\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 191:\n",
      "  Allocated: 1716.11MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.11MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6795, min: -7.0572\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4709, min: -6.3268\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.20MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.20MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6795, min: -7.0572\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4709, min: -6.3268\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8092, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1126, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0927, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.85MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 96.5091, min: -100.1021\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 192:\n",
      "  Allocated: 1716.29MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.29MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1084, min: -7.3358\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9808, min: -6.8399\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.80MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.80MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1084, min: -7.3358\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9808, min: -6.8399\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0761, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9966, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1482, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.45MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 113.4812, min: -111.9923\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 193:\n",
      "  Allocated: 1716.05MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.05MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4643, min: -7.5958\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9274, min: -6.0813\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.05MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.05MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4643, min: -7.5958\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9274, min: -6.0813\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6976, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5811, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6919, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.70MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.7894, min: -82.0090\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 194:\n",
      "  Allocated: 1718.24MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.24MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9779, min: -7.7144\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5602, min: -6.5759\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.69MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.69MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9779, min: -7.7144\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5602, min: -6.5759\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8756, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3960, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7316, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.34MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 107.0275, min: -93.0623\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 195:\n",
      "  Allocated: 1714.76MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.76MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2137, min: -8.1683\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7926, min: -6.5847\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.08MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.08MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2137, min: -8.1683\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7926, min: -6.5847\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6774, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4342, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9789, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.73MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 107.1485, min: -104.0984\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 196:\n",
      "  Allocated: 1714.01MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.01MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9495, min: -7.7173\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6807, min: -5.8990\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.25MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.25MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9495, min: -7.7173\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6807, min: -5.8990\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3249, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 3.9729, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3286, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.76MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.6040, min: -90.9979\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 197:\n",
      "  Allocated: 1714.88MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.88MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1506, min: -7.1086\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9015, min: -5.9348\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.60MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.60MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1506, min: -7.1086\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9015, min: -5.9348\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3813, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0153, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0774, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.11MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 69.7282, min: -65.6001\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 198:\n",
      "  Allocated: 1715.26MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.26MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0383, min: -7.2211\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0111, min: -5.8829\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.54MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.54MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0383, min: -7.2211\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0111, min: -5.8829\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3031, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6259, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.3167, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.05MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 104.6578, min: -103.5682\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 199:\n",
      "  Allocated: 1714.73MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.73MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9207, min: -7.5403\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9032, min: -6.4464\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.43MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.43MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9207, min: -7.5403\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9032, min: -6.4464\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3962, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4029, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0283, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.08MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.0781, min: -89.3401\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 200:\n",
      "  Allocated: 1715.59MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.59MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9345, min: -8.1016\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6083, min: -5.8150\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.20MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.20MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9345, min: -8.1016\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6083, min: -5.8150\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1034, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3831, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0064, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.56MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 77.0349, min: -77.3106\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 201:\n",
      "  Allocated: 1715.91MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.91MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6879, min: -7.4176\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6887, min: -6.6312\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.42MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.42MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6879, min: -7.4176\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6887, min: -6.6312\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1709, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5361, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.0448, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.93MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.7141, min: -91.0375\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 202:\n",
      "  Allocated: 1714.81MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.81MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8816, min: -7.3018\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3048, min: -6.6791\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.95MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.95MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8816, min: -7.3018\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3048, min: -6.6791\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4710, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6033, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7030, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.60MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 88.7199, min: -83.3238\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 203:\n",
      "  Allocated: 1714.81MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.81MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7905, min: -7.2413\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4771, min: -6.5725\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.62MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.62MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7905, min: -7.2413\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4771, min: -6.5725\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5942, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4072, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6259, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.13MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.9543, min: -82.7364\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 204:\n",
      "  Allocated: 1716.25MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.26MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3593, min: -7.9195\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0639, min: -6.2504\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.11MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.11MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3593, min: -7.9195\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0639, min: -6.2504\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4028, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0659, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9151, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.76MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.3115, min: -83.2201\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 205:\n",
      "  Allocated: 1714.38MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.38MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8240, min: -7.3803\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1345, min: -6.0594\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.95MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.95MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8240, min: -7.3803\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1345, min: -6.0594\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8236, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2415, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8358, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.46MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.6021, min: -96.2352\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 206:\n",
      "  Allocated: 1715.44MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.44MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4716, min: -6.9418\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6923, min: -6.6282\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.76MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.76MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4716, min: -6.9418\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6923, min: -6.6282\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4401, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9465, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.4906, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.12MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 87.1339, min: -76.8481\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 207:\n",
      "  Allocated: 1715.87MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.87MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6893, min: -6.5338\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1916, min: -5.8990\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.31MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.31MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6893, min: -6.5338\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1916, min: -5.8990\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1922, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4599, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3559, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.67MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 95.4637, min: -96.3478\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 208:\n",
      "  Allocated: 1715.31MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.31MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5070, min: -6.8889\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3754, min: -6.4376\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.06MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.06MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5070, min: -6.8889\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3754, min: -6.4376\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4178, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2013, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.5072, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.71MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.6903, min: -90.3479\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 209:\n",
      "  Allocated: 1719.03MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1735.03MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8461, min: -7.9497\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1056, min: -6.4110\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.20MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.20MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8461, min: -7.9497\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1056, min: -6.4110\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5701, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1235, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8974, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.57MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.4077, min: -80.2657\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 210:\n",
      "  Allocated: 1714.44MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.44MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7877, min: -7.7387\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2941, min: -6.1448\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.43MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.43MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7877, min: -7.7387\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2941, min: -6.1448\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7620, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7962, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0749, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.08MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.9241, min: -84.6810\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 211:\n",
      "  Allocated: 1713.25MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.25MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6270, min: -7.4559\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3077, min: -6.3456\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.14MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5830.14MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6270, min: -7.4559\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3077, min: -6.3456\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4288, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0198, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2815, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.79MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.6735, min: -99.0167\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 212:\n",
      "  Allocated: 1713.90MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.90MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4940, min: -7.3462\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9716, min: -6.7188\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.03MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5830.03MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4940, min: -7.3462\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9716, min: -6.7188\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1414, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7484, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9044, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6016.68MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.9171, min: -83.2050\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 213:\n",
      "  Allocated: 1715.39MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.39MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0613, min: -7.7763\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8661, min: -6.8789\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.80MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.80MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0613, min: -7.7763\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8661, min: -6.8789\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4642, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7667, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1534, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.45MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.2601, min: -85.9845\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 214:\n",
      "  Allocated: 1713.39MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.39MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8138, min: -6.9941\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1395, min: -6.6824\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.45MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5829.45MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8138, min: -6.9941\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1395, min: -6.6824\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7656, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8007, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5186, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6016.10MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.1884, min: -83.0821\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 215:\n",
      "  Allocated: 1713.20MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.20MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8115, min: -7.4243\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7406, min: -6.2656\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.05MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.05MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8115, min: -7.4243\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7406, min: -6.2656\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6617, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5890, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0251, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.70MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.9167, min: -98.2048\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 216:\n",
      "  Allocated: 1716.71MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.71MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4024, min: -7.3393\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6613, min: -6.2677\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.12MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.12MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4024, min: -7.3393\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6613, min: -6.2677\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3982, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4426, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6544, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.49MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.3287, min: -89.6108\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 217:\n",
      "  Allocated: 1714.88MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.88MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7060, min: -7.4169\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7553, min: -6.1000\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.75MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.75MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7060, min: -7.4169\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7553, min: -6.1000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2255, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5037, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6814, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.40MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 87.2328, min: -91.6172\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 218:\n",
      "  Allocated: 1713.77MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.77MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7392, min: -7.9927\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4412, min: -6.6249\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.23MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.23MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7392, min: -7.9927\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4412, min: -6.6249\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8643, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9745, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3456, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.88MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 59.2684, min: -62.7510\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 219:\n",
      "  Allocated: 1715.25MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.25MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6753, min: -7.5364\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6238, min: -6.1148\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.18MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.18MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6753, min: -7.5364\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6238, min: -6.1148\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4757, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3208, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1445, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.83MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.9444, min: -90.6534\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 220:\n",
      "  Allocated: 1715.86MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.86MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.8265, min: -6.9270\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7041, min: -5.7756\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.23MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.23MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.8265, min: -6.9270\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7041, min: -5.7756\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9909, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4633, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0633, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.60MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 108.4759, min: -109.6398\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 221:\n",
      "  Allocated: 1712.72MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1728.72MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6251, min: -7.1361\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7210, min: -6.7628\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.68MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.68MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6251, min: -7.1361\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7210, min: -6.7628\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5301, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9230, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7587, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.33MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 96.5479, min: -90.2570\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 222:\n",
      "  Allocated: 1712.90MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1728.90MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.0834\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0122, min: -8.0986\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7712, min: -6.7705\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.79MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.79MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0122, min: -8.0986\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7712, min: -6.7705\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2803, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7160, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4075, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.44MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.7129, min: -95.5839\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 223:\n",
      "  Allocated: 1717.34MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.34MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8883, min: -8.4248\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9817, min: -6.1979\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.26MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.26MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8883, min: -8.4248\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9817, min: -6.1979\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8788, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4988, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8162, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.91MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 72.1645, min: -74.6991\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 224:\n",
      "  Allocated: 1715.69MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.69MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2473, min: -6.9464\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6261, min: -6.8188\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.84MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.41MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2473, min: -6.9464\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6261, min: -6.8188\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3268, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1864, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4817, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.49MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 102.2124, min: -101.4033\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 225:\n",
      "  Allocated: 1714.97MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.97MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8328, min: -6.5257\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6938, min: -7.2432\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.49MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.49MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8328, min: -6.5257\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6938, min: -7.2432\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1901, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0010, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2131, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.00MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.5614, min: -85.6515\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 226:\n",
      "  Allocated: 1716.29MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.29MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0546, min: -7.2614\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6369, min: -6.4517\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.87MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.87MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0546, min: -7.2614\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6369, min: -6.4517\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4869, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8572, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5205, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.52MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 76.2270, min: -68.7941\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 227:\n",
      "  Allocated: 1713.19MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.19MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9265, min: -7.0877\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5502, min: -7.8199\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.28MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.28MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9265, min: -7.0877\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5502, min: -7.8199\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9232, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7851, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4297, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.79MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 75.5617, min: -76.4068\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 228:\n",
      "  Allocated: 1714.54MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.54MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7187, min: -6.9008\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8554, min: -6.0625\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.92MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.49MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7187, min: -6.9008\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8554, min: -6.0625\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9833, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7978, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0249, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.29MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 108.8724, min: -96.7697\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 229:\n",
      "  Allocated: 1717.66MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.67MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9022, min: -7.6628\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7426, min: -5.4517\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.98MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.98MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9022, min: -7.6628\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7426, min: -5.4517\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0509, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2878, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5385, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.63MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.8091, min: -86.7257\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 230:\n",
      "  Allocated: 1716.06MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.06MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6624, min: -7.6172\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7081, min: -7.6682\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.51MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.51MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6624, min: -7.6172\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7081, min: -7.6682\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4395, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5242, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1563, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.88MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.7909, min: -90.2231\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 231:\n",
      "  Allocated: 1714.49MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.49MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8037, min: -7.0289\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4665, min: -6.0865\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.08MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.08MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8037, min: -7.0289\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4665, min: -6.0865\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0128, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 3.8504, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8620, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.73MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 76.2182, min: -74.4099\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 232:\n",
      "  Allocated: 1715.27MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.27MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6538, min: -7.1827\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4166, min: -6.3197\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.71MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.28MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6538, min: -7.1827\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4166, min: -6.3197\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2718, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2269, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3466, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.36MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.3558, min: -86.4855\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 233:\n",
      "  Allocated: 1716.51MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.51MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5528, min: -7.6042\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9141, min: -6.2254\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.55MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.55MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5528, min: -7.6042\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9141, min: -6.2254\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5028, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8074, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0703, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.20MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.9684, min: -82.2983\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 234:\n",
      "  Allocated: 1715.86MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.86MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2107, min: -7.5446\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8128, min: -6.6343\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.23MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.23MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2107, min: -7.5446\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8128, min: -6.6343\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2498, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.0858, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8098, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.60MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.6445, min: -80.2063\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 235:\n",
      "  Allocated: 1714.06MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.06MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6434, min: -7.5433\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9847, min: -6.2747\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.15MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5829.15MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6434, min: -7.5433\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9847, min: -6.2747\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4728, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4353, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8854, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.52MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 60.6085, min: -58.1538\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 236:\n",
      "  Allocated: 1716.65MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.65MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2401, min: -7.3902\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7860, min: -6.4124\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.10MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.10MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2401, min: -7.3902\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7860, min: -6.4124\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6297, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4488, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1078, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.61MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 70.2580, min: -81.1422\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 237:\n",
      "  Allocated: 1714.61MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.61MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9813, min: -7.7180\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5286, min: -5.9716\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.97MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.97MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9813, min: -7.7180\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5286, min: -5.9716\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6742, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8476, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2653, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.62MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 107.5313, min: -98.5505\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 238:\n",
      "  Allocated: 1716.52MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.52MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1284, min: -6.9163\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5109, min: -7.2207\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.29MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.29MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1284, min: -6.9163\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5109, min: -7.2207\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3751, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5805, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5622, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.94MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.3856, min: -85.1511\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 239:\n",
      "  Allocated: 1714.54MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.54MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6077, min: -6.7519\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4148, min: -6.2212\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.24MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.24MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6077, min: -6.7519\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4148, min: -6.2212\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1135, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0140, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3255, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.75MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 68.0072, min: -66.2506\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 240:\n",
      "  Allocated: 1714.31MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.31MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1242, min: -6.6223\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7502, min: -6.8188\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.37MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.37MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1242, min: -6.6223\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7502, min: -6.8188\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1894, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3005, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.5716, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.02MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.0144, min: -87.5770\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 241:\n",
      "  Allocated: 1713.96MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.96MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4666, min: -7.1227\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7699, min: -7.1483\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.53MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.53MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4666, min: -7.1227\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7699, min: -7.1483\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5651, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0877, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1015, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.18MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.9378, min: -83.9744\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 242:\n",
      "  Allocated: 1716.07MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.07MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6244, min: -7.4540\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7692, min: -6.6070\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.87MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.87MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6244, min: -7.4540\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7692, min: -6.6070\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0830, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3256, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3617, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.38MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.6236, min: -87.9319\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 243:\n",
      "  Allocated: 1714.44MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.44MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6526, min: -6.5617\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9108, min: -5.9697\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.34MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.34MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6526, min: -6.5617\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9108, min: -5.9697\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3034, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8913, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1651, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.71MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 102.4301, min: -95.0319\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 244:\n",
      "  Allocated: 1713.91MB\n",
      "  Cached: 8100.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.91MB\n",
      "  Cached: 8100.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0385, min: -7.9411\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3247, min: -7.9583\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.59MB\n",
      "  Cached: 8100.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5829.59MB\n",
      "  Cached: 8100.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0385, min: -7.9411\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3247, min: -7.9583\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2787, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5442, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4904, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6016.24MB\n",
      "  Cached: 8100.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.8865, min: -72.2487\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 245:\n",
      "  Allocated: 1715.16MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.16MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9955, min: -6.9649\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1183, min: -6.4665\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.02MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.02MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9955, min: -6.9649\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1183, min: -6.4665\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6747, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3647, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9736, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.52MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.6030, min: -90.2133\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 246:\n",
      "  Allocated: 1715.84MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.84MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1021\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7238, min: -7.7748\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7362, min: -5.8178\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.42MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.42MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7238, min: -7.7748\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7362, min: -5.8178\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1228, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2425, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9040, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.79MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 101.0342, min: -100.7983\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 247:\n",
      "  Allocated: 1714.91MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.91MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6359, min: -6.7700\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3260, min: -6.1663\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.57MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.57MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6359, min: -6.7700\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3260, min: -6.1663\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0512, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9188, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7553, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.94MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.3729, min: -82.5753\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 248:\n",
      "  Allocated: 1715.88MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.88MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.0312, min: -7.6609\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1956, min: -5.6270\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.11MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.11MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.0312, min: -7.6609\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1956, min: -5.6270\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5078, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8981, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9777, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.76MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.3032, min: -99.7378\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 249:\n",
      "  Allocated: 1715.73MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.73MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6723, min: -8.1276\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9087, min: -6.6963\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.70MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.70MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6723, min: -8.1276\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9087, min: -6.6963\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2507, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9417, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4678, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.35MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.4435, min: -89.9564\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 250:\n",
      "  Allocated: 1717.76MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.76MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9288, min: -7.5715\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1541, min: -5.4239\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.82MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.82MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9288, min: -7.5715\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1541, min: -5.4239\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3944, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1785, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8005, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.47MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.5696, min: -85.7012\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 251:\n",
      "  Allocated: 1717.03MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.03MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2915, min: -6.5763\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5950, min: -6.8455\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.83MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.83MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2915, min: -6.5763\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5950, min: -6.8455\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7717, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3789, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5623, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.48MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.6264, min: -86.6937\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 252:\n",
      "  Allocated: 1716.77MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.77MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4490, min: -7.8237\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0091, min: -6.3761\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.50MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.50MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4490, min: -7.8237\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0091, min: -6.3761\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5439, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9012, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0510, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.00MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.0562, min: -95.7421\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 253:\n",
      "  Allocated: 1715.81MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.81MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1081, min: -6.9775\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7073, min: -6.8590\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.11MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.11MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1081, min: -6.9775\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7073, min: -6.8590\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9720, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2431, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3090, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.48MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.8927, min: -92.6942\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 254:\n",
      "  Allocated: 1718.55MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.55MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.0673, min: -7.1541\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0710, min: -6.7081\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.16MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.16MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.0673, min: -7.1541\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0710, min: -6.7081\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3923, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4362, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6833, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.81MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 80.3832, min: -84.0603\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 255:\n",
      "  Allocated: 1716.05MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.05MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7141, min: -7.4865\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6645, min: -6.0320\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.22MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.22MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7141, min: -7.4865\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6645, min: -6.0320\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5566, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9276, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4169, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.87MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.5632, min: -92.9368\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 256:\n",
      "  Allocated: 1713.23MB\n",
      "  Cached: 8002.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.24MB\n",
      "  Cached: 8002.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6682, min: -6.7213\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6694, min: -6.3379\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.61MB\n",
      "  Cached: 8002.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.61MB\n",
      "  Cached: 8002.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6682, min: -6.7213\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6694, min: -6.3379\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5267, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0264, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9756, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.26MB\n",
      "  Cached: 8002.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 108.0636, min: -100.5252\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 257:\n",
      "  Allocated: 1715.36MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.36MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7505, min: -7.7902\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0116, min: -5.8291\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.99MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.99MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7505, min: -7.7902\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0116, min: -5.8291\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7209, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0882, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.3977, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.64MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 101.9599, min: -93.8623\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 258:\n",
      "  Allocated: 1716.47MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.47MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3880, min: -6.7005\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6552, min: -7.5274\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.47MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.47MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3880, min: -6.7005\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6552, min: -7.5274\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6180, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2932, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3370, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.84MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.2832, min: -92.2165\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 259:\n",
      "  Allocated: 1713.81MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.81MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9937, min: -8.1972\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2112, min: -6.2925\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.58MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.58MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9937, min: -8.1972\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2112, min: -6.2925\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5266, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8821, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1599, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.09MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 100.1133, min: -101.9373\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 260:\n",
      "  Allocated: 1714.90MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.90MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0793, min: -7.5189\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1781, min: -7.9492\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.61MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.61MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0793, min: -7.5189\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1781, min: -7.9492\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0406, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8360, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3201, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.98MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 111.0457, min: -113.6618\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 261:\n",
      "  Allocated: 1715.09MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.09MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7786, min: -6.9577\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4437, min: -6.3132\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.98MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.98MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7786, min: -6.9577\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4437, min: -6.3132\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4924, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6551, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5138, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.35MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 87.1786, min: -87.8913\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 262:\n",
      "  Allocated: 1717.55MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.55MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4682, min: -6.4982\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2175, min: -6.7272\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.58MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.58MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4682, min: -6.4982\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2175, min: -6.7272\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2260, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7418, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6905, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.23MB\n",
      "  Cached: 8082.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 100.9375, min: -98.9913\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 263:\n",
      "  Allocated: 1716.07MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.07MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7939, min: -8.0088\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0078, min: -5.6085\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.37MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.37MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7939, min: -8.0088\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0078, min: -5.6085\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5951, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5513, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4528, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.02MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.7577, min: -93.9366\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 264:\n",
      "  Allocated: 1715.19MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.19MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2412, min: -7.4492\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6216, min: -6.4152\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.91MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.91MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2412, min: -7.4492\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6216, min: -6.4152\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9466, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3727, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5379, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.56MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.1106, min: -91.2807\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 265:\n",
      "  Allocated: 1715.50MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.50MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6161, min: -7.7984\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6565, min: -8.1924\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.51MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.51MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6161, min: -7.7984\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6565, min: -8.1924\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2423, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7626, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9558, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.16MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.2391, min: -96.0270\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 266:\n",
      "  Allocated: 1716.38MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.38MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0203, min: -7.4118\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5123, min: -6.2747\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.53MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.10MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0203, min: -7.4118\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5123, min: -6.2747\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0114, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1502, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9433, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.18MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.3062, min: -93.0849\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 267:\n",
      "  Allocated: 1716.57MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.57MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6316, min: -2.1078\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6068, min: -7.4574\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8432, min: -6.0102\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.91MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.91MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6068, min: -7.4574\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8432, min: -6.0102\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7785, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4225, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6063, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.56MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.8620, min: -99.9657\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 268:\n",
      "  Allocated: 1716.24MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.24MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9832, min: -6.7508\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3431, min: -5.9183\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.56MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.56MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9832, min: -6.7508\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3431, min: -5.9183\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8827, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7621, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1266, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.21MB\n",
      "  Cached: 8050.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.6161, min: -90.7582\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 269:\n",
      "  Allocated: 1716.03MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.03MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8101, min: -7.3059\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7203, min: -6.7598\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.06MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.06MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8101, min: -7.3059\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7203, min: -6.7598\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5706, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9324, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8950, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.71MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.6852, min: -70.7250\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 270:\n",
      "  Allocated: 1716.04MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.04MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5887, min: -6.7636\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7041, min: -6.1083\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.98MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.98MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5887, min: -6.7636\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7041, min: -6.1083\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9468, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9333, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0481, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.63MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 53.4376, min: -51.7554\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 271:\n",
      "  Allocated: 1716.35MB\n",
      "  Cached: 8068.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.35MB\n",
      "  Cached: 8068.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1738, min: -7.3098\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8280, min: -6.1560\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.84MB\n",
      "  Cached: 8068.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.41MB\n",
      "  Cached: 8068.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1738, min: -7.3098\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8280, min: -6.1560\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6399, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9820, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.2396, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.21MB\n",
      "  Cached: 8068.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 95.0428, min: -95.7229\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 272:\n",
      "  Allocated: 1717.53MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.53MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8360, min: -7.3907\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3088, min: -6.2245\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.94MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.51MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8360, min: -7.3907\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3088, min: -6.2245\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3268, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4768, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 9.9754, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.45MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.8994, min: -85.9497\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 273:\n",
      "  Allocated: 1717.81MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.81MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1923, min: -7.4018\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5449, min: -6.0855\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.66MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.66MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1923, min: -7.4018\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5449, min: -6.0855\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4111, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2492, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2267, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.03MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.5325, min: -87.1098\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 274:\n",
      "  Allocated: 1716.23MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.24MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9035, min: -7.5531\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7759, min: -6.4768\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.10MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.10MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9035, min: -7.5531\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7759, min: -6.4768\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7727, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3627, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8920, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.75MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 57.2349, min: -58.4269\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 275:\n",
      "  Allocated: 1717.39MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.39MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0453, min: -7.7618\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5660, min: -6.3301\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.14MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.71MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0453, min: -7.7618\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5660, min: -6.3301\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4489, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7411, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2989, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.79MB\n",
      "  Cached: 8066.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.4955, min: -91.3079\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 276:\n",
      "  Allocated: 1717.82MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.82MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4445, min: -7.0553\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5772, min: -6.2558\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.55MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.55MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4445, min: -7.0553\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5772, min: -6.2558\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9889, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5544, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9316, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.19MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 95.4423, min: -91.5007\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 277:\n",
      "  Allocated: 1716.81MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.81MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0401, min: -8.3412\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3903, min: -6.2802\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.88MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.45MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0401, min: -8.3412\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3903, min: -6.2802\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2229, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1009, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6950, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.52MB\n",
      "  Cached: 8034.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.9724, min: -85.6596\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 278:\n",
      "  Allocated: 1714.96MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.96MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8934, min: -6.8586\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6917, min: -5.7427\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.22MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.22MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8934, min: -6.8586\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6917, min: -5.7427\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8253, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4038, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0922, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.87MB\n",
      "  Cached: 8018.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.1682, min: -91.2199\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 279:\n",
      "  Allocated: 1717.29MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.29MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0581, min: -7.4349\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0139, min: -7.4089\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.21MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.21MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0581, min: -7.4349\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0139, min: -7.4089\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5484, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4454, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0699, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.86MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 109.5587, min: -102.9022\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 280:\n",
      "  Allocated: 1716.43MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.43MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9495, min: -6.8884\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7459, min: -6.2054\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.58MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.58MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9495, min: -6.8884\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7459, min: -6.2054\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4768, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8038, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3496, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.23MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 106.2677, min: -103.0570\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 281:\n",
      "  Allocated: 1713.20MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.20MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1915, min: -8.2691\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2126, min: -5.1028\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.43MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.43MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1915, min: -8.2691\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2126, min: -5.1028\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9799, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2467, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2069, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.08MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.0762, min: -92.7285\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 282:\n",
      "  Allocated: 1716.53MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.53MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3255, min: -6.9309\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1816, min: -6.4234\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.35MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.35MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3255, min: -6.9309\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1816, min: -6.4234\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5305, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6364, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5815, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.00MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.6372, min: -95.3484\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 283:\n",
      "  Allocated: 1716.60MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.60MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5789, min: -7.1143\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8788, min: -6.8700\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.14MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.14MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5789, min: -7.1143\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8788, min: -6.8700\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6044, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2140, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1270, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.51MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 60.7010, min: -66.9400\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 284:\n",
      "  Allocated: 1715.25MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.25MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.0262\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0925, min: -7.1192\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5963, min: -6.3226\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.91MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5830.91MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0925, min: -7.1192\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5963, min: -6.3226\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2060, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7532, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0221, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.56MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.1126, min: -104.7277\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 285:\n",
      "  Allocated: 1717.68MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.69MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7438, min: -7.9587\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7651, min: -6.3475\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.57MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.57MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7438, min: -7.9587\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7651, min: -6.3475\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4498, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8304, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5713, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.22MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 76.2050, min: -78.1881\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 286:\n",
      "  Allocated: 1719.54MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1735.54MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0861, min: -7.7566\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9967, min: -6.5248\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.74MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.74MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0861, min: -7.7566\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9967, min: -6.5248\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1946, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8450, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5898, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.39MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 104.9002, min: -103.7088\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 287:\n",
      "  Allocated: 1715.73MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.73MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5543, min: -7.0445\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8826, min: -6.1894\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.42MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.99MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5543, min: -7.0445\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8826, min: -6.1894\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5934, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9808, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7641, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.07MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 74.6701, min: -70.2224\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 288:\n",
      "  Allocated: 1718.88MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.88MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5287, min: -6.6455\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4169, min: -7.5634\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.48MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.05MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5287, min: -6.6455\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4169, min: -7.5634\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7228, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4829, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1550, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.13MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 102.8684, min: -99.9615\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 289:\n",
      "  Allocated: 1720.42MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1736.42MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5269, min: -6.9302\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4897, min: -6.0725\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5896.09MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5847.66MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5269, min: -6.9302\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4897, min: -6.0725\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0419, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1703, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.3331, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6034.74MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 109.7565, min: -102.8023\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 290:\n",
      "  Allocated: 1714.47MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.47MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2935, min: -6.7942\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3164, min: -6.3898\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.20MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.20MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2935, min: -6.7942\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3164, min: -6.3898\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1414, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6463, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8391, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.84MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.8187, min: -104.4589\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 291:\n",
      "  Allocated: 1715.99MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.99MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2427, min: -6.9890\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2385, min: -5.4540\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.12MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.12MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2427, min: -6.9890\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2385, min: -5.4540\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9970, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8275, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 9.1630, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.48MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.2399, min: -86.9436\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 292:\n",
      "  Allocated: 1715.88MB\n",
      "  Cached: 8104.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.88MB\n",
      "  Cached: 8104.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6382, min: -8.5414\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4365, min: -5.7712\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.30MB\n",
      "  Cached: 8104.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.30MB\n",
      "  Cached: 8104.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6382, min: -8.5414\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4365, min: -5.7712\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6425, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3030, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1590, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.94MB\n",
      "  Cached: 8104.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.9403, min: -82.9014\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 293:\n",
      "  Allocated: 1716.94MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.94MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8818, min: -7.3809\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6783, min: -6.6038\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.55MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.55MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8818, min: -7.3809\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6783, min: -6.6038\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0892, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9050, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5199, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.20MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 80.2100, min: -80.1148\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 294:\n",
      "  Allocated: 1716.73MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.73MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7240, min: -7.5301\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8174, min: -6.5211\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.88MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.88MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7240, min: -7.5301\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8174, min: -6.5211\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2337, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6916, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4366, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.25MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 68.8031, min: -73.1077\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 295:\n",
      "  Allocated: 1715.98MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.98MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2674, min: -7.7622\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0417, min: -6.7965\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.44MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.44MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2674, min: -7.7622\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0417, min: -6.7965\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7011, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8642, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1375, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.95MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.0764, min: -79.6503\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 296:\n",
      "  Allocated: 1717.17MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.17MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2613, min: -8.4202\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8413, min: -5.7370\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.76MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.33MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2613, min: -8.4202\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8413, min: -5.7370\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6834, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6997, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1884, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.41MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.2051, min: -91.0455\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 297:\n",
      "  Allocated: 1715.30MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.30MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3910, min: -7.2824\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4654, min: -6.2973\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.91MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.48MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3910, min: -7.2824\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4654, min: -6.2973\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7496, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2786, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2304, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.56MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 105.9159, min: -107.3542\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 298:\n",
      "  Allocated: 1715.11MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.11MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1295, min: -7.8333\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5740, min: -6.2219\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.66MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.66MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1295, min: -7.8333\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5740, min: -6.2219\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5886, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0415, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7590, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.02MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.7224, min: -85.5145\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 299:\n",
      "  Allocated: 1716.15MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.15MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3910, min: -6.7235\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0148, min: -5.8891\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.12MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.12MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3910, min: -6.7235\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0148, min: -5.8891\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7286, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6919, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1419, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.77MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 101.2121, min: -100.5131\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 300:\n",
      "  Allocated: 1718.44MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.44MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4584, min: -7.0364\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7924, min: -6.8594\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.96MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.53MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4584, min: -7.0364\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7924, min: -6.8594\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3842, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5030, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.2092, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.61MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.9645, min: -95.3376\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 301:\n",
      "  Allocated: 1715.70MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.70MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5989, min: -7.3712\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9621, min: -6.7164\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.59MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.59MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5989, min: -7.3712\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9621, min: -6.7164\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1924, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7026, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6689, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.24MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 66.0241, min: -65.7950\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 302:\n",
      "  Allocated: 1715.07MB\n",
      "  Cached: 8008.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.07MB\n",
      "  Cached: 8008.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3585, min: -7.4556\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8435, min: -5.9824\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.73MB\n",
      "  Cached: 8008.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.73MB\n",
      "  Cached: 8008.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3585, min: -7.4556\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8435, min: -5.9824\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3185, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5343, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8313, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.37MB\n",
      "  Cached: 8008.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.2868, min: -89.8333\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 303:\n",
      "  Allocated: 1714.18MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.18MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1561, min: -8.3231\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5144, min: -6.7241\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.00MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.00MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1561, min: -8.3231\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5144, min: -6.7241\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7767, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1648, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5074, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.51MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.4628, min: -83.6222\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 304:\n",
      "  Allocated: 1714.66MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.67MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6884, min: -7.1003\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8130, min: -6.5706\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.55MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5830.55MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6884, min: -7.1003\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8130, min: -6.5706\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8625, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6752, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2930, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.20MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.6457, min: -90.7501\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 305:\n",
      "  Allocated: 1713.55MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.55MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4584, min: -7.0943\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8837, min: -6.6838\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.90MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.90MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4584, min: -7.0943\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8837, min: -6.6838\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7781, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5909, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6737, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.54MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.4876, min: -77.9760\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 306:\n",
      "  Allocated: 1717.90MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.90MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9038, min: -7.4531\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3804, min: -6.5333\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5895.11MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5847.11MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9038, min: -7.4531\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3804, min: -6.5333\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6808, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7650, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3260, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6033.76MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 101.8386, min: -97.2625\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 307:\n",
      "  Allocated: 1714.39MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.39MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0115, min: -7.3121\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6500, min: -6.2544\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.03MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.03MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0115, min: -7.3121\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6500, min: -6.2544\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6606, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5349, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2394, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.68MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 80.5536, min: -81.2902\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 308:\n",
      "  Allocated: 1716.63MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.63MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7678, min: -7.8072\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9273, min: -6.3365\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.59MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.59MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7678, min: -7.8072\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9273, min: -6.3365\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2944, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7052, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2860, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.77MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 63.2004, min: -66.5443\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 309:\n",
      "  Allocated: 1717.09MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.09MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2566, min: -6.8645\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3733, min: -6.7107\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.37MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.37MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2566, min: -6.8645\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3733, min: -6.7107\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1030, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0493, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6150, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.02MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 75.2128, min: -75.4869\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 310:\n",
      "  Allocated: 1715.83MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.83MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7308, min: -6.9983\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8729, min: -6.1027\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5894.61MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5846.61MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7308, min: -6.9983\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8729, min: -6.1027\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0927, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8164, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8636, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6033.26MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.8809, min: -96.3214\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 311:\n",
      "  Allocated: 1717.15MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.15MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6380, min: -2.0921\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4858, min: -7.4302\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0471, min: -5.9969\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.61MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.61MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4858, min: -7.4302\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0471, min: -5.9969\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1452, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2421, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6102, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.98MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.4095, min: -84.6475\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 312:\n",
      "  Allocated: 1714.85MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.85MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7123, min: -7.2958\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9390, min: -6.3612\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.12MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.12MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7123, min: -7.2958\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9390, min: -6.3612\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6324, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3182, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8728, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.48MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 76.7653, min: -83.0914\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 313:\n",
      "  Allocated: 1714.90MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.90MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1382, min: -7.3865\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6463, min: -7.0370\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.70MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.70MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1382, min: -7.3865\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6463, min: -7.0370\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9689, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7603, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0160, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.35MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 87.2436, min: -87.5658\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 314:\n",
      "  Allocated: 1712.95MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1728.95MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4122, min: -6.8691\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7731, min: -5.6498\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.10MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5830.10MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4122, min: -6.8691\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7731, min: -5.6498\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1594, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7863, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3356, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.61MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 87.6352, min: -88.5387\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 315:\n",
      "  Allocated: 1718.71MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.71MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6343, min: -6.9424\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2370, min: -6.2032\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.38MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.38MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6343, min: -6.9424\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2370, min: -6.2032\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3611, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0171, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0756, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.03MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.0425, min: -81.2395\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 316:\n",
      "  Allocated: 1716.88MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.88MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6180, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8279, min: -7.8356\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0707, min: -5.0957\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.61MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5829.61MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8279, min: -7.8356\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0707, min: -5.0957\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8684, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8327, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1126, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.98MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.8962, min: -94.2572\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 317:\n",
      "  Allocated: 1717.11MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.11MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2296, min: -7.2328\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3815, min: -6.3787\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.22MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.22MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2296, min: -7.2328\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3815, min: -6.3787\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8761, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3148, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0258, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.87MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.3114, min: -80.1982\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 318:\n",
      "  Allocated: 1719.04MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1735.04MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7162, min: -7.7949\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8858, min: -6.5789\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.90MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.90MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7162, min: -7.7949\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8858, min: -6.5789\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2277, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7344, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0746, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.55MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.4251, min: -100.6967\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 319:\n",
      "  Allocated: 1716.74MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.74MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1001, min: -8.3073\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9744, min: -5.5376\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.98MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.98MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1001, min: -8.3073\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9744, min: -5.5376\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7291, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8273, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4721, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.63MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 105.5524, min: -100.0599\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 320:\n",
      "  Allocated: 1716.49MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.49MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1694, min: -6.8850\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9338, min: -6.5351\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.36MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.36MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1694, min: -6.8850\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9338, min: -6.5351\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4203, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7374, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7881, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.01MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 78.6389, min: -78.0315\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 321:\n",
      "  Allocated: 1714.84MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.84MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8185, min: -8.2376\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1612, min: -6.8869\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5876.44MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5828.44MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8185, min: -8.2376\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1612, min: -6.8869\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0684, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0403, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6387, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6015.94MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 116.1806, min: -115.1147\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 322:\n",
      "  Allocated: 1716.65MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.65MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8225, min: -7.6344\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5897, min: -6.6288\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.95MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.95MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8225, min: -7.6344\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5897, min: -6.6288\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3036, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8876, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9203, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.60MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.6413, min: -102.0407\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 323:\n",
      "  Allocated: 1716.76MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.76MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6412, min: -6.5998\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7167, min: -6.0340\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.92MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.92MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6412, min: -6.5998\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7167, min: -6.0340\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1460, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7020, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1697, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.57MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 88.0307, min: -90.4024\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 324:\n",
      "  Allocated: 1715.11MB\n",
      "  Cached: 8102.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.11MB\n",
      "  Cached: 8102.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7178, min: -9.1085\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8139, min: -6.7813\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.84MB\n",
      "  Cached: 8102.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.84MB\n",
      "  Cached: 8102.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7178, min: -9.1085\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8139, min: -6.7813\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1328, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0511, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5726, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.49MB\n",
      "  Cached: 8102.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 115.1894, min: -117.4758\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 325:\n",
      "  Allocated: 1713.58MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.58MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8515, min: -7.2203\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6457, min: -6.6020\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.70MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.70MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8515, min: -7.2203\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6457, min: -6.6020\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2750, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6340, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0683, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.06MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.4481, min: -96.7971\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 326:\n",
      "  Allocated: 1715.82MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.82MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7595, min: -7.0456\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4626, min: -6.3102\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.53MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.10MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7595, min: -7.0456\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4626, min: -6.3102\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0254, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5605, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5655, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.18MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.7626, min: -81.9569\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 327:\n",
      "  Allocated: 1714.76MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.76MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0093, min: -7.2537\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5964, min: -6.5971\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.18MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5828.18MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0093, min: -7.2537\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5964, min: -6.5971\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9694, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6300, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6781, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.55MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.3900, min: -94.4501\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 328:\n",
      "  Allocated: 1714.44MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.44MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0884, min: -7.0405\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9644, min: -6.5790\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.51MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.51MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0884, min: -7.0405\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9644, min: -6.5790\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4790, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0708, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9976, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.16MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.9267, min: -82.1510\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 329:\n",
      "  Allocated: 1715.72MB\n",
      "  Cached: 8006.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.72MB\n",
      "  Cached: 8006.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6237, min: -7.6083\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5035, min: -5.6978\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.06MB\n",
      "  Cached: 8006.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.06MB\n",
      "  Cached: 8006.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6237, min: -7.6083\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5035, min: -5.6978\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5766, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7546, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8459, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.71MB\n",
      "  Cached: 8006.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.7663, min: -78.1800\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 330:\n",
      "  Allocated: 1713.30MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.30MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8035, min: -6.5661\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4611, min: -6.4954\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.55MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.55MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8035, min: -6.5661\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4611, min: -6.4954\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5335, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2121, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0559, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.92MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.4800, min: -84.7566\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 331:\n",
      "  Allocated: 1713.47MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.47MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9112, min: -6.7306\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0223, min: -6.3710\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.64MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5830.64MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9112, min: -6.7306\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0223, min: -6.3710\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5506, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6109, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0062, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.15MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 80.7330, min: -75.2478\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 332:\n",
      "  Allocated: 1714.95MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.95MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6896, min: -7.2978\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8552, min: -6.5649\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.37MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.94MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6896, min: -7.2978\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8552, min: -6.5649\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0790, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2594, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8815, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.02MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.6527, min: -87.4771\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 333:\n",
      "  Allocated: 1713.97MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.97MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1671, min: -7.3084\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9254, min: -6.3766\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.14MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5829.14MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1671, min: -7.3084\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9254, min: -6.3766\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6001, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6962, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9479, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.32MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 106.0984, min: -108.0731\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 334:\n",
      "  Allocated: 1715.75MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.75MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1706, min: -7.7360\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2792, min: -6.0117\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.86MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5829.86MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1706, min: -7.7360\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2792, min: -6.0117\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4339, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6342, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.7105, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6016.51MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.9384, min: -92.5564\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 335:\n",
      "  Allocated: 1717.41MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.41MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9672, min: -7.2261\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8660, min: -5.8343\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5894.58MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5846.58MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9672, min: -7.2261\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8660, min: -5.8343\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9976, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5081, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9682, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6034.09MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 63.9181, min: -64.3152\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 336:\n",
      "  Allocated: 1716.43MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.43MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7944, min: -7.1876\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9313, min: -6.0995\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.04MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.61MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7944, min: -7.1876\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9313, min: -6.0995\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3217, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3363, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6028, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.68MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.9364, min: -87.7286\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 337:\n",
      "  Allocated: 1717.04MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.04MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4256, min: -7.6827\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1867, min: -6.0044\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.31MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.88MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4256, min: -7.6827\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1867, min: -6.0044\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7986, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5506, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3179, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.96MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.2574, min: -92.7537\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 338:\n",
      "  Allocated: 1717.16MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.16MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0827, min: -7.9661\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6951, min: -6.5592\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.34MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.34MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0827, min: -7.9661\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6951, min: -6.5592\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1702, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9817, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0054, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.99MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 68.3353, min: -70.6209\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 339:\n",
      "  Allocated: 1718.88MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.88MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4723, min: -7.4389\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5131, min: -6.0142\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.50MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.07MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4723, min: -7.4389\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5131, min: -6.0142\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4903, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9347, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 9.4002, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.87MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.5982, min: -85.9630\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 340:\n",
      "  Allocated: 1717.44MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.44MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9242, min: -7.8506\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8087, min: -5.8652\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.17MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.17MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9242, min: -7.8506\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8087, min: -5.8652\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5386, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1820, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4074, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.82MB\n",
      "  Cached: 8024.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 109.3461, min: -104.1440\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 341:\n",
      "  Allocated: 1717.21MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.21MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5726, min: -7.9027\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6467, min: -6.5738\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.41MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.41MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5726, min: -7.9027\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6467, min: -6.5738\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4996, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1771, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2442, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.06MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.8538, min: -72.2099\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 342:\n",
      "  Allocated: 1715.47MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.47MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5594, min: -8.2384\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2368, min: -5.8668\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.96MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.96MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5594, min: -8.2384\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2368, min: -5.8668\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2859, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6548, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0147, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.47MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 105.0389, min: -94.7341\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 343:\n",
      "  Allocated: 1713.82MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.82MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0448, min: -6.9082\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3936, min: -6.2717\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.11MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.11MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0448, min: -6.9082\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3936, min: -6.2717\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3734, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8596, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.9400, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.76MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 105.3647, min: -107.9924\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 344:\n",
      "  Allocated: 1715.48MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.48MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6105, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3316, min: -7.4329\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6367, min: -7.3154\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.25MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.25MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3316, min: -7.4329\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6367, min: -7.3154\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0291, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5843, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9692, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.90MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 96.3564, min: -95.5633\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 345:\n",
      "  Allocated: 1714.75MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.75MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0870, min: -6.6204\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6030, min: -5.8646\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.24MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.24MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0870, min: -6.6204\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6030, min: -5.8646\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5775, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6854, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4277, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.89MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 69.0280, min: -74.1604\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 346:\n",
      "  Allocated: 1717.09MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.09MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8359, min: -7.6288\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3281, min: -6.1561\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.57MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.57MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8359, min: -7.6288\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3281, min: -6.1561\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2186, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5320, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7335, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.22MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.9358, min: -89.7901\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 347:\n",
      "  Allocated: 1715.40MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.40MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4301, min: -7.7386\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5802, min: -6.0326\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.15MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.72MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4301, min: -7.7386\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5802, min: -6.0326\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3461, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1748, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6769, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.66MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.5788, min: -90.0187\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 348:\n",
      "  Allocated: 1716.43MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.43MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5711, min: -7.0499\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4575, min: -6.6364\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.42MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.99MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5711, min: -7.0499\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4575, min: -6.6364\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3349, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3401, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7786, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.06MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.2120, min: -92.8056\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 349:\n",
      "  Allocated: 1713.84MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.84MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5573, min: -7.0005\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8267, min: -6.1820\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.79MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.79MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5573, min: -7.0005\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8267, min: -6.1820\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4205, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6412, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3460, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.44MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 78.4577, min: -77.8248\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 350:\n",
      "  Allocated: 1714.43MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.43MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8371, min: -6.9258\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6824, min: -6.1331\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.58MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.58MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8371, min: -6.9258\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6824, min: -6.1331\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2855, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5743, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8888, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.23MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.8597, min: -92.5740\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 351:\n",
      "  Allocated: 1714.92MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.92MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9739, min: -6.8599\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7991, min: -6.5282\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.53MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.53MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9739, min: -6.8599\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7991, min: -6.5282\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2813, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7700, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6415, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.18MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 109.9250, min: -111.6676\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 352:\n",
      "  Allocated: 1716.75MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.75MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1142, min: -7.2688\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2305, min: -6.5590\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.54MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.54MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1142, min: -7.2688\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2305, min: -6.5590\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3305, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8197, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7070, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.91MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.9748, min: -87.6329\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 353:\n",
      "  Allocated: 1718.04MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.04MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5911, min: -7.9172\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7057, min: -6.3256\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.32MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.32MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5911, min: -7.9172\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7057, min: -6.3256\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3034, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.0820, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6047, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.97MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.7172, min: -85.9607\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 354:\n",
      "  Allocated: 1715.09MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.09MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8878, min: -6.6422\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8748, min: -5.8725\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.29MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.29MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8878, min: -6.6422\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8748, min: -5.8725\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6880, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3593, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0938, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.65MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.5264, min: -91.3248\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 355:\n",
      "  Allocated: 1719.39MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1735.39MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4940, min: -6.6571\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7754, min: -6.9402\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.97MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.54MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4940, min: -6.6571\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7754, min: -6.9402\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5784, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6167, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4925, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.61MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.5917, min: -86.1009\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 356:\n",
      "  Allocated: 1716.34MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.34MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8467, min: -7.7845\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6799, min: -6.7071\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.90MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.90MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8467, min: -7.7845\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6799, min: -6.7071\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2132, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3942, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2634, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.55MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 117.4873, min: -106.7711\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 357:\n",
      "  Allocated: 1715.18MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.18MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1519, min: -7.6997\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9100, min: -6.3670\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.23MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.23MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1519, min: -7.6997\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9100, min: -6.3670\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0887, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9315, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9281, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.88MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.9278, min: -84.8883\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 358:\n",
      "  Allocated: 1713.62MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.62MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4575, min: -7.4930\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4347, min: -6.5391\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.92MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.92MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4575, min: -7.4930\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4347, min: -6.5391\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4339, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8201, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7380, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.57MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 96.2983, min: -94.7146\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 359:\n",
      "  Allocated: 1714.18MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.18MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.7622, min: -8.0050\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4186, min: -5.6465\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.31MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.31MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.7622, min: -8.0050\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4186, min: -5.6465\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3668, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3877, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4893, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.82MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.1196, min: -90.8482\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 360:\n",
      "  Allocated: 1715.81MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.81MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6083, min: -7.8855\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6369, min: -6.1565\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.29MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.29MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6083, min: -7.8855\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6369, min: -6.1565\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0601, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3494, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2487, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.94MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 64.0191, min: -61.1789\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 361:\n",
      "  Allocated: 1718.53MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.53MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6493, min: -7.1698\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7127, min: -6.1027\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5895.40MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5847.40MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6493, min: -7.1698\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7127, min: -6.1027\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7178, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1353, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7321, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6034.05MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.5454, min: -84.1368\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 362:\n",
      "  Allocated: 1715.92MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.92MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6194, min: -6.5950\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8604, min: -6.9935\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.02MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.02MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6194, min: -6.5950\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8604, min: -6.9935\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2337, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2720, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1957, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.67MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.0025, min: -89.3156\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 363:\n",
      "  Allocated: 1717.35MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.35MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.6118, min: -6.6296\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3395, min: -6.7838\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.31MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.31MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.6118, min: -6.6296\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3395, min: -6.7838\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3445, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3172, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.3118, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.96MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 75.3695, min: -83.6502\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 364:\n",
      "  Allocated: 1717.39MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.39MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.9693, min: -7.3302\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5092, min: -7.2886\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.20MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.20MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.9693, min: -7.3302\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5092, min: -7.2886\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7886, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9597, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.1021, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.71MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 111.6226, min: -107.1455\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 365:\n",
      "  Allocated: 1715.87MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.87MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6347, min: -7.5839\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4399, min: -5.9945\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.36MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.36MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6347, min: -7.5839\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4399, min: -5.9945\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5350, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4987, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8864, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.01MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 102.0609, min: -100.5486\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 366:\n",
      "  Allocated: 1716.02MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.02MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0631, min: -7.7530\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6460, min: -6.3157\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.72MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.72MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0631, min: -7.7530\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6460, min: -6.3157\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5347, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1259, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.7240, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.37MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.6602, min: -89.4838\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 367:\n",
      "  Allocated: 1714.96MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.96MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9795, min: -7.9226\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6195, min: -6.2617\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.44MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.44MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9795, min: -7.9226\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6195, min: -6.2617\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4939, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9488, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6452, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.95MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.1808, min: -97.9576\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 368:\n",
      "  Allocated: 1714.82MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.82MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1209, min: -7.9425\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4773, min: -6.4016\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.10MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.10MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1209, min: -7.9425\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4773, min: -6.4016\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7790, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0547, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5082, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.75MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.4640, min: -80.0924\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 369:\n",
      "  Allocated: 1715.68MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.69MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4346, min: -6.7124\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5966, min: -6.4858\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.11MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.11MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4346, min: -6.7124\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5966, min: -6.4858\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2894, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8660, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1937, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.62MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.8357, min: -85.3884\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 370:\n",
      "  Allocated: 1717.07MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.07MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6339, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1214, min: -7.2650\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7250, min: -5.9815\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.08MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.08MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1214, min: -7.2650\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7250, min: -5.9815\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2809, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4500, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3412, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.73MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.2665, min: -89.6681\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 371:\n",
      "  Allocated: 1715.87MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.87MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8427, min: -6.6322\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7546, min: -7.2853\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.07MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.07MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8427, min: -6.6322\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7546, min: -7.2853\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5509, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9612, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6557, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.72MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 70.2142, min: -69.3057\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 372:\n",
      "  Allocated: 1714.25MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.25MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7450, min: -7.0838\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3416, min: -5.7844\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.45MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.45MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7450, min: -7.0838\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3416, min: -5.7844\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7016, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1986, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0675, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.10MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.0245, min: -82.1247\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 373:\n",
      "  Allocated: 1714.66MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.67MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.5332, min: -7.2433\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5596, min: -6.5012\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.23MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.80MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.5332, min: -7.2433\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5596, min: -6.5012\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0026, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1031, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5751, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.88MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.5678, min: -98.0994\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 374:\n",
      "  Allocated: 1714.62MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.62MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6682, min: -7.1935\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6244, min: -6.1420\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.62MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.62MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6682, min: -7.1935\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6244, min: -6.1420\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6736, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5080, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9534, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.27MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.6367, min: -86.4939\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 375:\n",
      "  Allocated: 1716.39MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.39MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9076, min: -6.6430\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1846, min: -5.4940\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.15MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.15MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9076, min: -6.6430\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1846, min: -5.4940\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5677, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1759, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5025, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.80MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.6482, min: -97.0136\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 376:\n",
      "  Allocated: 1715.31MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.31MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3312, min: -7.2388\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3257, min: -6.5674\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.87MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.87MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3312, min: -7.2388\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3257, min: -6.5674\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1008, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4234, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9449, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.38MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.4695, min: -78.0018\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 377:\n",
      "  Allocated: 1716.23MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.24MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8940, min: -7.1190\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6898, min: -5.7185\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.33MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.33MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8940, min: -7.1190\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6898, min: -5.7185\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9663, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3070, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6880, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.98MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.1622, min: -87.2919\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 378:\n",
      "  Allocated: 1715.38MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.38MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3870, min: -6.8278\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0692, min: -5.7674\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.82MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.82MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3870, min: -6.8278\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0692, min: -5.7674\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9463, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5419, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1950, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.47MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.7778, min: -97.8076\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 379:\n",
      "  Allocated: 1714.54MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.54MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4250, min: -7.0670\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1698, min: -6.2812\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.71MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.71MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4250, min: -7.0670\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1698, min: -6.2812\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2633, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8371, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.5851, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.36MB\n",
      "  Cached: 8056.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.5899, min: -75.5411\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 380:\n",
      "  Allocated: 1714.38MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.38MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.5373, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1652, min: -7.3638\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4968, min: -6.0588\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.67MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.67MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1652, min: -7.3638\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4968, min: -6.0588\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6791, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7753, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2930, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.32MB\n",
      "  Cached: 8070.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.8114, min: -92.0041\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 381:\n",
      "  Allocated: 1713.24MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.24MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6645, min: -6.8168\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5991, min: -6.7555\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.89MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.89MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6645, min: -6.8168\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5991, min: -6.7555\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0673, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0430, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2980, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.54MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 80.1115, min: -77.9490\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 382:\n",
      "  Allocated: 1715.73MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.73MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0951, min: -7.3168\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9672, min: -6.9034\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5894.73MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5846.73MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0951, min: -7.3168\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9672, min: -6.9034\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9925, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0044, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7366, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6033.38MB\n",
      "  Cached: 8038.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.6668, min: -92.7028\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 383:\n",
      "  Allocated: 1716.41MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.41MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.5572, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6926, min: -7.2683\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2210, min: -5.4585\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.21MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.21MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6926, min: -7.2683\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2210, min: -5.4585\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5854, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9166, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3847, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.85MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 112.1844, min: -112.1759\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 384:\n",
      "  Allocated: 1714.95MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.95MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8632, min: -7.1000\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0216, min: -7.1517\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.23MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.23MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8632, min: -7.1000\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0216, min: -7.1517\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9736, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9676, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8912, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.88MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 75.1579, min: -72.8222\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 385:\n",
      "  Allocated: 1716.63MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.63MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0322, min: -7.3669\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8233, min: -7.1338\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.09MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.09MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0322, min: -7.3669\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8233, min: -7.1338\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8352, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6774, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6523, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.74MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.1400, min: -92.5145\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 386:\n",
      "  Allocated: 1716.45MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.45MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8863, min: -7.5081\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6667, min: -6.1767\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5895.37MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5847.37MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8863, min: -7.5081\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6667, min: -6.1767\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5650, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7776, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7657, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6035.73MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7292.86MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 100.6949, min: -102.7982\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 387:\n",
      "  Allocated: 1717.11MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.11MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7101, min: -7.6102\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6145, min: -6.1288\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5895.87MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5847.44MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7101, min: -7.6102\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6145, min: -6.1288\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2891, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5846, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5435, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6034.52MB\n",
      "  Cached: 8086.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.1807, min: -96.0172\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 388:\n",
      "  Allocated: 1714.54MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.54MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5001, min: -7.5687\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5827, min: -5.9328\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.50MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.07MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5001, min: -7.5687\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5827, min: -5.9328\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8513, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8924, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1640, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.68MB\n",
      "  Cached: 8022.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.1060, min: -100.4165\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 389:\n",
      "  Allocated: 1716.90MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.90MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8785, min: -6.6103\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2606, min: -6.6549\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.07MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.64MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8785, min: -6.6103\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2606, min: -6.6549\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4503, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5335, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8625, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.58MB\n",
      "  Cached: 8054.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 71.1518, min: -71.7377\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 390:\n",
      "  Allocated: 1717.82MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.82MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.0740, min: -8.0427\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4184, min: -6.1585\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.97MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.97MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.0740, min: -8.0427\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4184, min: -6.1585\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2523, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8095, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9438, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.62MB\n",
      "  Cached: 8088.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 73.8084, min: -70.1476\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 391:\n",
      "  Allocated: 1715.50MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.50MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5515, min: -7.8548\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5389, min: -6.8610\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.17MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.17MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5515, min: -7.8548\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5389, min: -6.8610\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8263, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8337, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2527, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.82MB\n",
      "  Cached: 8040.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 117.6747, min: -108.3690\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 392:\n",
      "  Allocated: 1715.55MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.55MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3845, min: -7.8213\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7515, min: -6.3402\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.55MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.55MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3845, min: -7.8213\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7515, min: -6.3402\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0899, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4541, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2192, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.06MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.7106, min: -82.7328\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 393:\n",
      "  Allocated: 1714.09MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.09MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0665, min: -6.8112\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1074, min: -6.6062\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.36MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5830.36MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0665, min: -6.8112\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1074, min: -6.6062\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4851, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0715, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0401, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.87MB\n",
      "  Cached: 8072.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 69.1877, min: -62.2151\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 394:\n",
      "  Allocated: 1713.74MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.74MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8395, min: -7.7392\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5700, min: -6.3517\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.04MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.04MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8395, min: -7.7392\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5700, min: -6.3517\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6405, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0152, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1445, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.69MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.6933, min: -83.0944\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 395:\n",
      "  Allocated: 1715.96MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.96MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0046, min: -7.4030\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9384, min: -6.3966\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.14MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.14MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0046, min: -7.4030\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9384, min: -6.3966\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4023, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6914, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2886, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.79MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 106.2590, min: -105.4617\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 396:\n",
      "  Allocated: 1717.48MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.48MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6908, min: -7.4604\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7492, min: -7.5562\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.55MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.55MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6908, min: -7.4604\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7492, min: -7.5562\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2393, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6961, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2715, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.20MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 102.2216, min: -105.5685\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 397:\n",
      "  Allocated: 1712.53MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1728.53MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0554, min: -7.3041\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0695, min: -6.4504\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.19MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.19MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0554, min: -7.3041\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0695, min: -6.4504\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5765, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0482, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4353, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.84MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 102.8947, min: -103.3537\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 398:\n",
      "  Allocated: 1714.05MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.05MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1505, min: -8.3683\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4568, min: -7.1954\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.00MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.57MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1505, min: -8.3683\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4568, min: -7.1954\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3467, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6304, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4000, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.65MB\n",
      "  Cached: 8044.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.4631, min: -107.4033\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 399:\n",
      "  Allocated: 1714.66MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.67MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0874, min: -7.0636\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3879, min: -6.3457\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.11MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.11MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0874, min: -7.0636\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3879, min: -6.3457\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1504, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6775, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3674, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.76MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.4418, min: -87.3025\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 400:\n",
      "  Allocated: 1716.48MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.48MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9690, min: -6.7865\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6341, min: -6.4448\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.86MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.86MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9690, min: -6.7865\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6341, min: -6.4448\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4659, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5119, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 10.3924, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.51MB\n",
      "  Cached: 8076.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 118.5800, min: -118.9426\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 401:\n",
      "  Allocated: 1718.07MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.07MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0859, min: -7.7499\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0148, min: -7.3931\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.80MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.80MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0859, min: -7.7499\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0148, min: -7.3931\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5392, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6311, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7970, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.16MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 107.9813, min: -105.8206\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 402:\n",
      "  Allocated: 1714.17MB\n",
      "  Cached: 8106.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.17MB\n",
      "  Cached: 8106.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0613, min: -7.0790\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1460, min: -6.7067\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.21MB\n",
      "  Cached: 8106.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.21MB\n",
      "  Cached: 8106.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0613, min: -7.0790\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1460, min: -6.7067\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9330, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6888, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5663, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.85MB\n",
      "  Cached: 8106.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 63.9674, min: -63.7612\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 403:\n",
      "  Allocated: 1715.69MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.70MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0576, min: -7.3501\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3660, min: -6.3938\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.87MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.87MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0576, min: -7.3501\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3660, min: -6.3938\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1381, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3999, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8051, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.52MB\n",
      "  Cached: 8026.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 96.7480, min: -89.0311\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 404:\n",
      "  Allocated: 1714.23MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.24MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6664, min: -7.6551\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6432, min: -6.0479\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.18MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.18MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6664, min: -7.6551\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6432, min: -6.0479\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3666, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0928, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8922, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.82MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.4050, min: -89.9849\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 405:\n",
      "  Allocated: 1714.66MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.67MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1407, min: -7.4805\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9974, min: -6.4038\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.34MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.34MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1407, min: -7.4805\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9974, min: -6.4038\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8497, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0988, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8270, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.99MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 76.3256, min: -75.8735\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 406:\n",
      "  Allocated: 1715.58MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.58MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6324, min: -7.1183\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4882, min: -5.6476\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.52MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.52MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6324, min: -7.1183\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4882, min: -5.6476\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7737, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1998, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7076, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.17MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.4524, min: -92.3442\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 407:\n",
      "  Allocated: 1712.94MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1728.94MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5765, min: -7.0909\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8084, min: -6.6396\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5874.14MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5826.14MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5765, min: -7.0909\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8084, min: -6.6396\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2195, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1068, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9238, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6014.51MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 88.8444, min: -91.3597\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 408:\n",
      "  Allocated: 1714.97MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.97MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0019, min: -6.4969\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5314, min: -6.0288\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.67MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.67MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0019, min: -6.4969\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5314, min: -6.0288\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5909, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3742, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4526, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.03MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 98.0790, min: -87.7109\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 409:\n",
      "  Allocated: 1718.12MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.12MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1088, min: -7.2104\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6921, min: -6.4116\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5895.71MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5847.71MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1088, min: -7.2104\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6921, min: -6.4116\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9647, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7883, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7165, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6034.35MB\n",
      "  Cached: 8090.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.8490, min: -97.0201\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 410:\n",
      "  Allocated: 1716.39MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.39MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2498, min: -8.2989\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3880, min: -6.1427\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.39MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.39MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2498, min: -8.2989\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3880, min: -6.1427\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5361, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3054, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0651, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.04MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 76.9148, min: -71.2889\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 411:\n",
      "  Allocated: 1716.05MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.05MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0671, min: -6.9530\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2571, min: -5.9749\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.63MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.20MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0671, min: -6.9530\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2571, min: -5.9749\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9118, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3044, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0706, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.14MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 80.2647, min: -79.8114\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 412:\n",
      "  Allocated: 1717.99MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.99MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3348, min: -7.3588\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8905, min: -6.7388\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.86MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.86MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3348, min: -7.3588\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8905, min: -6.7388\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7055, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4331, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5381, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.51MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.0026, min: -92.8889\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 413:\n",
      "  Allocated: 1715.81MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.81MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4260, min: -7.2565\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1911, min: -6.6645\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.69MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.69MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4260, min: -7.2565\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1911, min: -6.6645\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6678, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8159, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7467, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.33MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.2866, min: -85.7605\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 414:\n",
      "  Allocated: 1717.12MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.12MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6848, min: -7.3106\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0549, min: -6.1452\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.27MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.27MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6848, min: -7.3106\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0549, min: -6.1452\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7925, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7177, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7387, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.92MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.2105, min: -100.1061\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 415:\n",
      "  Allocated: 1716.97MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.97MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1901, min: -7.1349\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0232, min: -6.7586\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.84MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.84MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1901, min: -7.1349\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0232, min: -6.7586\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3629, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0242, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.8503, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.49MB\n",
      "  Cached: 8042.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 63.8514, min: -66.0038\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 416:\n",
      "  Allocated: 1714.44MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.44MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.3880, min: -2.0853\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0295, min: -8.8777\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4701, min: -5.8377\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.62MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.62MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0295, min: -8.8777\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4701, min: -5.8377\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9907, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4155, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6677, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.26MB\n",
      "  Cached: 8074.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.8765, min: -87.8553\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 417:\n",
      "  Allocated: 1716.81MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.81MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6155, min: -7.5549\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0745, min: -5.7808\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5894.22MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5846.22MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6155, min: -7.5549\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0745, min: -5.7808\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3567, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0343, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8847, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.87MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.9343, min: -88.5310\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 418:\n",
      "  Allocated: 1716.40MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.40MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9413, min: -8.0808\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0915, min: -5.4755\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.86MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.86MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9413, min: -8.0808\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0915, min: -5.4755\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3668, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4659, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1101, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.51MB\n",
      "  Cached: 8058.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.9585, min: -88.4809\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 419:\n",
      "  Allocated: 1715.93MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.93MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.4357, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1335, min: -6.5560\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3791, min: -6.1765\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.15MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.15MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1335, min: -6.5560\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3791, min: -6.1765\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0978, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8495, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7146, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.80MB\n",
      "  Cached: 8060.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 105.5252, min: -104.4941\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 420:\n",
      "  Allocated: 1715.45MB\n",
      "  Cached: 8092.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.45MB\n",
      "  Cached: 8092.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5909, min: -6.3945\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5857, min: -6.4808\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.11MB\n",
      "  Cached: 8092.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.11MB\n",
      "  Cached: 8092.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5909, min: -6.3945\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5857, min: -6.4808\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3463, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5865, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8369, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.76MB\n",
      "  Cached: 8092.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.1320, min: -85.0937\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 421:\n",
      "  Allocated: 1715.68MB\n",
      "  Cached: 8016.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.69MB\n",
      "  Cached: 8016.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3321, min: -8.0975\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6826, min: -5.7632\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.63MB\n",
      "  Cached: 8016.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.63MB\n",
      "  Cached: 8016.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3321, min: -8.0975\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6826, min: -5.7632\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6787, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9476, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2028, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.28MB\n",
      "  Cached: 8016.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.3242, min: -91.3485\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 422:\n",
      "  Allocated: 1715.62MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.62MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8905, min: -6.9778\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6731, min: -5.9893\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.59MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.59MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8905, min: -6.9778\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6731, min: -5.9893\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2940, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1796, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5716, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.24MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 101.0466, min: -100.1789\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 423:\n",
      "  Allocated: 1712.87MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1728.87MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0260, min: -9.3101\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7564, min: -6.4598\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.88MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5829.88MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0260, min: -9.3101\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7564, min: -6.4598\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4683, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7684, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8209, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6016.53MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 110.1111, min: -102.2113\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 424:\n",
      "  Allocated: 1715.27MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.27MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6306, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2973, min: -7.7225\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7723, min: -5.8521\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.56MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.56MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2973, min: -7.7225\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7723, min: -5.8521\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7063, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3496, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1329, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.21MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 95.0720, min: -89.1294\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 425:\n",
      "  Allocated: 1714.86MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.86MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9905, min: -7.5420\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6669, min: -6.4224\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.50MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.50MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9905, min: -7.5420\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6669, min: -6.4224\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5884, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0602, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7364, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.15MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.5606, min: -86.6074\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 426:\n",
      "  Allocated: 1714.11MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.11MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.0787, min: -7.4236\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7850, min: -6.1237\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.50MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.50MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.0787, min: -7.4236\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7850, min: -6.1237\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3303, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8060, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7338, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.15MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.4742, min: -94.4882\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 427:\n",
      "  Allocated: 1714.86MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.86MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7902, min: -6.6569\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7103, min: -5.9818\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.54MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.54MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7902, min: -6.6569\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7103, min: -5.9818\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1967, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7294, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2800, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.91MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 80.3302, min: -76.8697\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 428:\n",
      "  Allocated: 1715.09MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.09MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0397, min: -8.3293\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7255, min: -6.1488\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.70MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.70MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0397, min: -8.3293\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7255, min: -6.1488\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4314, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1683, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3577, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.35MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 80.0621, min: -74.0501\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 429:\n",
      "  Allocated: 1716.58MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.58MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4729, min: -7.4009\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1735, min: -6.5357\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5879.90MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.90MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4729, min: -7.4009\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1735, min: -6.5357\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4381, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4659, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0746, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.27MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 102.0248, min: -101.4877\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 430:\n",
      "  Allocated: 1715.18MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.18MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4930, min: -7.3798\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0455, min: -6.7787\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.03MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.03MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4930, min: -7.3798\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0455, min: -6.7787\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6022, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1134, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2797, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.68MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.1421, min: -99.6911\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 431:\n",
      "  Allocated: 1716.12MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.12MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3638, min: -7.7452\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0291, min: -6.0249\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.24MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.24MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3638, min: -7.7452\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0291, min: -6.0249\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5229, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6044, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3910, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.61MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.8910, min: -84.5631\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 432:\n",
      "  Allocated: 1717.21MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.21MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8898, min: -7.5972\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9465, min: -6.8780\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.85MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.85MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8898, min: -7.5972\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9465, min: -6.8780\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8004, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8700, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8267, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.50MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 70.5527, min: -69.6315\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 433:\n",
      "  Allocated: 1715.43MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.43MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6761, min: -7.8454\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3069, min: -6.3829\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.44MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.44MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6761, min: -7.8454\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3069, min: -6.3829\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8554, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7468, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5939, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.09MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 118.2165, min: -112.6021\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 434:\n",
      "  Allocated: 1716.44MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.44MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7255, min: -7.3813\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5408, min: -6.2947\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.11MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.68MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7255, min: -7.3813\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5408, min: -6.2947\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2747, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1727, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4804, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.76MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.9985, min: -92.9029\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 435:\n",
      "  Allocated: 1716.76MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.76MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8064, min: -7.9265\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1499, min: -6.5617\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.07MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.07MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8064, min: -7.9265\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1499, min: -6.5617\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4408, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1994, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2468, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.72MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.6820, min: -83.8270\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 436:\n",
      "  Allocated: 1718.47MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.47MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1204, min: -8.3710\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6029, min: -6.1191\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.54MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5837.54MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1204, min: -8.3710\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6029, min: -6.1191\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0728, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4839, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1551, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.19MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.3664, min: -86.1749\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 437:\n",
      "  Allocated: 1714.81MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.81MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8878, min: -7.6172\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7381, min: -6.3187\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.35MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5829.35MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8878, min: -7.6172\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7381, min: -6.3187\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9780, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4562, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1345, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6016.00MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.6866, min: -99.9107\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 438:\n",
      "  Allocated: 1715.81MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.81MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0441, min: -8.1514\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7688, min: -6.0535\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.91MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.91MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0441, min: -8.1514\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7688, min: -6.0535\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6925, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7715, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6100, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.56MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 87.9859, min: -83.8534\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 439:\n",
      "  Allocated: 1713.75MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.75MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6249, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2053, min: -7.4669\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1997, min: -6.4113\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.23MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.23MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2053, min: -7.4669\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1997, min: -6.4113\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1073, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8844, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.3894, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.88MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 101.9122, min: -93.5354\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 440:\n",
      "  Allocated: 1716.69MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.69MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2634, min: -7.0831\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6617, min: -6.8561\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5895.42MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5847.42MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2634, min: -7.0831\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6617, min: -6.8561\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9851, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5115, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1040, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6034.07MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.6711, min: -80.4978\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 441:\n",
      "  Allocated: 1714.82MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.82MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8104, min: -8.6455\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6695, min: -5.7297\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.82MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.82MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8104, min: -8.6455\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6695, min: -5.7297\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9943, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8829, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6153, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.47MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 87.2266, min: -87.3347\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 442:\n",
      "  Allocated: 1715.44MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.44MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6399, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8451, min: -7.0500\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6371, min: -6.0225\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.02MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.59MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8451, min: -7.0500\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6371, min: -6.0225\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7159, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8785, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 9.3443, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.67MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.1235, min: -88.9090\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 443:\n",
      "  Allocated: 1716.09MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.09MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2431, min: -7.4057\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4112, min: -6.8224\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.73MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.30MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2431, min: -7.4057\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4112, min: -6.8224\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6324, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6962, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2174, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.38MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.6217, min: -94.8197\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 444:\n",
      "  Allocated: 1715.33MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.33MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9229, min: -6.9137\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5014, min: -7.5318\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.88MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5839.88MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9229, min: -6.9137\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5014, min: -7.5318\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0326, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6949, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2750, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.53MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 104.6393, min: -102.2559\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 445:\n",
      "  Allocated: 1716.99MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.99MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7672, min: -8.9135\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0895, min: -6.8475\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.62MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.19MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7672, min: -8.9135\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0895, min: -6.8475\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7695, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8417, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8469, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.27MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 95.1350, min: -97.7759\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 446:\n",
      "  Allocated: 1715.37MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.37MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8047, min: -7.1792\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6550, min: -5.8317\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.97MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.97MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8047, min: -7.1792\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6550, min: -5.8317\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.8846, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0528, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.7405, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.62MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.8326, min: -79.0314\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 447:\n",
      "  Allocated: 1715.05MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.05MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8797, min: -7.4240\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5944, min: -6.4233\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.07MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5828.64MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8797, min: -7.4240\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5944, min: -6.4233\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5783, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2514, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4974, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.06MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.6476, min: -82.3560\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 448:\n",
      "  Allocated: 1717.58MB\n",
      "  Cached: 8126.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.58MB\n",
      "  Cached: 8126.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7026, min: -7.2141\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5478, min: -6.3192\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.50MB\n",
      "  Cached: 8126.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.50MB\n",
      "  Cached: 8126.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7026, min: -7.2141\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5478, min: -6.3192\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2722, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5836, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4709, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.15MB\n",
      "  Cached: 8126.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.0395, min: -86.9877\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 449:\n",
      "  Allocated: 1715.47MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.47MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6399, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8789, min: -7.5795\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1429, min: -6.2380\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.41MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.41MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8789, min: -7.5795\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1429, min: -6.2380\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8433, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1996, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8551, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.78MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 80.1986, min: -78.9594\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 450:\n",
      "  Allocated: 1713.11MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.11MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6399, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2441, min: -7.8791\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3147, min: -6.7080\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.49MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5828.49MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2441, min: -7.8791\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3147, min: -6.7080\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8330, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1748, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7544, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.67MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.4838, min: -86.6065\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 451:\n",
      "  Allocated: 1716.32MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.32MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1101, min: -7.8658\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7337, min: -6.5052\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.16MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.16MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1101, min: -7.8658\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7337, min: -6.5052\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3182, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9805, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.6863, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.81MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 84.0874, min: -89.8912\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 452:\n",
      "  Allocated: 1714.33MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.33MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0293, min: -7.2972\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2603, min: -6.7262\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.14MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.14MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0293, min: -7.2972\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2603, min: -6.7262\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1413, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4396, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0923, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.79MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 106.8443, min: -108.7580\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 453:\n",
      "  Allocated: 1715.01MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.01MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6816, min: -7.3231\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8664, min: -6.1910\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.73MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.30MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6816, min: -7.3231\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8664, min: -6.1910\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6833, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8469, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 9.0172, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.38MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 89.3728, min: -87.2836\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 454:\n",
      "  Allocated: 1714.19MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.19MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6990, min: -7.3207\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6889, min: -7.0244\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5876.15MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5828.15MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6990, min: -7.3207\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6889, min: -7.0244\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2182, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5977, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3496, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6016.33MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 99.7839, min: -103.1307\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 455:\n",
      "  Allocated: 1717.51MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.51MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0688, min: -8.1489\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0020, min: -6.6518\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.58MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.58MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0688, min: -8.1489\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0020, min: -6.6518\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1148, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3546, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2737, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.23MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.7564, min: -81.4293\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 456:\n",
      "  Allocated: 1715.25MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.25MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8232, min: -8.4836\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6259, min: -5.6691\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.78MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.78MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8232, min: -8.4836\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6259, min: -5.6691\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7045, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3537, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0018, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.43MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 78.5340, min: -73.6065\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 457:\n",
      "  Allocated: 1713.95MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.95MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7611, min: -6.4083\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9782, min: -6.0596\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.47MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.47MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7611, min: -6.4083\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9782, min: -6.0596\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6057, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3983, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9229, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.12MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 101.1400, min: -102.4157\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 458:\n",
      "  Allocated: 1713.53MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.53MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8852, min: -8.8175\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9827, min: -6.7330\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.65MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.65MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8852, min: -8.8175\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9827, min: -6.7330\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9961, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8065, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1490, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.16MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 73.7371, min: -69.4361\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 459:\n",
      "  Allocated: 1713.77MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.77MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3944, min: -7.3389\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4045, min: -7.3595\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5877.15MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5829.15MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3944, min: -7.3389\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4045, min: -7.3595\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1725, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9444, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.0014, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.14MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 88.3538, min: -86.3028\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 460:\n",
      "  Allocated: 1715.97MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.97MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2520, min: -7.4499\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7468, min: -6.1803\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.55MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.55MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2520, min: -7.4499\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7468, min: -6.1803\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2062, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7644, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9288, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.20MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 105.9540, min: -106.4697\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 461:\n",
      "  Allocated: 1716.98MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.98MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7148, min: -7.4235\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7646, min: -6.0642\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.20MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.20MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7148, min: -7.4235\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7646, min: -6.0642\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4232, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3450, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6160, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.85MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 113.2359, min: -112.3245\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 462:\n",
      "  Allocated: 1715.59MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.59MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5119, min: -6.4601\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0467, min: -6.2327\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.10MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.10MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5119, min: -6.4601\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0467, min: -6.2327\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9621, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6817, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.1487, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.75MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.8204, min: -93.2400\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 463:\n",
      "  Allocated: 1715.36MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.36MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3829, min: -7.9632\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6649, min: -7.1405\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.90MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5830.90MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3829, min: -7.9632\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6649, min: -7.1405\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2101, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2136, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.2138, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6017.55MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.7753, min: -88.3482\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 464:\n",
      "  Allocated: 1715.38MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.38MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3299, min: -7.6159\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7028, min: -5.9356\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.96MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.96MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3299, min: -7.6159\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7028, min: -5.9356\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2768, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0697, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7775, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.61MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 105.0379, min: -103.8422\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 465:\n",
      "  Allocated: 1714.38MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.38MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8189, min: -7.5235\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7790, min: -7.3547\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.88MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.88MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8189, min: -7.5235\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7790, min: -7.3547\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0653, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4130, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6294, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.25MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.3933, min: -103.1824\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 466:\n",
      "  Allocated: 1714.19MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.19MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8027, min: -7.1929\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7902, min: -6.8145\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.43MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.43MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8027, min: -7.1929\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7902, min: -6.8145\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0440, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3249, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9802, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.08MB\n",
      "  Cached: 8080.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.7753, min: -89.9888\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 467:\n",
      "  Allocated: 1716.67MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.68MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5398, min: -6.8980\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4572, min: -6.0495\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.80MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.37MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5398, min: -6.8980\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4572, min: -6.0495\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1046, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7361, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9416, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.17MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.0781, min: -85.7195\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 468:\n",
      "  Allocated: 1716.22MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.22MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8109, min: -7.6810\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6856, min: -6.2834\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.74MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.74MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8109, min: -7.6810\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6856, min: -6.2834\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2684, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9360, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7202, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.39MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 67.9126, min: -64.7230\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 469:\n",
      "  Allocated: 1716.93MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.93MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5281, min: -6.8333\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0401, min: -6.6054\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.59MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.59MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5281, min: -6.8333\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0401, min: -6.6054\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2766, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6797, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3959, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.10MB\n",
      "  Cached: 8032.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 112.3000, min: -102.1588\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 470:\n",
      "  Allocated: 1718.20MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1734.20MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9620, min: -6.7741\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0205, min: -5.8226\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.59MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.59MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9620, min: -6.7741\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0205, min: -5.8226\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7496, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6119, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4054, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.24MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 102.5643, min: -104.6034\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 471:\n",
      "  Allocated: 1713.91MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.91MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3990, min: -7.6217\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6762, min: -7.1086\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.31MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.31MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3990, min: -7.6217\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6762, min: -7.1086\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5531, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4276, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7730, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.96MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.3181, min: -77.7335\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 472:\n",
      "  Allocated: 1717.81MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.81MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0326, min: -6.6624\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0704, min: -7.2050\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.63MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.63MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0326, min: -6.6624\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0704, min: -7.2050\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1952, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5721, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.0333, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.14MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 96.5949, min: -94.2469\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 473:\n",
      "  Allocated: 1717.27MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.27MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1966, min: -6.9873\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2768, min: -7.6835\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.58MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.58MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1966, min: -6.9873\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2768, min: -7.6835\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3025, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7784, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3991, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.23MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 100.7687, min: -99.4137\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 474:\n",
      "  Allocated: 1714.83MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.83MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9164, min: -6.6152\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8608, min: -6.3935\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.98MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.98MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9164, min: -6.6152\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8608, min: -6.3935\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9146, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6270, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0236, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.63MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 74.1127, min: -78.0562\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 475:\n",
      "  Allocated: 1714.52MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.52MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7794, min: -6.9090\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7304, min: -8.4571\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.59MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.71MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7794, min: -6.9090\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7304, min: -8.4571\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2710, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1829, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7711, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.24MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 115.3047, min: -108.5408\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 476:\n",
      "  Allocated: 1715.39MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.39MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4639, min: -7.3942\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9041, min: -6.0460\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.04MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.04MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4639, min: -7.3942\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9041, min: -6.0460\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3657, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4847, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7759, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.69MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.6359, min: -88.1135\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 477:\n",
      "  Allocated: 1717.38MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.38MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9209, min: -7.5088\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1798, min: -7.4059\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.45MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.45MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9209, min: -7.5088\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1798, min: -7.4059\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7542, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6095, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4597, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.96MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 61.9731, min: -62.7410\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 478:\n",
      "  Allocated: 1716.60MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.60MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8112, min: -7.1581\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1887, min: -6.3841\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.66MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.66MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8112, min: -7.1581\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1887, min: -6.3841\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2191, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3032, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1369, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.31MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.1639, min: -89.0904\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 479:\n",
      "  Allocated: 1714.87MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.87MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7160, min: -7.8793\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0176, min: -6.2263\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5878.66MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5830.66MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7160, min: -7.8793\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0176, min: -6.2263\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1212, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.1705, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4855, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.02MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 95.7515, min: -93.8649\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 480:\n",
      "  Allocated: 1714.25MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.25MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1552, min: -7.2754\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9804, min: -6.7986\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.53MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.53MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1552, min: -7.2754\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9804, min: -6.7986\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8955, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6574, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4338, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.18MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.9648, min: -98.1591\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 481:\n",
      "  Allocated: 1715.09MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.09MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9190, min: -7.1738\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8800, min: -6.5349\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.50MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.50MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9190, min: -7.1738\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8800, min: -6.5349\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0154, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6551, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7788, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.15MB\n",
      "  Cached: 8014.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 88.2428, min: -89.0366\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 482:\n",
      "  Allocated: 1714.20MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.20MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6872, min: -6.7486\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6779, min: -7.0914\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.30MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.30MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6872, min: -6.7486\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6779, min: -7.0914\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2403, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8092, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6041, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.95MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 101.6824, min: -92.5875\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 483:\n",
      "  Allocated: 1714.33MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.33MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9152, min: -7.9327\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5846, min: -7.6966\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5894.83MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5846.83MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9152, min: -7.9327\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5846, min: -7.6966\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0408, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9900, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4829, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6033.48MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.3342, min: -77.6740\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 484:\n",
      "  Allocated: 1715.63MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.63MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0559, min: -7.6113\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6462, min: -7.0421\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.70MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.70MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0559, min: -7.6113\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6462, min: -7.0421\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2609, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6160, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9753, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.06MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 77.7261, min: -83.1012\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 485:\n",
      "  Allocated: 1715.25MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.25MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0659, min: -7.3508\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4615, min: -5.9416\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.61MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.61MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0659, min: -7.3508\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4615, min: -5.9416\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5104, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6822, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2036, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.26MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 79.9945, min: -81.4080\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 486:\n",
      "  Allocated: 1716.65MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.65MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1825, min: -8.3117\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6749, min: -6.3988\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5894.58MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5846.58MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1825, min: -8.3117\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6749, min: -6.3988\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2919, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7365, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5642, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6033.23MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.7183, min: -91.2566\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 487:\n",
      "  Allocated: 1712.76MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1728.76MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6941, min: -7.1809\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5317, min: -6.4598\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.46MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.46MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6941, min: -7.1809\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5317, min: -6.4598\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9156, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.4942, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2862, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.83MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 92.9913, min: -92.2266\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 488:\n",
      "  Allocated: 1714.66MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.67MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8054, min: -7.1438\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3663, min: -7.1949\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.94MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.51MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8054, min: -7.1438\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3663, min: -7.1949\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0406, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8602, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9072, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.59MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 87.9419, min: -83.6124\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 489:\n",
      "  Allocated: 1714.38MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.38MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8087, min: -7.8640\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5094, min: -6.2779\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5887.69MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.69MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8087, min: -7.8640\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5094, min: -6.2779\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7633, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5470, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0735, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.06MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 87.8592, min: -87.6314\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 490:\n",
      "  Allocated: 1714.05MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.05MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7256, min: -7.5536\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8872, min: -6.1332\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5890.02MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5842.02MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7256, min: -7.5536\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8872, min: -6.1332\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0509, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4270, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0787, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.67MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.3601, min: -90.8015\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 491:\n",
      "  Allocated: 1715.61MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.61MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8767, min: -6.5705\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1122, min: -6.1787\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.45MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.02MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8767, min: -6.5705\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1122, min: -6.1787\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7746, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 3.8347, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6746, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.09MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 101.3106, min: -100.5418\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 492:\n",
      "  Allocated: 1713.18MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.18MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1011, min: -7.3397\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0974, min: -6.8911\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.94MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.94MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1011, min: -7.3397\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0974, min: -6.8911\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5051, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6426, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5874, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.59MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 115.6208, min: -119.1169\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 493:\n",
      "  Allocated: 1714.18MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.18MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.9594, min: -7.3600\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2358, min: -5.7413\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.43MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.43MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.9594, min: -7.3600\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2358, min: -5.7413\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4216, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3177, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 8.9578, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6022.80MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 110.8101, min: -103.8795\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 494:\n",
      "  Allocated: 1713.52MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.52MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0462, min: -6.7751\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7430, min: -6.4114\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.40MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.40MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0462, min: -6.7751\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7430, min: -6.4114\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2385, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.3045, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9094, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.05MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.5432, min: -92.3207\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 495:\n",
      "  Allocated: 1716.90MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.90MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4825, min: -6.6389\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9731, min: -6.1845\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.03MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.03MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4825, min: -6.6389\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9731, min: -6.1845\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2592, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8754, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0421, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.53MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 93.4536, min: -89.2156\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 496:\n",
      "  Allocated: 1716.69MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.69MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6889, min: -7.8383\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9170, min: -6.0144\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.34MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.34MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6889, min: -7.8383\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9170, min: -6.0144\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1058, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8393, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4838, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6026.99MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.5524, min: -87.2680\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 497:\n",
      "  Allocated: 1714.95MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.95MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0531, min: -7.4996\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6518, min: -6.5497\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.71MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5841.71MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0531, min: -7.4996\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6518, min: -6.5497\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9069, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8577, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9595, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.36MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 102.5636, min: -99.5958\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 498:\n",
      "  Allocated: 1717.70MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.70MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9530, min: -8.3223\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6992, min: -6.4295\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5894.23MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5846.23MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9530, min: -8.3223\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6992, min: -6.4295\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6048, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9920, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3937, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.88MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 106.5543, min: -101.2617\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 499:\n",
      "  Allocated: 1714.96MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.96MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1877, min: -6.4415\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2491, min: -6.3321\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5886.94MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5838.51MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1877, min: -6.4415\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2491, min: -6.3321\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2470, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9852, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6120, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.31MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.4850, min: -87.8687\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 500:\n",
      "  Allocated: 1714.95MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.95MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5818, min: -6.3699\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9416, min: -6.5941\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.00MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.00MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5818, min: -6.3699\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9416, min: -6.5941\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8344, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8436, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5516, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.51MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 80.7586, min: -82.0344\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 501:\n",
      "  Allocated: 1714.19MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.19MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5489, min: -7.8916\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7428, min: -6.2130\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.82MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.82MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5489, min: -7.8916\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7428, min: -6.2130\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9063, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2738, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0981, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.47MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 83.5464, min: -85.5099\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 502:\n",
      "  Allocated: 1714.19MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.19MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5062, min: -7.6010\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5795, min: -6.9825\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.49MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.06MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5062, min: -7.6010\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5795, min: -6.9825\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7521, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2739, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5521, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.00MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 90.0720, min: -88.5114\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 503:\n",
      "  Allocated: 1714.56MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.56MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7862, min: -7.2749\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9729, min: -6.2508\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5888.84MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.84MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7862, min: -7.2749\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9729, min: -6.2508\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0052, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2683, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4948, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6027.49MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 107.4654, min: -108.1087\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 504:\n",
      "  Allocated: 1714.39MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.39MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1737, min: -7.7953\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3002, min: -5.7415\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.99MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.99MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1737, min: -7.7953\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3002, min: -5.7415\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9829, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6809, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9832, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.64MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 86.9975, min: -87.1184\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 505:\n",
      "  Allocated: 1715.21MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.21MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8778, min: -6.9428\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4613, min: -6.2942\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5885.21MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.78MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8778, min: -6.9428\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4613, min: -6.2942\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9978, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9728, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1043, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6024.72MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.6182, min: -89.0608\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 506:\n",
      "  Allocated: 1715.09MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.09MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7439, min: -7.7012\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8741, min: -6.8888\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5889.08MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5840.65MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7439, min: -7.7012\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8741, min: -6.8888\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5065, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8966, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6461, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6028.58MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 70.5246, min: -69.1663\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 507:\n",
      "  Allocated: 1715.05MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.05MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2548, min: -7.2794\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8433, min: -6.5267\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.87MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.87MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2548, min: -7.2794\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8433, min: -6.5267\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5318, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0151, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3340, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.52MB\n",
      "  Cached: 8094.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 75.4158, min: -78.3512\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 508:\n",
      "  Allocated: 1716.62MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.62MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3798, min: -7.7769\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4111, min: -6.5851\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5883.13MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5835.13MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3798, min: -7.7769\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.4111, min: -6.5851\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6998, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2592, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0213, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6023.50MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.5375, min: -92.8558\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 509:\n",
      "  Allocated: 1716.09MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.09MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7971, min: -7.7171\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7488, min: -6.9021\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.27MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.27MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7971, min: -7.7171\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7488, min: -6.9021\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5571, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0218, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2224, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6018.92MB\n",
      "  Cached: 8096.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 68.5053, min: -69.1244\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 510:\n",
      "  Allocated: 1717.34MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.34MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6221, min: -7.6526\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7813, min: -7.0953\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5882.15MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5834.15MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6221, min: -7.6526\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7813, min: -7.0953\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8067, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0964, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.3531, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6020.80MB\n",
      "  Cached: 8064.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 82.1690, min: -84.6221\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 511:\n",
      "  Allocated: 1714.48MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.48MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.5592, min: -2.1091\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2241, min: -7.2502\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0606, min: -6.3465\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.50MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.50MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2241, min: -7.2502\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0606, min: -6.3465\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6882, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.0936, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1613, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.15MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 63.4041, min: -65.3930\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 512:\n",
      "  Allocated: 1716.09MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.09MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8911, min: -7.1744\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5540, min: -6.0546\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.90MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.47MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8911, min: -7.1744\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5540, min: -6.0546\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9882, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2433, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7529, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6032.55MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 94.3770, min: -98.0707\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 513:\n",
      "  Allocated: 1716.02MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.02MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0688, min: -6.9698\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2595, min: -6.5631\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.78MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5831.78MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0688, min: -6.9698\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2595, min: -6.5631\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3939, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7622, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9127, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.43MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 73.1489, min: -71.1672\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 514:\n",
      "  Allocated: 1713.23MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.24MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9852, min: -7.2505\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6864, min: -6.0504\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.33MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.33MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9852, min: -7.2505\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6864, min: -6.0504\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.3571, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6395, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6233, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.97MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 70.0515, min: -72.9184\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 515:\n",
      "  Allocated: 1713.55MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.55MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7443, min: -7.4500\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0396, min: -6.3472\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.72MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.72MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7443, min: -7.4500\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0396, min: -6.3472\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5025, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.0718, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4193, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.37MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 88.0126, min: -91.4355\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 516:\n",
      "  Allocated: 1712.99MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1728.99MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6341, min: -7.9575\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8582, min: -6.3682\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.02MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.02MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.6341, min: -7.9575\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8582, min: -6.3682\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7230, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5788, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6557, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6029.67MB\n",
      "  Cached: 8030.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 72.8243, min: -74.9083\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 517:\n",
      "  Allocated: 1716.13MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.13MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5815, min: -6.6898\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5843, min: -6.1733\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5891.55MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5843.12MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5815, min: -6.6898\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5843, min: -6.1733\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1741, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.9963, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.7385, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6030.20MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 80.6106, min: -85.6751\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 518:\n",
      "  Allocated: 1715.16MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.16MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0990, min: -6.9019\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9281, min: -5.6018\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.30MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.30MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.0990, min: -6.9019\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9281, min: -5.6018\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1342, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.0829, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4922, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.94MB\n",
      "  Cached: 8062.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 91.5168, min: -91.5151\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 519:\n",
      "  Allocated: 1716.50MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.50MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4133, min: -7.6898\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9227, min: -6.0921\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.74MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.74MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4133, min: -7.6898\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.9227, min: -6.0921\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5540, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.2880, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.2253, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.11MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 85.1487, min: -85.7564\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 520:\n",
      "  Allocated: 1716.30MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.30MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1108, min: -7.5236\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6671, min: -6.0761\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5893.33MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5845.33MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.1108, min: -7.5236\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6671, min: -6.0761\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1285, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8036, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.1646, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.98MB\n",
      "  Cached: 8078.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 103.3489, min: -104.8007\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 521:\n",
      "  Allocated: 1716.53MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.53MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2994, min: -7.5070\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5280, min: -6.4251\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5892.08MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5844.08MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.2994, min: -7.5070\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.5280, min: -6.4251\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.5395, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.5965, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.2999, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6031.73MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 108.5880, min: -108.2318\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 522:\n",
      "  Allocated: 1713.38MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1729.38MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.5252, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9070, min: -7.3169\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8998, min: -7.7454\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5884.83MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5836.83MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9070, min: -7.3169\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8998, min: -7.7454\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1665, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 3.9572, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.7450, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6025.20MB\n",
      "  Cached: 8046.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 115.6380, min: -111.7790\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 523:\n",
      "  Allocated: 1714.62MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1730.62MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8318, min: -7.7166\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4400, min: -6.1702\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5880.77MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5832.77MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.8318, min: -7.7166\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.4400, min: -6.1702\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.6416, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.0495, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.4213, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6019.42MB\n",
      "  Cached: 8110.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 97.8010, min: -99.9737\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 524:\n",
      "  Allocated: 1717.16MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1733.16MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9907, min: -9.0110\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6762, min: -6.5460\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5881.91MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5833.91MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.9907, min: -9.0110\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.6762, min: -6.5460\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1332, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.8564, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.3314, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6021.56MB\n",
      "  Cached: 8048.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 104.0968, min: -104.8488\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 525:\n",
      "  Allocated: 1716.18MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1732.18MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5267, min: -6.8867\n",
      "  memory: 8.00MB\n",
      "\n",
      "Stage4 features:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8104, min: -7.6258\n",
      "  memory: 4.00MB\n",
      "\n",
      "GPU Memory at Backbone end:\n",
      "  Allocated: 5897.56MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "GPU Memory at Hybrid encoder start:\n",
      "  Allocated: 5849.56MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Input stage3:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 7.5267, min: -6.8867\n",
      "  memory: 8.00MB\n",
      "\n",
      "Input stage4:\n",
      "  shape: torch.Size([4, 1024, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.8104, min: -7.6258\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S3:\n",
      "  shape: torch.Size([4, 256, 32, 32]), device: cuda:0, dtype: torch.float32\n",
      "  max: 5.1957, min: 0.0000\n",
      "  memory: 4.00MB\n",
      "\n",
      "Projected S4:\n",
      "  shape: torch.Size([4, 256, 16, 16]), device: cuda:0, dtype: torch.float32\n",
      "  max: 4.6240, min: 0.0000\n",
      "  memory: 1.00MB\n",
      "\n",
      "Output Fi:\n",
      "  shape: torch.Size([4, 256, 64, 64]), device: cuda:0, dtype: torch.float32\n",
      "  max: 6.7597, min: 0.0000\n",
      "  memory: 16.00MB\n",
      "\n",
      "GPU Memory at Hybrid encoder end:\n",
      "  Allocated: 6036.21MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7293.60MB\n",
      "\n",
      "Shape embeddings:\n",
      "  shape: torch.Size([4, 3, 256]), device: cuda:0, dtype: torch.float32\n",
      "  max: 81.2436, min: -82.5650\n",
      "  memory: 0.01MB\n",
      "\n",
      "GPU Memory at Start of batch 526:\n",
      "  Allocated: 1715.61MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7294.35MB\n",
      "\n",
      "GPU Memory at Backbone start:\n",
      "  Allocated: 1731.61MB\n",
      "  Cached: 8036.00MB\n",
      "  Peak: 7294.35MB\n",
      "\n",
      "Input to backbone:\n",
      "  shape: torch.Size([4, 3, 512, 512]), device: cuda:0, dtype: torch.float32\n",
      "  max: 2.6400, min: -2.1179\n",
      "  memory: 12.00MB\n",
      "\n",
      "Stage3 features:\n",
      "  shape: torch.Size([4, 512, 32, 32]), device: cuda:0, dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=6 torchrun --nproc_per_node=1 --master_port=29501 module5/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8224ef1f-e0e0-41ae-896e-bf5c876dc8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response maps shape before decoder: torch.Size([2, 3, 64, 64])\n",
      "Response maps shape before decoder: torch.Size([2, 3, 64, 64])\n",
      "Response maps shape before decoder: torch.Size([2, 3, 64, 64])\n",
      "\n",
      "Test results:\n",
      "Input image shape: torch.Size([2, 3, 512, 512])\n",
      "Input bboxes shape: torch.Size([2, 3, 4])\n",
      "\n",
      "Density maps:\n",
      "Iteration 0 density map shape: torch.Size([2, 1, 512, 512])\n",
      "Iteration 1 density map shape: torch.Size([2, 1, 512, 512])\n",
      "Iteration 2 density map shape: torch.Size([2, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=7 torchrun --nproc_per_node=1 module5/engine.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03fb2c09-ed51-4604-852f-a4f6378aad15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Modify the line in iefl.py line 223 from:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m attn \u001b[38;5;241m=\u001b[39m (\u001b[43mq\u001b[49m \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# To:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):  \u001b[38;5;66;03m# Disable AMP for this operation\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'q' is not defined"
     ]
    }
   ],
   "source": [
    "# Modify the line in iefl.py line 223 from:\n",
    "attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "\n",
    "# To:\n",
    "with torch.cuda.amp.autocast(enabled=False):  # Disable AMP for this operation\n",
    "    q_f32 = q.float()\n",
    "    k_f32 = k.float()\n",
    "    attn = (q_f32 @ k_f32.transpose(-2, -1)) * self.scale\n",
    "    attn = attn.to(dtype=q.dtype)  # Cast back to original dtype if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
