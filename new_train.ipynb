{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bc73632-b277-4a0f-a9fc-4d4362652014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "Training with 1 GPUs\n",
      "Initializing directories...\n",
      "Setting up datasets...\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/home/renaldy_fredyan/PhDResearch/ELS/module5/train.py\", line 266, in <module>\n",
      "[rank0]:     train()\n",
      "[rank0]:   File \"/home/renaldy_fredyan/PhDResearch/ELS/module5/train.py\", line 144, in train\n",
      "[rank0]:     pred_density_maps = model(images, exemplars)\n",
      "[rank0]:   File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1643, in forward\n",
      "[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)\n",
      "[rank0]:   File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1459, in _run_ddp_forward\n",
      "[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
      "[rank0]:   File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/home/renaldy_fredyan/PhDResearch/ELS/module5/engine.py\", line 48, in forward\n",
      "[rank0]:     exemplar_features = self.iefl(Fi, bboxes)\n",
      "[rank0]:   File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/home/renaldy_fredyan/PhDResearch/ELS/module5/iefl.py\", line 314, in forward\n",
      "[rank0]:     F_tmp = self.mhca(F_tmp, roi_features, roi_features)\n",
      "[rank0]:   File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/home/renaldy_fredyan/PhDResearch/ELS/module5/iefl.py\", line 228, in forward\n",
      "[rank0]:     attn = (q @ k.transpose(-2, -1)) * self.scale\n",
      "[rank0]: RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasGemmStridedBatchedEx( handle, opa, opb, m, n, k, (void*)(&falpha), a, CUDA_R_16F, lda, stridea, b, CUDA_R_16F, ldb, strideb, (void*)(&fbeta), c, CUDA_R_16F, ldc, stridec, num_batches, CUDA_R_32F, CUBLAS_GEMM_DEFAULT_TENSOR_OP)`\n",
      "[rank0]:[W216 13:14:46.224314790 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
      "E0216 13:14:47.990000 2920755 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 2920758) of binary: /opt/miniconda/envs/Rey2/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda/envs/Rey2/bin/torchrun\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('torch==2.5.1', 'console_scripts', 'torchrun')())\n",
      "  File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/distributed/run.py\", line 919, in main\n",
      "    run(args)\n",
      "  File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/distributed/run.py\", line 910, in run\n",
      "    elastic_launch(\n",
      "  File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/opt/miniconda/envs/Rey2/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "module5/train.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-02-16_13:14:47\n",
      "  host      : viplab-G481-H81-00\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 2920758)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=7 torchrun --nproc_per_node=1 module5/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8224ef1f-e0e0-41ae-896e-bf5c876dc8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 3, 32])\n",
      "torch.Size([2, 8, 3, 32])\n",
      "torch.Size([2, 8, 3, 32])\n",
      "torch.Size([2, 8, 3, 32])\n",
      "torch.Size([2, 8, 3, 32])\n",
      "torch.Size([2, 8, 3, 32])\n",
      "\n",
      "Input shapes:\n",
      "Image features: torch.Size([2, 256, 64, 64])\n",
      "Bounding boxes: torch.Size([2, 3, 4])\n",
      "\n",
      "Output features:\n",
      "F_E^1 shape: torch.Size([2, 3, 256])\n",
      "F_E^2 shape: torch.Size([2, 3, 256])\n",
      "F_E^3 shape: torch.Size([2, 3, 256])\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=7 torchrun --nproc_per_node=1 module5/iefl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03fb2c09-ed51-4604-852f-a4f6378aad15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Modify the line in iefl.py line 223 from:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m attn \u001b[38;5;241m=\u001b[39m (\u001b[43mq\u001b[49m \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# To:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):  \u001b[38;5;66;03m# Disable AMP for this operation\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'q' is not defined"
     ]
    }
   ],
   "source": [
    "# Modify the line in iefl.py line 223 from:\n",
    "attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "\n",
    "# To:\n",
    "with torch.cuda.amp.autocast(enabled=False):  # Disable AMP for this operation\n",
    "    q_f32 = q.float()\n",
    "    k_f32 = k.float()\n",
    "    attn = (q_f32 @ k_f32.transpose(-2, -1)) * self.scale\n",
    "    attn = attn.to(dtype=q.dtype)  # Cast back to original dtype if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
