{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251297c8-f1ec-4d19-955d-9e59801f82b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "Downloading pretrained model...\n",
      "Downloading pretrained model...\n",
      "Downloading pretrained model...\n",
      "Downloading pretrained model...\n",
      "model.safetensors: 100%|█████████████████████| 178M/178M [00:05<00:00, 35.5MB/s]\n",
      "Model saved to models/swin_tiny_patch4_window7_224.ms_in22k.pth\n",
      "Model saved to models/swin_tiny_patch4_window7_224.ms_in22k.pth\n",
      "Model saved to models/swin_tiny_patch4_window7_224.ms_in22k.pth\n",
      "Model saved to models/swin_tiny_patch4_window7_224.ms_in22k.pth\n",
      "Pretrained weights loaded successfully, ignoring mismatched keys.\n",
      "Pretrained weights loaded successfully, ignoring mismatched keys.\n",
      "Pretrained weights loaded successfully, ignoring mismatched keys.\n",
      "Pretrained weights loaded successfully, ignoring mismatched keys.\n",
      "Epoch 1/10: 100%|███████████████| 458/458 [15:08<00:00,  1.98s/batch, loss=0.69]\n",
      "Epoch 1/10: 100%|███████████████| 458/458 [15:08<00:00,  1.98s/batch, loss=0.87]\n",
      "Epoch 1/10: 100%|██████████████| 458/458 [15:08<00:00,  1.98s/batch, loss=0.836]\n",
      "Epoch 1/10: 100%|██████████████| 458/458 [15:08<00:00,  1.98s/batch, loss=0.851]\n",
      "Validation Loss: 0.4885\n",
      "Validation Loss: 0.0030\n",
      "Validation Loss: 0.4929\n",
      "Validation Loss: 0.0031\n",
      "Validation Loss: 0.4923\n",
      "Validation Loss: 0.0031\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [1/10] completed in 929.49 seconds, Loss: 0.6899\n",
      "New best model saved at checkpoints/best_model.pth   | 0/458 [00:00<?, ?batch/s]\n",
      "Epoch [1/10] completed in 929.60 seconds, Loss: 0.8514\n",
      "New best model saved at checkpoints/best_model.pth   | 0/458 [00:00<?, ?batch/s]\n",
      "Epoch [1/10] completed in 929.69 seconds, Loss: 0.8702\n",
      "Validation Loss: 0.4958                              | 0/458 [00:00<?, ?batch/s]\n",
      "Validation Loss: 0.0031\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [1/10] completed in 930.14 seconds, Loss: 0.8359\n",
      "Epoch 2/10: 100%|███████████████| 458/458 [14:54<00:00,  1.95s/batch, loss=0.37]\n",
      "Epoch 2/10: 100%|██████████████| 458/458 [14:54<00:00,  1.95s/batch, loss=0.324]\n",
      "Epoch 2/10: 100%|██████████████| 458/458 [14:54<00:00,  1.95s/batch, loss=0.296]\n",
      "Epoch 2/10: 100%|██████████████| 458/458 [14:54<00:00,  1.95s/batch, loss=0.361]\n",
      "Validation Loss: 0.2996\n",
      "Validation Loss: 0.0019\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [2/10] completed in 925.82 seconds, Loss: 0.3239\n",
      "Validation Loss: 0.2983                              | 0/458 [00:00<?, ?batch/s]\n",
      "Validation Loss: 0.0019\n",
      "Validation Loss: 0.3014\n",
      "Validation Loss: 0.0019\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [2/10] completed in 926.28 seconds, Loss: 0.2964\n",
      "Epoch 3/10:   0%|                                    | 0/458 [00:00<?, ?batch/s]New best model saved at checkpoints/best_model.pth\n",
      "Epoch [2/10] completed in 925.84 seconds, Loss: 0.3701\n",
      "Validation Loss: 0.3003                              | 0/458 [00:00<?, ?batch/s]\n",
      "Validation Loss: 0.0019\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [2/10] completed in 927.52 seconds, Loss: 0.3611\n",
      "Epoch 3/10: 100%|██████████████| 458/458 [14:37<00:00,  1.91s/batch, loss=0.302]\n",
      "Epoch 3/10: 100%|██████████████| 458/458 [14:37<00:00,  1.92s/batch, loss=0.333]\n",
      "Epoch 3/10: 100%|██████████████| 458/458 [14:37<00:00,  1.91s/batch, loss=0.372]\n",
      "Epoch 3/10: 100%|██████████████| 458/458 [14:36<00:00,  1.91s/batch, loss=0.285]\n",
      "Validation Loss: 0.2458\n",
      "Validation Loss: 0.0015\n",
      "Validation Loss: 0.2461\n",
      "Validation Loss: 0.0015\n",
      "Validation Loss: 0.2459\n",
      "Validation Loss: 0.0015\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [3/10] completed in 901.08 seconds, Loss: 0.3020\n",
      "New best model saved at checkpoints/best_model.pth   | 0/458 [00:00<?, ?batch/s]\n",
      "Epoch [3/10] completed in 900.18 seconds, Loss: 0.2855\n",
      "New best model saved at checkpoints/best_model.pth   | 0/458 [00:00<?, ?batch/s]\n",
      "Epoch [3/10] completed in 901.94 seconds, Loss: 0.3335\n",
      "Epoch 4/10:   0%|                                    | 0/458 [00:00<?, ?batch/s]Validation Loss: 0.2458\n",
      "Validation Loss: 0.0015\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [3/10] completed in 901.72 seconds, Loss: 0.3723\n",
      "Epoch 4/10: 100%|██████████████| 458/458 [14:22<00:00,  1.88s/batch, loss=0.358]\n",
      "Epoch 4/10: 100%|██████████████| 458/458 [14:22<00:00,  1.88s/batch, loss=0.324]\n",
      "Epoch 4/10: 100%|██████████████| 458/458 [14:22<00:00,  1.88s/batch, loss=0.319]\n",
      "Epoch 4/10: 100%|██████████████| 458/458 [14:22<00:00,  1.88s/batch, loss=0.336]\n",
      "Validation Loss: 0.2432\n",
      "Validation Loss: 0.0015\n",
      "Validation Loss: 0.2430\n",
      "Validation Loss: 0.0015\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [4/10] completed in 883.73 seconds, Loss: 0.3241\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [4/10] completed in 883.09 seconds, Loss: 0.3193\n",
      "Validation Loss: 0.2430                              | 0/458 [00:00<?, ?batch/s]\n",
      "Validation Loss: 0.0015\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [4/10] completed in 884.47 seconds, Loss: 0.3364\n",
      "Validation Loss: 0.2431                              | 0/458 [00:00<?, ?batch/s]\n",
      "Validation Loss: 0.0015\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [4/10] completed in 889.80 seconds, Loss: 0.3585\n",
      "Epoch 5/10: 100%|██████████████| 458/458 [14:55<00:00,  1.95s/batch, loss=0.295]\n",
      "Epoch 5/10: 100%|██████████████| 458/458 [14:55<00:00,  1.96s/batch, loss=0.328]\n",
      "Epoch 5/10: 100%|██████████████| 458/458 [14:55<00:00,  1.96s/batch, loss=0.304]\n",
      "Epoch 5/10: 100%|██████████████| 458/458 [14:49<00:00,  1.94s/batch, loss=0.263]\n",
      "Validation Loss: 0.2524\n",
      "Validation Loss: 0.0016\n",
      "Epoch [5/10] completed in 916.73 seconds, Loss: 0.3042\n",
      "Validation Loss: 0.2522                              | 0/458 [00:00<?, ?batch/s]\n",
      "Validation Loss: 0.0016\n",
      "Epoch [5/10] completed in 915.91 seconds, Loss: 0.2946\n",
      "Epoch 6/10:   0%|                                    | 0/458 [00:00<?, ?batch/s]Validation Loss: 0.2523\n",
      "Validation Loss: 0.0016\n",
      "Epoch [5/10] completed in 910.41 seconds, Loss: 0.2634\n",
      "Validation Loss: 0.2525\n",
      "Validation Loss: 0.0016\n",
      "Epoch 6/10:   0%|                                    | 0/458 [00:00<?, ?batch/s]Epoch [5/10] completed in 916.78 seconds, Loss: 0.3281\n",
      "Epoch 6/10: 100%|██████████████| 458/458 [14:26<00:00,  1.89s/batch, loss=0.279]\n",
      "Epoch 6/10: 100%|██████████████| 458/458 [14:26<00:00,  1.89s/batch, loss=0.305]\n",
      "Epoch 6/10: 100%|██████████████| 458/458 [14:26<00:00,  1.89s/batch, loss=0.276]\n",
      "Epoch 6/10: 100%|██████████████| 458/458 [14:26<00:00,  1.89s/batch, loss=0.303]\n",
      "Validation Loss: 0.2586\n",
      "Validation Loss: 0.0016\n",
      "Epoch [6/10] completed in 890.93 seconds, Loss: 0.2787\n",
      "Epoch 7/10:   0%|                                    | 0/458 [00:00<?, ?batch/s]Validation Loss: 0.2584\n",
      "Validation Loss: 0.0016\n",
      "Epoch [6/10] completed in 890.92 seconds, Loss: 0.3054\n",
      "Validation Loss: 0.2585                              | 0/458 [00:00<?, ?batch/s]\n",
      "Validation Loss: 0.0016\n",
      "Epoch [6/10] completed in 890.99 seconds, Loss: 0.3026\n",
      "Validation Loss: 0.2586                              | 0/458 [00:00<?, ?batch/s]\n",
      "Validation Loss: 0.0016\n",
      "Epoch [6/10] completed in 891.86 seconds, Loss: 0.2760\n",
      "Epoch 7/10: 100%|██████████████| 458/458 [14:41<00:00,  1.93s/batch, loss=0.271]\n",
      "Epoch 7/10: 100%|██████████████| 458/458 [14:42<00:00,  1.93s/batch, loss=0.254]\n",
      "Epoch 7/10: 100%|██████████████| 458/458 [14:42<00:00,  1.93s/batch, loss=0.268]\n",
      "Epoch 7/10: 100%|██████████████| 458/458 [14:42<00:00,  1.93s/batch, loss=0.346]\n",
      "Validation Loss: 0.2441\n",
      "Validation Loss: 0.0015\n",
      "Epoch [7/10] completed in 907.30 seconds, Loss: 0.3463\n",
      "Validation Loss: 0.2439                              | 0/458 [00:00<?, ?batch/s]\n",
      "Validation Loss: 0.0015\n",
      "Epoch [7/10] completed in 907.31 seconds, Loss: 0.2677\n",
      "Validation Loss: 0.2440                              | 0/458 [00:00<?, ?batch/s]\n",
      "Validation Loss: 0.0015\n",
      "Epoch [7/10] completed in 906.46 seconds, Loss: 0.2705\n",
      "Epoch 8/10:   0%|                                    | 0/458 [00:00<?, ?batch/s]Validation Loss: 0.2439\n",
      "Validation Loss: 0.0015\n",
      "Epoch [7/10] completed in 907.42 seconds, Loss: 0.2544\n",
      "Epoch 8/10: 100%|██████████████| 458/458 [14:23<00:00,  1.88s/batch, loss=0.335]\n",
      "Epoch 8/10: 100%|██████████████| 458/458 [14:23<00:00,  1.88s/batch, loss=0.247]\n",
      "Epoch 8/10: 100%|██████████████| 458/458 [14:23<00:00,  1.88s/batch, loss=0.273]\n",
      "Epoch 8/10: 100%|██████████████| 458/458 [14:23<00:00,  1.88s/batch, loss=0.293]\n",
      "Validation Loss: 0.2443\n",
      "Validation Loss: 0.0015\n",
      "Epoch [8/10] completed in 881.23 seconds, Loss: 0.2733\n",
      "Validation Loss: 0.2444                              | 0/458 [00:00<?, ?batch/s]\n",
      "Validation Loss: 0.0015\n",
      "Epoch [8/10] completed in 881.49 seconds, Loss: 0.3351\n",
      "Validation Loss: 0.2443                              | 0/458 [00:00<?, ?batch/s]\n",
      "Validation Loss: 0.0015\n",
      "Epoch [8/10] completed in 881.75 seconds, Loss: 0.2468\n",
      "Validation Loss: 0.2443                              | 0/458 [00:00<?, ?batch/s]\n",
      "Validation Loss: 0.0015\n",
      "Epoch [8/10] completed in 881.78 seconds, Loss: 0.2926\n",
      "Epoch 9/10: 100%|██████████████| 458/458 [14:43<00:00,  1.93s/batch, loss=0.309]\n",
      "Epoch 9/10: 100%|███████████████| 458/458 [14:44<00:00,  1.93s/batch, loss=0.28]\n",
      "Epoch 9/10: 100%|██████████████| 458/458 [14:43<00:00,  1.93s/batch, loss=0.265]\n",
      "Epoch 9/10: 100%|██████████████| 458/458 [14:43<00:00,  1.93s/batch, loss=0.363]\n",
      "Validation Loss: 0.2392\n",
      "Validation Loss: 0.0015\n",
      "Validation Loss: 0.2392\n",
      "Validation Loss: 0.0015\n",
      "Validation Loss: 0.2392\n",
      "Validation Loss: 0.0015\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [9/10] completed in 908.61 seconds, Loss: 0.2654\n",
      "Epoch [9/10] completed in 908.29 seconds, Loss: 0.3630\n",
      "Epoch 10/10:   0%|                                   | 0/458 [00:00<?, ?batch/s]New best model saved at checkpoints/best_model.pth\n",
      "Epoch [9/10] completed in 908.45 seconds, Loss: 0.3086\n",
      "Validation Loss: 0.2392                              | 0/458 [00:00<?, ?batch/s]\n",
      "Validation Loss: 0.0015\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [9/10] completed in 909.42 seconds, Loss: 0.2802\n",
      "Epoch 10/10: 100%|█████████████| 458/458 [14:38<00:00,  1.92s/batch, loss=0.308]\n",
      "Epoch 10/10: 100%|█████████████| 458/458 [14:38<00:00,  1.92s/batch, loss=0.262]\n",
      "Epoch 10/10: 100%|█████████████| 458/458 [14:38<00:00,  1.92s/batch, loss=0.293]\n",
      "Epoch 10/10: 100%|█████████████| 458/458 [14:38<00:00,  1.92s/batch, loss=0.245]\n",
      "Validation Loss: 0.2381\n",
      "Validation Loss: 0.0015\n",
      "Validation Loss: 0.2380\n",
      "Validation Loss: 0.0015\n",
      "Validation Loss: 0.2381\n",
      "Validation Loss: 0.0015\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [10/10] completed in 902.21 seconds, Loss: 0.2445\n",
      "Training completed in 9048.18 seconds.\n",
      "Best model saved at checkpoints/best_model.pth with validation loss: 0.0015\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [10/10] completed in 902.22 seconds, Loss: 0.2624\n",
      "Training completed in 9048.18 seconds.\n",
      "Best model saved at checkpoints/best_model.pth with validation loss: 0.0015\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [10/10] completed in 902.30 seconds, Loss: 0.3076\n",
      "Training completed in 9048.26 seconds.\n",
      "Best model saved at checkpoints/best_model.pth with validation loss: 0.0015\n",
      "Validation Loss: 0.2380\n",
      "Validation Loss: 0.0015\n",
      "New best model saved at checkpoints/best_model.pth\n",
      "Epoch [10/10] completed in 905.28 seconds, Loss: 0.2933\n",
      "Training completed in 9051.84 seconds.\n",
      "Best model saved at checkpoints/best_model.pth with validation loss: 0.0015\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=4,5,6,7 torchrun --nproc_per_node=4 module/train4.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad1af68d-1029-4643-ba78-d5b21118a1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on Validation Set\n",
      "Model already exists at models/swin_tiny_patch4_window7_224.ms_in22k.pth\n",
      "Pretrained weights loaded successfully, ignoring mismatched keys.\n",
      "Current Allocated Memory: 0.27 GB\n",
      "Max Allocated Memory: 0.41 GB\n",
      "Current Reserved Memory: 0.51 GB\n",
      "Max Reserved Memory: 0.51 GB\n",
      "Evaluation Results on val set: MAE = 32.0794, RMSE = 73.7011\n",
      "\n",
      "Evaluating on Test Set\n",
      "Model already exists at models/swin_tiny_patch4_window7_224.ms_in22k.pth\n",
      "Pretrained weights loaded successfully, ignoring mismatched keys.\n",
      "Current Allocated Memory: 0.27 GB\n",
      "Max Allocated Memory: 0.41 GB\n",
      "Current Reserved Memory: 0.51 GB\n",
      "Max Reserved Memory: 0.51 GB\n",
      "Evaluation Results on test set: MAE = 32.5422, RMSE = 115.2307\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=7 python module/evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be984f2-4623-4b9c-bf78-1bc538255556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists at models/swin_tiny_patch4_window7_224.ms_in22k.pth\n",
      "Pretrained weights loaded successfully, ignoring mismatched keys.\n",
      "Rank 0 - dataset size: 1286, batches: 161\n",
      "Before all_reduce - Rank 0: ae = 41449.97265625, se = 7012864.0\n",
      "After all_reduce - Rank 0: ae = 41449.97265625, se = 7012864.0\n",
      "Val set: MAE = 32.1817, RMSE = 73.7887\n",
      "Rank 0 - dataset size: 1190, batches: 149\n",
      "Before all_reduce - Rank 0: ae = 38402.7265625, se = 15910703.0\n",
      "After all_reduce - Rank 0: ae = 38402.7265625, se = 15910703.0\n",
      "Test set: MAE = 32.2171, RMSE = 115.5331\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=6 torchrun --nproc_per_node=1 module/evaluate2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ec2eb-d0f9-4ea7-bd50-f3d6768ac150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8623fe29-3418-4c7e-a3a0-4ab3609a7486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOCA modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4be6140-0199-48bf-ad5f-04c7b316d498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "0\n",
      "1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/train.py\", line 242, in <module>\n",
      "    train(args)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/train.py\", line 130, in train\n",
      "    out, aux_out = model(img, bboxes)  # Forward pass\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 963, in forward\n",
      "    output = self.module(*inputs[0], **kwargs[0])\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/architecture/loca.py\", line 86, in forward\n",
      "    image_features = self.encoder(src, pos_emb, src_key_padding_mask=None, src_mask=None)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/architecture/transformer.py\", line 35, in forward\n",
      "    output = layer(output, pos_emb, src_mask, src_key_padding_mask)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/architecture/transformer.py\", line 72, in forward\n",
      "    src = src + self.dropout1(self.self_attn(\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/activation.py\", line 1038, in forward\n",
      "    attn_output, attn_output_weights = F.multi_head_attention_forward(\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/functional.py\", line 5358, in multi_head_attention_forward\n",
      "    attn_output, attn_output_weights = _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/functional.py\", line 5039, in _scaled_dot_product_attention\n",
      "    attn = dropout(attn, p=dropout_p)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/functional.py\", line 1279, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB (GPU 1; 10.75 GiB total capacity; 6.93 GiB already allocated; 973.81 MiB free; 8.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/train.py\", line 242, in <module>\n",
      "    train(args)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/train.py\", line 130, in train\n",
      "    out, aux_out = model(img, bboxes)  # Forward pass\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 963, in forward\n",
      "    output = self.module(*inputs[0], **kwargs[0])\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/architecture/loca.py\", line 86, in forward\n",
      "    image_features = self.encoder(src, pos_emb, src_key_padding_mask=None, src_mask=None)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/architecture/transformer.py\", line 35, in forward\n",
      "    output = layer(output, pos_emb, src_mask, src_key_padding_mask)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/architecture/transformer.py\", line 72, in forward\n",
      "    src = src + self.dropout1(self.self_attn(\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/activation.py\", line 1038, in forward\n",
      "    attn_output, attn_output_weights = F.multi_head_attention_forward(\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/functional.py\", line 5358, in multi_head_attention_forward\n",
      "    attn_output, attn_output_weights = _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/functional.py\", line 5039, in _scaled_dot_product_attention\n",
      "    attn = dropout(attn, p=dropout_p)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/functional.py\", line 1279, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 10.75 GiB total capacity; 6.93 GiB already allocated; 973.81 MiB free; 8.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 324277) of binary: /opt/miniconda/envs/Rey1/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda/envs/Rey1/bin/torchrun\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('torch==1.11.0', 'console_scripts', 'torchrun')())\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/run.py\", line 724, in main\n",
      "    run(args)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/run.py\", line 715, in run\n",
      "    elastic_launch(\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 245, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "module2/train.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2025-02-04_18:36:50\n",
      "  host      : viplab-G481-H81-00\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 324278)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-02-04_18:36:50\n",
      "  host      : viplab-G481-H81-00\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 324277)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=6,7 torchrun --nproc_per_node=2 module2/train.py --model_name efficient1 --backbone resnet50 --swav_backbone --pre_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7cac844-f3ef-4107-afb2-5c713daffea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/evaluate.py\", line 101, in <module>\n",
      "    evaluate(args)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/evaluate.py\", line 48, in evaluate\n",
      "    model.load_state_dict(state_dict)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1497, in load_state_dict\n",
      "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
      "RuntimeError: Error(s) in loading state_dict for DistributedDataParallel:\n",
      "\tMissing key(s) in state_dict: \"module.backbone.backbone.conv1.weight\", \"module.backbone.backbone.bn1.weight\", \"module.backbone.backbone.bn1.bias\", \"module.backbone.backbone.bn1.running_mean\", \"module.backbone.backbone.bn1.running_var\", \"module.backbone.backbone.layer1.0.conv1.weight\", \"module.backbone.backbone.layer1.0.bn1.weight\", \"module.backbone.backbone.layer1.0.bn1.bias\", \"module.backbone.backbone.layer1.0.bn1.running_mean\", \"module.backbone.backbone.layer1.0.bn1.running_var\", \"module.backbone.backbone.layer1.0.conv2.weight\", \"module.backbone.backbone.layer1.0.bn2.weight\", \"module.backbone.backbone.layer1.0.bn2.bias\", \"module.backbone.backbone.layer1.0.bn2.running_mean\", \"module.backbone.backbone.layer1.0.bn2.running_var\", \"module.backbone.backbone.layer1.0.conv3.weight\", \"module.backbone.backbone.layer1.0.bn3.weight\", \"module.backbone.backbone.layer1.0.bn3.bias\", \"module.backbone.backbone.layer1.0.bn3.running_mean\", \"module.backbone.backbone.layer1.0.bn3.running_var\", \"module.backbone.backbone.layer1.0.downsample.0.weight\", \"module.backbone.backbone.layer1.0.downsample.1.weight\", \"module.backbone.backbone.layer1.0.downsample.1.bias\", \"module.backbone.backbone.layer1.0.downsample.1.running_mean\", \"module.backbone.backbone.layer1.0.downsample.1.running_var\", \"module.backbone.backbone.layer1.1.conv1.weight\", \"module.backbone.backbone.layer1.1.bn1.weight\", \"module.backbone.backbone.layer1.1.bn1.bias\", \"module.backbone.backbone.layer1.1.bn1.running_mean\", \"module.backbone.backbone.layer1.1.bn1.running_var\", \"module.backbone.backbone.layer1.1.conv2.weight\", \"module.backbone.backbone.layer1.1.bn2.weight\", \"module.backbone.backbone.layer1.1.bn2.bias\", \"module.backbone.backbone.layer1.1.bn2.running_mean\", \"module.backbone.backbone.layer1.1.bn2.running_var\", \"module.backbone.backbone.layer1.1.conv3.weight\", \"module.backbone.backbone.layer1.1.bn3.weight\", \"module.backbone.backbone.layer1.1.bn3.bias\", \"module.backbone.backbone.layer1.1.bn3.running_mean\", \"module.backbone.backbone.layer1.1.bn3.running_var\", \"module.backbone.backbone.layer1.2.conv1.weight\", \"module.backbone.backbone.layer1.2.bn1.weight\", \"module.backbone.backbone.layer1.2.bn1.bias\", \"module.backbone.backbone.layer1.2.bn1.running_mean\", \"module.backbone.backbone.layer1.2.bn1.running_var\", \"module.backbone.backbone.layer1.2.conv2.weight\", \"module.backbone.backbone.layer1.2.bn2.weight\", \"module.backbone.backbone.layer1.2.bn2.bias\", \"module.backbone.backbone.layer1.2.bn2.running_mean\", \"module.backbone.backbone.layer1.2.bn2.running_var\", \"module.backbone.backbone.layer1.2.conv3.weight\", \"module.backbone.backbone.layer1.2.bn3.weight\", \"module.backbone.backbone.layer1.2.bn3.bias\", \"module.backbone.backbone.layer1.2.bn3.running_mean\", \"module.backbone.backbone.layer1.2.bn3.running_var\", \"module.backbone.backbone.layer2.0.conv1.weight\", \"module.backbone.backbone.layer2.0.bn1.weight\", \"module.backbone.backbone.layer2.0.bn1.bias\", \"module.backbone.backbone.layer2.0.bn1.running_mean\", \"module.backbone.backbone.layer2.0.bn1.running_var\", \"module.backbone.backbone.layer2.0.conv2.weight\", \"module.backbone.backbone.layer2.0.bn2.weight\", \"module.backbone.backbone.layer2.0.bn2.bias\", \"module.backbone.backbone.layer2.0.bn2.running_mean\", \"module.backbone.backbone.layer2.0.bn2.running_var\", \"module.backbone.backbone.layer2.0.conv3.weight\", \"module.backbone.backbone.layer2.0.bn3.weight\", \"module.backbone.backbone.layer2.0.bn3.bias\", \"module.backbone.backbone.layer2.0.bn3.running_mean\", \"module.backbone.backbone.layer2.0.bn3.running_var\", \"module.backbone.backbone.layer2.0.downsample.0.weight\", \"module.backbone.backbone.layer2.0.downsample.1.weight\", \"module.backbone.backbone.layer2.0.downsample.1.bias\", \"module.backbone.backbone.layer2.0.downsample.1.running_mean\", \"module.backbone.backbone.layer2.0.downsample.1.running_var\", \"module.backbone.backbone.layer2.1.conv1.weight\", \"module.backbone.backbone.layer2.1.bn1.weight\", \"module.backbone.backbone.layer2.1.bn1.bias\", \"module.backbone.backbone.layer2.1.bn1.running_mean\", \"module.backbone.backbone.layer2.1.bn1.running_var\", \"module.backbone.backbone.layer2.1.conv2.weight\", \"module.backbone.backbone.layer2.1.bn2.weight\", \"module.backbone.backbone.layer2.1.bn2.bias\", \"module.backbone.backbone.layer2.1.bn2.running_mean\", \"module.backbone.backbone.layer2.1.bn2.running_var\", \"module.backbone.backbone.layer2.1.conv3.weight\", \"module.backbone.backbone.layer2.1.bn3.weight\", \"module.backbone.backbone.layer2.1.bn3.bias\", \"module.backbone.backbone.layer2.1.bn3.running_mean\", \"module.backbone.backbone.layer2.1.bn3.running_var\", \"module.backbone.backbone.layer2.2.conv1.weight\", \"module.backbone.backbone.layer2.2.bn1.weight\", \"module.backbone.backbone.layer2.2.bn1.bias\", \"module.backbone.backbone.layer2.2.bn1.running_mean\", \"module.backbone.backbone.layer2.2.bn1.running_var\", \"module.backbone.backbone.layer2.2.conv2.weight\", \"module.backbone.backbone.layer2.2.bn2.weight\", \"module.backbone.backbone.layer2.2.bn2.bias\", \"module.backbone.backbone.layer2.2.bn2.running_mean\", \"module.backbone.backbone.layer2.2.bn2.running_var\", \"module.backbone.backbone.layer2.2.conv3.weight\", \"module.backbone.backbone.layer2.2.bn3.weight\", \"module.backbone.backbone.layer2.2.bn3.bias\", \"module.backbone.backbone.layer2.2.bn3.running_mean\", \"module.backbone.backbone.layer2.2.bn3.running_var\", \"module.backbone.backbone.layer2.3.conv1.weight\", \"module.backbone.backbone.layer2.3.bn1.weight\", \"module.backbone.backbone.layer2.3.bn1.bias\", \"module.backbone.backbone.layer2.3.bn1.running_mean\", \"module.backbone.backbone.layer2.3.bn1.running_var\", \"module.backbone.backbone.layer2.3.conv2.weight\", \"module.backbone.backbone.layer2.3.bn2.weight\", \"module.backbone.backbone.layer2.3.bn2.bias\", \"module.backbone.backbone.layer2.3.bn2.running_mean\", \"module.backbone.backbone.layer2.3.bn2.running_var\", \"module.backbone.backbone.layer2.3.conv3.weight\", \"module.backbone.backbone.layer2.3.bn3.weight\", \"module.backbone.backbone.layer2.3.bn3.bias\", \"module.backbone.backbone.layer2.3.bn3.running_mean\", \"module.backbone.backbone.layer2.3.bn3.running_var\", \"module.backbone.backbone.layer3.0.conv1.weight\", \"module.backbone.backbone.layer3.0.bn1.weight\", \"module.backbone.backbone.layer3.0.bn1.bias\", \"module.backbone.backbone.layer3.0.bn1.running_mean\", \"module.backbone.backbone.layer3.0.bn1.running_var\", \"module.backbone.backbone.layer3.0.conv2.weight\", \"module.backbone.backbone.layer3.0.bn2.weight\", \"module.backbone.backbone.layer3.0.bn2.bias\", \"module.backbone.backbone.layer3.0.bn2.running_mean\", \"module.backbone.backbone.layer3.0.bn2.running_var\", \"module.backbone.backbone.layer3.0.conv3.weight\", \"module.backbone.backbone.layer3.0.bn3.weight\", \"module.backbone.backbone.layer3.0.bn3.bias\", \"module.backbone.backbone.layer3.0.bn3.running_mean\", \"module.backbone.backbone.layer3.0.bn3.running_var\", \"module.backbone.backbone.layer3.0.downsample.0.weight\", \"module.backbone.backbone.layer3.0.downsample.1.weight\", \"module.backbone.backbone.layer3.0.downsample.1.bias\", \"module.backbone.backbone.layer3.0.downsample.1.running_mean\", \"module.backbone.backbone.layer3.0.downsample.1.running_var\", \"module.backbone.backbone.layer3.1.conv1.weight\", \"module.backbone.backbone.layer3.1.bn1.weight\", \"module.backbone.backbone.layer3.1.bn1.bias\", \"module.backbone.backbone.layer3.1.bn1.running_mean\", \"module.backbone.backbone.layer3.1.bn1.running_var\", \"module.backbone.backbone.layer3.1.conv2.weight\", \"module.backbone.backbone.layer3.1.bn2.weight\", \"module.backbone.backbone.layer3.1.bn2.bias\", \"module.backbone.backbone.layer3.1.bn2.running_mean\", \"module.backbone.backbone.layer3.1.bn2.running_var\", \"module.backbone.backbone.layer3.1.conv3.weight\", \"module.backbone.backbone.layer3.1.bn3.weight\", \"module.backbone.backbone.layer3.1.bn3.bias\", \"module.backbone.backbone.layer3.1.bn3.running_mean\", \"module.backbone.backbone.layer3.1.bn3.running_var\", \"module.backbone.backbone.layer3.2.conv1.weight\", \"module.backbone.backbone.layer3.2.bn1.weight\", \"module.backbone.backbone.layer3.2.bn1.bias\", \"module.backbone.backbone.layer3.2.bn1.running_mean\", \"module.backbone.backbone.layer3.2.bn1.running_var\", \"module.backbone.backbone.layer3.2.conv2.weight\", \"module.backbone.backbone.layer3.2.bn2.weight\", \"module.backbone.backbone.layer3.2.bn2.bias\", \"module.backbone.backbone.layer3.2.bn2.running_mean\", \"module.backbone.backbone.layer3.2.bn2.running_var\", \"module.backbone.backbone.layer3.2.conv3.weight\", \"module.backbone.backbone.layer3.2.bn3.weight\", \"module.backbone.backbone.layer3.2.bn3.bias\", \"module.backbone.backbone.layer3.2.bn3.running_mean\", \"module.backbone.backbone.layer3.2.bn3.running_var\", \"module.backbone.backbone.layer3.3.conv1.weight\", \"module.backbone.backbone.layer3.3.bn1.weight\", \"module.backbone.backbone.layer3.3.bn1.bias\", \"module.backbone.backbone.layer3.3.bn1.running_mean\", \"module.backbone.backbone.layer3.3.bn1.running_var\", \"module.backbone.backbone.layer3.3.conv2.weight\", \"module.backbone.backbone.layer3.3.bn2.weight\", \"module.backbone.backbone.layer3.3.bn2.bias\", \"module.backbone.backbone.layer3.3.bn2.running_mean\", \"module.backbone.backbone.layer3.3.bn2.running_var\", \"module.backbone.backbone.layer3.3.conv3.weight\", \"module.backbone.backbone.layer3.3.bn3.weight\", \"module.backbone.backbone.layer3.3.bn3.bias\", \"module.backbone.backbone.layer3.3.bn3.running_mean\", \"module.backbone.backbone.layer3.3.bn3.running_var\", \"module.backbone.backbone.layer3.4.conv1.weight\", \"module.backbone.backbone.layer3.4.bn1.weight\", \"module.backbone.backbone.layer3.4.bn1.bias\", \"module.backbone.backbone.layer3.4.bn1.running_mean\", \"module.backbone.backbone.layer3.4.bn1.running_var\", \"module.backbone.backbone.layer3.4.conv2.weight\", \"module.backbone.backbone.layer3.4.bn2.weight\", \"module.backbone.backbone.layer3.4.bn2.bias\", \"module.backbone.backbone.layer3.4.bn2.running_mean\", \"module.backbone.backbone.layer3.4.bn2.running_var\", \"module.backbone.backbone.layer3.4.conv3.weight\", \"module.backbone.backbone.layer3.4.bn3.weight\", \"module.backbone.backbone.layer3.4.bn3.bias\", \"module.backbone.backbone.layer3.4.bn3.running_mean\", \"module.backbone.backbone.layer3.4.bn3.running_var\", \"module.backbone.backbone.layer3.5.conv1.weight\", \"module.backbone.backbone.layer3.5.bn1.weight\", \"module.backbone.backbone.layer3.5.bn1.bias\", \"module.backbone.backbone.layer3.5.bn1.running_mean\", \"module.backbone.backbone.layer3.5.bn1.running_var\", \"module.backbone.backbone.layer3.5.conv2.weight\", \"module.backbone.backbone.layer3.5.bn2.weight\", \"module.backbone.backbone.layer3.5.bn2.bias\", \"module.backbone.backbone.layer3.5.bn2.running_mean\", \"module.backbone.backbone.layer3.5.bn2.running_var\", \"module.backbone.backbone.layer3.5.conv3.weight\", \"module.backbone.backbone.layer3.5.bn3.weight\", \"module.backbone.backbone.layer3.5.bn3.bias\", \"module.backbone.backbone.layer3.5.bn3.running_mean\", \"module.backbone.backbone.layer3.5.bn3.running_var\", \"module.backbone.backbone.layer4.0.conv1.weight\", \"module.backbone.backbone.layer4.0.bn1.weight\", \"module.backbone.backbone.layer4.0.bn1.bias\", \"module.backbone.backbone.layer4.0.bn1.running_mean\", \"module.backbone.backbone.layer4.0.bn1.running_var\", \"module.backbone.backbone.layer4.0.conv2.weight\", \"module.backbone.backbone.layer4.0.bn2.weight\", \"module.backbone.backbone.layer4.0.bn2.bias\", \"module.backbone.backbone.layer4.0.bn2.running_mean\", \"module.backbone.backbone.layer4.0.bn2.running_var\", \"module.backbone.backbone.layer4.0.conv3.weight\", \"module.backbone.backbone.layer4.0.bn3.weight\", \"module.backbone.backbone.layer4.0.bn3.bias\", \"module.backbone.backbone.layer4.0.bn3.running_mean\", \"module.backbone.backbone.layer4.0.bn3.running_var\", \"module.backbone.backbone.layer4.0.downsample.0.weight\", \"module.backbone.backbone.layer4.0.downsample.1.weight\", \"module.backbone.backbone.layer4.0.downsample.1.bias\", \"module.backbone.backbone.layer4.0.downsample.1.running_mean\", \"module.backbone.backbone.layer4.0.downsample.1.running_var\", \"module.backbone.backbone.layer4.1.conv1.weight\", \"module.backbone.backbone.layer4.1.bn1.weight\", \"module.backbone.backbone.layer4.1.bn1.bias\", \"module.backbone.backbone.layer4.1.bn1.running_mean\", \"module.backbone.backbone.layer4.1.bn1.running_var\", \"module.backbone.backbone.layer4.1.conv2.weight\", \"module.backbone.backbone.layer4.1.bn2.weight\", \"module.backbone.backbone.layer4.1.bn2.bias\", \"module.backbone.backbone.layer4.1.bn2.running_mean\", \"module.backbone.backbone.layer4.1.bn2.running_var\", \"module.backbone.backbone.layer4.1.conv3.weight\", \"module.backbone.backbone.layer4.1.bn3.weight\", \"module.backbone.backbone.layer4.1.bn3.bias\", \"module.backbone.backbone.layer4.1.bn3.running_mean\", \"module.backbone.backbone.layer4.1.bn3.running_var\", \"module.backbone.backbone.layer4.2.conv1.weight\", \"module.backbone.backbone.layer4.2.bn1.weight\", \"module.backbone.backbone.layer4.2.bn1.bias\", \"module.backbone.backbone.layer4.2.bn1.running_mean\", \"module.backbone.backbone.layer4.2.bn1.running_var\", \"module.backbone.backbone.layer4.2.conv2.weight\", \"module.backbone.backbone.layer4.2.bn2.weight\", \"module.backbone.backbone.layer4.2.bn2.bias\", \"module.backbone.backbone.layer4.2.bn2.running_mean\", \"module.backbone.backbone.layer4.2.bn2.running_var\", \"module.backbone.backbone.layer4.2.conv3.weight\", \"module.backbone.backbone.layer4.2.bn3.weight\", \"module.backbone.backbone.layer4.2.bn3.bias\", \"module.backbone.backbone.layer4.2.bn3.running_mean\", \"module.backbone.backbone.layer4.2.bn3.running_var\", \"module.backbone.backbone.fc.weight\", \"module.backbone.backbone.fc.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"module.backbone.backbone.patch_embed.proj.weight\", \"module.backbone.backbone.patch_embed.proj.bias\", \"module.backbone.backbone.patch_embed.norm.weight\", \"module.backbone.backbone.patch_embed.norm.bias\", \"module.backbone.backbone.layers.0.blocks.0.norm1.weight\", \"module.backbone.backbone.layers.0.blocks.0.norm1.bias\", \"module.backbone.backbone.layers.0.blocks.0.attn.relative_position_bias_table\", \"module.backbone.backbone.layers.0.blocks.0.attn.qkv.weight\", \"module.backbone.backbone.layers.0.blocks.0.attn.qkv.bias\", \"module.backbone.backbone.layers.0.blocks.0.attn.proj.weight\", \"module.backbone.backbone.layers.0.blocks.0.attn.proj.bias\", \"module.backbone.backbone.layers.0.blocks.0.norm2.weight\", \"module.backbone.backbone.layers.0.blocks.0.norm2.bias\", \"module.backbone.backbone.layers.0.blocks.0.mlp.fc1.weight\", \"module.backbone.backbone.layers.0.blocks.0.mlp.fc1.bias\", \"module.backbone.backbone.layers.0.blocks.0.mlp.fc2.weight\", \"module.backbone.backbone.layers.0.blocks.0.mlp.fc2.bias\", \"module.backbone.backbone.layers.0.blocks.1.norm1.weight\", \"module.backbone.backbone.layers.0.blocks.1.norm1.bias\", \"module.backbone.backbone.layers.0.blocks.1.attn.relative_position_bias_table\", \"module.backbone.backbone.layers.0.blocks.1.attn.qkv.weight\", \"module.backbone.backbone.layers.0.blocks.1.attn.qkv.bias\", \"module.backbone.backbone.layers.0.blocks.1.attn.proj.weight\", \"module.backbone.backbone.layers.0.blocks.1.attn.proj.bias\", \"module.backbone.backbone.layers.0.blocks.1.norm2.weight\", \"module.backbone.backbone.layers.0.blocks.1.norm2.bias\", \"module.backbone.backbone.layers.0.blocks.1.mlp.fc1.weight\", \"module.backbone.backbone.layers.0.blocks.1.mlp.fc1.bias\", \"module.backbone.backbone.layers.0.blocks.1.mlp.fc2.weight\", \"module.backbone.backbone.layers.0.blocks.1.mlp.fc2.bias\", \"module.backbone.backbone.layers.1.downsample.norm.weight\", \"module.backbone.backbone.layers.1.downsample.norm.bias\", \"module.backbone.backbone.layers.1.downsample.reduction.weight\", \"module.backbone.backbone.layers.1.blocks.0.norm1.weight\", \"module.backbone.backbone.layers.1.blocks.0.norm1.bias\", \"module.backbone.backbone.layers.1.blocks.0.attn.relative_position_bias_table\", \"module.backbone.backbone.layers.1.blocks.0.attn.qkv.weight\", \"module.backbone.backbone.layers.1.blocks.0.attn.qkv.bias\", \"module.backbone.backbone.layers.1.blocks.0.attn.proj.weight\", \"module.backbone.backbone.layers.1.blocks.0.attn.proj.bias\", \"module.backbone.backbone.layers.1.blocks.0.norm2.weight\", \"module.backbone.backbone.layers.1.blocks.0.norm2.bias\", \"module.backbone.backbone.layers.1.blocks.0.mlp.fc1.weight\", \"module.backbone.backbone.layers.1.blocks.0.mlp.fc1.bias\", \"module.backbone.backbone.layers.1.blocks.0.mlp.fc2.weight\", \"module.backbone.backbone.layers.1.blocks.0.mlp.fc2.bias\", \"module.backbone.backbone.layers.1.blocks.1.norm1.weight\", \"module.backbone.backbone.layers.1.blocks.1.norm1.bias\", \"module.backbone.backbone.layers.1.blocks.1.attn.relative_position_bias_table\", \"module.backbone.backbone.layers.1.blocks.1.attn.qkv.weight\", \"module.backbone.backbone.layers.1.blocks.1.attn.qkv.bias\", \"module.backbone.backbone.layers.1.blocks.1.attn.proj.weight\", \"module.backbone.backbone.layers.1.blocks.1.attn.proj.bias\", \"module.backbone.backbone.layers.1.blocks.1.norm2.weight\", \"module.backbone.backbone.layers.1.blocks.1.norm2.bias\", \"module.backbone.backbone.layers.1.blocks.1.mlp.fc1.weight\", \"module.backbone.backbone.layers.1.blocks.1.mlp.fc1.bias\", \"module.backbone.backbone.layers.1.blocks.1.mlp.fc2.weight\", \"module.backbone.backbone.layers.1.blocks.1.mlp.fc2.bias\", \"module.backbone.backbone.layers.2.downsample.norm.weight\", \"module.backbone.backbone.layers.2.downsample.norm.bias\", \"module.backbone.backbone.layers.2.downsample.reduction.weight\", \"module.backbone.backbone.layers.2.blocks.0.norm1.weight\", \"module.backbone.backbone.layers.2.blocks.0.norm1.bias\", \"module.backbone.backbone.layers.2.blocks.0.attn.relative_position_bias_table\", \"module.backbone.backbone.layers.2.blocks.0.attn.qkv.weight\", \"module.backbone.backbone.layers.2.blocks.0.attn.qkv.bias\", \"module.backbone.backbone.layers.2.blocks.0.attn.proj.weight\", \"module.backbone.backbone.layers.2.blocks.0.attn.proj.bias\", \"module.backbone.backbone.layers.2.blocks.0.norm2.weight\", \"module.backbone.backbone.layers.2.blocks.0.norm2.bias\", \"module.backbone.backbone.layers.2.blocks.0.mlp.fc1.weight\", \"module.backbone.backbone.layers.2.blocks.0.mlp.fc1.bias\", \"module.backbone.backbone.layers.2.blocks.0.mlp.fc2.weight\", \"module.backbone.backbone.layers.2.blocks.0.mlp.fc2.bias\", \"module.backbone.backbone.layers.2.blocks.1.norm1.weight\", \"module.backbone.backbone.layers.2.blocks.1.norm1.bias\", \"module.backbone.backbone.layers.2.blocks.1.attn.relative_position_bias_table\", \"module.backbone.backbone.layers.2.blocks.1.attn.qkv.weight\", \"module.backbone.backbone.layers.2.blocks.1.attn.qkv.bias\", \"module.backbone.backbone.layers.2.blocks.1.attn.proj.weight\", \"module.backbone.backbone.layers.2.blocks.1.attn.proj.bias\", \"module.backbone.backbone.layers.2.blocks.1.norm2.weight\", \"module.backbone.backbone.layers.2.blocks.1.norm2.bias\", \"module.backbone.backbone.layers.2.blocks.1.mlp.fc1.weight\", \"module.backbone.backbone.layers.2.blocks.1.mlp.fc1.bias\", \"module.backbone.backbone.layers.2.blocks.1.mlp.fc2.weight\", \"module.backbone.backbone.layers.2.blocks.1.mlp.fc2.bias\", \"module.backbone.backbone.layers.2.blocks.2.norm1.weight\", \"module.backbone.backbone.layers.2.blocks.2.norm1.bias\", \"module.backbone.backbone.layers.2.blocks.2.attn.relative_position_bias_table\", \"module.backbone.backbone.layers.2.blocks.2.attn.qkv.weight\", \"module.backbone.backbone.layers.2.blocks.2.attn.qkv.bias\", \"module.backbone.backbone.layers.2.blocks.2.attn.proj.weight\", \"module.backbone.backbone.layers.2.blocks.2.attn.proj.bias\", \"module.backbone.backbone.layers.2.blocks.2.norm2.weight\", \"module.backbone.backbone.layers.2.blocks.2.norm2.bias\", \"module.backbone.backbone.layers.2.blocks.2.mlp.fc1.weight\", \"module.backbone.backbone.layers.2.blocks.2.mlp.fc1.bias\", \"module.backbone.backbone.layers.2.blocks.2.mlp.fc2.weight\", \"module.backbone.backbone.layers.2.blocks.2.mlp.fc2.bias\", \"module.backbone.backbone.layers.2.blocks.3.norm1.weight\", \"module.backbone.backbone.layers.2.blocks.3.norm1.bias\", \"module.backbone.backbone.layers.2.blocks.3.attn.relative_position_bias_table\", \"module.backbone.backbone.layers.2.blocks.3.attn.qkv.weight\", \"module.backbone.backbone.layers.2.blocks.3.attn.qkv.bias\", \"module.backbone.backbone.layers.2.blocks.3.attn.proj.weight\", \"module.backbone.backbone.layers.2.blocks.3.attn.proj.bias\", \"module.backbone.backbone.layers.2.blocks.3.norm2.weight\", \"module.backbone.backbone.layers.2.blocks.3.norm2.bias\", \"module.backbone.backbone.layers.2.blocks.3.mlp.fc1.weight\", \"module.backbone.backbone.layers.2.blocks.3.mlp.fc1.bias\", \"module.backbone.backbone.layers.2.blocks.3.mlp.fc2.weight\", \"module.backbone.backbone.layers.2.blocks.3.mlp.fc2.bias\", \"module.backbone.backbone.layers.2.blocks.4.norm1.weight\", \"module.backbone.backbone.layers.2.blocks.4.norm1.bias\", \"module.backbone.backbone.layers.2.blocks.4.attn.relative_position_bias_table\", \"module.backbone.backbone.layers.2.blocks.4.attn.qkv.weight\", \"module.backbone.backbone.layers.2.blocks.4.attn.qkv.bias\", \"module.backbone.backbone.layers.2.blocks.4.attn.proj.weight\", \"module.backbone.backbone.layers.2.blocks.4.attn.proj.bias\", \"module.backbone.backbone.layers.2.blocks.4.norm2.weight\", \"module.backbone.backbone.layers.2.blocks.4.norm2.bias\", \"module.backbone.backbone.layers.2.blocks.4.mlp.fc1.weight\", \"module.backbone.backbone.layers.2.blocks.4.mlp.fc1.bias\", \"module.backbone.backbone.layers.2.blocks.4.mlp.fc2.weight\", \"module.backbone.backbone.layers.2.blocks.4.mlp.fc2.bias\", \"module.backbone.backbone.layers.2.blocks.5.norm1.weight\", \"module.backbone.backbone.layers.2.blocks.5.norm1.bias\", \"module.backbone.backbone.layers.2.blocks.5.attn.relative_position_bias_table\", \"module.backbone.backbone.layers.2.blocks.5.attn.qkv.weight\", \"module.backbone.backbone.layers.2.blocks.5.attn.qkv.bias\", \"module.backbone.backbone.layers.2.blocks.5.attn.proj.weight\", \"module.backbone.backbone.layers.2.blocks.5.attn.proj.bias\", \"module.backbone.backbone.layers.2.blocks.5.norm2.weight\", \"module.backbone.backbone.layers.2.blocks.5.norm2.bias\", \"module.backbone.backbone.layers.2.blocks.5.mlp.fc1.weight\", \"module.backbone.backbone.layers.2.blocks.5.mlp.fc1.bias\", \"module.backbone.backbone.layers.2.blocks.5.mlp.fc2.weight\", \"module.backbone.backbone.layers.2.blocks.5.mlp.fc2.bias\", \"module.backbone.backbone.layers.3.downsample.norm.weight\", \"module.backbone.backbone.layers.3.downsample.norm.bias\", \"module.backbone.backbone.layers.3.downsample.reduction.weight\", \"module.backbone.backbone.layers.3.blocks.0.norm1.weight\", \"module.backbone.backbone.layers.3.blocks.0.norm1.bias\", \"module.backbone.backbone.layers.3.blocks.0.attn.relative_position_bias_table\", \"module.backbone.backbone.layers.3.blocks.0.attn.qkv.weight\", \"module.backbone.backbone.layers.3.blocks.0.attn.qkv.bias\", \"module.backbone.backbone.layers.3.blocks.0.attn.proj.weight\", \"module.backbone.backbone.layers.3.blocks.0.attn.proj.bias\", \"module.backbone.backbone.layers.3.blocks.0.norm2.weight\", \"module.backbone.backbone.layers.3.blocks.0.norm2.bias\", \"module.backbone.backbone.layers.3.blocks.0.mlp.fc1.weight\", \"module.backbone.backbone.layers.3.blocks.0.mlp.fc1.bias\", \"module.backbone.backbone.layers.3.blocks.0.mlp.fc2.weight\", \"module.backbone.backbone.layers.3.blocks.0.mlp.fc2.bias\", \"module.backbone.backbone.layers.3.blocks.1.norm1.weight\", \"module.backbone.backbone.layers.3.blocks.1.norm1.bias\", \"module.backbone.backbone.layers.3.blocks.1.attn.relative_position_bias_table\", \"module.backbone.backbone.layers.3.blocks.1.attn.qkv.weight\", \"module.backbone.backbone.layers.3.blocks.1.attn.qkv.bias\", \"module.backbone.backbone.layers.3.blocks.1.attn.proj.weight\", \"module.backbone.backbone.layers.3.blocks.1.attn.proj.bias\", \"module.backbone.backbone.layers.3.blocks.1.norm2.weight\", \"module.backbone.backbone.layers.3.blocks.1.norm2.bias\", \"module.backbone.backbone.layers.3.blocks.1.mlp.fc1.weight\", \"module.backbone.backbone.layers.3.blocks.1.mlp.fc1.bias\", \"module.backbone.backbone.layers.3.blocks.1.mlp.fc2.weight\", \"module.backbone.backbone.layers.3.blocks.1.mlp.fc2.bias\", \"module.backbone.backbone.norm.weight\", \"module.backbone.backbone.norm.bias\". \n",
      "\tsize mismatch for module.input_proj.weight: copying a param with shape torch.Size([256, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 3584, 1, 1]).\n",
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 324944) of binary: /opt/miniconda/envs/Rey1/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda/envs/Rey1/bin/torchrun\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('torch==1.11.0', 'console_scripts', 'torchrun')())\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/run.py\", line 724, in main\n",
      "    run(args)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/run.py\", line 715, in run\n",
      "    elastic_launch(\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 245, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "module2/evaluate.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-02-04_18:37:02\n",
      "  host      : viplab-G481-H81-00\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 324944)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=6 torchrun --nproc_per_node=1 module2/evaluate.py --model_name efficient1 --backbone resnet50 --swav_backbone --pre_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7d305f-d3b1-4bbc-8141-3e4e2b4c9707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3640eedf-6332-4ad0-9c70-c998e16baf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper i-ELF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3b896f5-de0e-423a-b238-ad3930a5e9fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "Downloading model swin_tiny_patch4_window7_224...\n",
      "Downloading model swin_tiny_patch4_window7_224...\n",
      "Model saved to pretrained_models/swin_tiny_patch4_window7_224.pthModel saved to pretrained_models/swin_tiny_patch4_window7_224.pth\n",
      "\n",
      "1\n",
      "0\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/train.py\", line 267, in <module>\n",
      "    train(args)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/train.py\", line 146, in train\n",
      "    out, aux_out, exemplar_features = model(img, bboxes)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 963, in forward\n",
      "    output = self.module(*inputs[0], **kwargs[0])\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/architecture/engine.py\", line 89, in forward\n",
      "    backbone_features = self.backbone(x)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/architecture/backbone.py\", line 175, in forward\n",
      "    features = self.backbone.forward_features(x)  # Sekarang akan mengembalikan list features\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/architecture/backbone.py\", line 51, in _forward_features\n",
      "    x = self.pos_drop(x)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1185, in __getattr__\n",
      "    raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
      "AttributeError: 'SwinTransformer' object has no attribute 'pos_drop'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/train.py\", line 267, in <module>\n",
      "    train(args)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/train.py\", line 146, in train\n",
      "    out, aux_out, exemplar_features = model(img, bboxes)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 963, in forward\n",
      "    output = self.module(*inputs[0], **kwargs[0])\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/architecture/engine.py\", line 89, in forward\n",
      "    backbone_features = self.backbone(x)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/architecture/backbone.py\", line 175, in forward\n",
      "    features = self.backbone.forward_features(x)  # Sekarang akan mengembalikan list features\n",
      "  File \"/home/renaldy_fredyan/PhDResearch/ELS/module2/architecture/backbone.py\", line 51, in _forward_features\n",
      "    x = self.pos_drop(x)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1185, in __getattr__\n",
      "    raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
      "AttributeError: 'SwinTransformer' object has no attribute 'pos_drop'\n",
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 504102) of binary: /opt/miniconda/envs/Rey1/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda/envs/Rey1/bin/torchrun\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('torch==1.11.0', 'console_scripts', 'torchrun')())\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/run.py\", line 724, in main\n",
      "    run(args)\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/run.py\", line 715, in run\n",
      "    elastic_launch(\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 245, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "module2/train.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2025-02-05_15:08:19\n",
      "  host      : viplab-G481-H81-00\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 504103)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-02-05_15:08:19\n",
      "  host      : viplab-G481-H81-00\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 504102)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=6,7 torchrun --nproc_per_node=2 module2/train.py --model_name efficient1 --backbone swinT1k --swav_backbone --pre_norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
