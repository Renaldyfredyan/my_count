{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ab65ac-7e57-4ca2-928f-949378d234b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total annotated images: 6146\n",
      "Total available images in folder: 6146\n",
      "Missing images in folder: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Paths to dataset and annotations\n",
    "image_dir = \"/home/renaldy_fredyan/PhDResearch/LOCA/Dataset/images_384_VarV2\"\n",
    "annotation_file = \"/home/renaldy_fredyan/PhDResearch/LOCA/Dataset/annotation_FSC147_384.json\"\n",
    "\n",
    "# Load annotations\n",
    "with open(annotation_file, \"r\") as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Count total annotated images\n",
    "annotated_images = list(annotations.keys())\n",
    "print(f\"Total annotated images: {len(annotated_images)}\")\n",
    "\n",
    "# Check consistency between annotations and available images\n",
    "missing_images = []\n",
    "for img_name in annotated_images:\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "    if not os.path.exists(img_path):\n",
    "        missing_images.append(img_name)\n",
    "\n",
    "print(f\"Total available images in folder: {len(os.listdir(image_dir))}\")\n",
    "print(f\"Missing images in folder: {len(missing_images)}\")\n",
    "if missing_images:\n",
    "    print(\"Missing image examples:\", missing_images[:5])  # Print first 5 missing images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b68045-431f-40ad-9af9-e6e876477282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total annotations loaded: 6146\n",
      "Split: train, Total images in split: 3659\n",
      "Dataset size: 3659\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ObjectCountingDataset(Dataset):\n",
    "    def __init__(self, data_path, img_size, split='train', tiling_p=0.5):\n",
    "        self.data_path = data_path\n",
    "        self.img_size = img_size\n",
    "        self.split = split\n",
    "        self.tiling_p = tiling_p\n",
    "\n",
    "        # Load annotations\n",
    "        annotation_file = os.path.join(data_path, 'annotation_FSC147_384.json')\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            self.annotations = json.load(f)\n",
    "        \n",
    "        # Log total annotations loaded\n",
    "        print(f\"Total annotations loaded: {len(self.annotations)}\")\n",
    "\n",
    "        # Load image splits\n",
    "        if split in ['train', 'val', 'test']:\n",
    "            split_file = os.path.join(data_path, 'Train_Test_Val_FSC_147.json')\n",
    "            with open(split_file, 'r') as f:\n",
    "                splits = json.load(f)\n",
    "                self.image_names = splits.get(split, [])\n",
    "        else:\n",
    "            self.image_names = list(self.annotations.keys())\n",
    "        \n",
    "        # Log total images in the specified split\n",
    "        print(f\"Split: {split}, Total images in split: {len(self.image_names)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_names[idx]\n",
    "        img_path = os.path.join(self.data_path, 'images_384_VarV2', img_name)\n",
    "\n",
    "        # Check if image exists\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Image {img_name} is missing.\")\n",
    "            raise FileNotFoundError(f\"{img_path} not found.\")\n",
    "\n",
    "        # Return dummy data for debugging\n",
    "        return img_name\n",
    "\n",
    "# Example Usage\n",
    "dataset_path = \"/home/renaldy_fredyan/PhDResearch/LOCA/Dataset/\"\n",
    "dataset = ObjectCountingDataset(data_path=dataset_path, img_size=512, split='train')\n",
    "print(f\"Dataset size: {len(dataset)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
